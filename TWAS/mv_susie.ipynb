{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# TWAS multivariate susie\n",
    "Ready to use pipeline that conduct multivariate susie based on the output of univariate susie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim\n",
    "\n",
    "The aim of this workflow is to estimate the association between genotype and variouse molecular phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "We provide a container image `docker://gaow/twas` that contains all software needed to run the pipeline. If you would like to configure it by yourself, please make sure you install the following software before running this notebook:\n",
    "- tidyverse\n",
    "- PLINK\n",
    "- R package mashr\n",
    "- R package mmbr\n",
    "- Output from the following univatiate analysis pipeline: twas_fusion_susie.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Input and Output\n",
    "## Input\n",
    "\n",
    "This workflow is design to performed based on the output of the uni_susie.ipynb pipeline. If other input are used. Please followed the following instructions.\n",
    "\n",
    "- `molecular-pheno`, a plink trio per regions that are the output from the second steps of uni_susie.ipynb output. For each region, at least two sets of molecular-pheno are needed. For univariate analysis, please refer to the univariate sections of twas_fusion_susie.ipynb. The plink trio shall be named as following `{name_prefix}.{region}`.bed/fam/bim , as shown in the following example.\n",
    "\n",
    "```\n",
    "geneTpmResidualsAgeGenderAdj_rename.ENSG00000196126.bed  \n",
    "geneTpmResidualsAgeGenderAdj_rename.ENSG00000196126.bim  \n",
    "geneTpmResidualsAgeGenderAdj_rename.ENSG00000196126.fam\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- `--molecular-pheno-dir` The file shall contains a colnames \"#molc_pheno\" which documenting all the paths to the diretory of twas_fusion_susie.ipynb output,as shown in the following example.\n",
    "\n",
    "```\n",
    "#molc_pheno\n",
    "./AC\n",
    "./PCC\"\n",
    "```\n",
    "    If alternate input are used, all the molecular-pheno, in the form of plink trio, shall be stored in a \"cache\" directory, and the paths documented in this file shall be directed to the folder above the \"cache\" directory. \n",
    "\n",
    "- `--region_list` An index text file with a \"#region\" column documenting the {region} sections for each of the aforementioned plink trio as shown in the following example.\n",
    "\n",
    "```\n",
    "#region\n",
    "ENSG00000196126\n",
    "```\n",
    "\n",
    "- `--name-prefix` the first part for the file name of each of the plink trio.\n",
    "\n",
    "- `--cv_times` the number of times of cross validation to be ran.\n",
    "\n",
    "\n",
    "## Output\n",
    "\n",
    "- `.mv_cv.RData` An RData object containing all the susie objects with added hsq/RMSE/R2/Pval metrixs.\n",
    "\n",
    "- `.mv.RData` An RData object containing all the susie objects with added hsq, without cross validation\n",
    "\n",
    "- `{name_prefix}.{region}.transformed_XY.RData` A collection of Rdata objects stored in the \"result\" folder under the working diretory, storing the mean imputed and scaled X as well as the scaled Y for each region. \n",
    "\n",
    "- `.mv_wgt.txt` A collection of the actual weights that are computed for each genes used to predict the expresion. It works with the scaled X and Y.\n",
    "\n",
    "- `.cv_diag.RData` A collection of Rdata objects stored in the \"result\" folder under the working diretory, storing the simulation dataset and the result for each run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR\u001b[0m: \u001b[91mNotebook JSON is invalid: %s\u001b[0m\n",
      "\n",
      "\n",
      "usage: sos run mv_susie.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "\n",
      "\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "\n",
      "\n",
      "  targets:              One or more targets to generate\n",
      "\n",
      "\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "\n",
      "\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Workflows:\n",
      "\n",
      "\n",
      "  mv_susie\n",
      "\n",
      "\n",
      "  mv_susie_cv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Global Workflow Options:\n",
      "\n",
      "\n",
      "  --molecular-pheno-dir VAL (as path, required)\n",
      "\n",
      "\n",
      "                        Path to a list of molecular phenotypes that are to be\n",
      "\n",
      "\n",
      "                        analysised, shall contains a cache file within it.\n",
      "\n",
      "\n",
      "  --region-list VAL (as path, required)\n",
      "\n",
      "\n",
      "                        List of regions that are shared upon all three diretory\n",
      "\n",
      "\n",
      "  --wd VAL (as path, required)\n",
      "\n",
      "\n",
      "                        Path to the work directory of this pipeline,where the\n",
      "\n",
      "\n",
      "                        output will be stored.\n",
      "\n",
      "\n",
      "  --output-path  f'{wd:a}/result'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Path to store the output folder\n",
      "\n",
      "\n",
      "  --job-size 2 (as int)\n",
      "\n",
      "\n",
      "                        Specify the number of jobs per run.\n",
      "\n",
      "\n",
      "  --container 'gaow/twas'\n",
      "\n",
      "\n",
      "                        Container option for software to run the analysis:\n",
      "\n",
      "\n",
      "                        docker or singularity\n",
      "\n",
      "\n",
      "  --name-prefix chr\n",
      "\n",
      "\n",
      "                        name prefix of the molecular_pheno\n",
      "\n",
      "\n",
      "  --impute TRUE\n",
      "\n",
      "\n",
      "                        Whether impute the missing values\n",
      "\n",
      "\n",
      "  --testing-prop 0.2 (as float)\n",
      "\n",
      "\n",
      "                        propotion of samples set into testing, set to zero if no\n",
      "\n",
      "\n",
      "                        cv are needed.\n",
      "\n",
      "\n",
      "  --cv-times 100 (as int)\n",
      "\n",
      "\n",
      "                        Number of training & testing samples used\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sections\n",
      "\n",
      "\n",
      "  mv_susie_1, mv_susie_cv_1:\n",
      "\n",
      "\n",
      "  mv_susie_2, mv_susie_cv_2:\n",
      "\n",
      "\n",
      "  mv_susie_cv_3:\n",
      "\n",
      "\n",
      "  mv_susie_3:\n",
      "\n",
      "\n",
      "  mv_susie_cv_4:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sos run mv_susie.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Working example \n",
    "A minimal working example (MWE) dataset that can be downloaded from the following link, which required a synapse account:\n",
    "https://www.synapse.org/#!Synapse:syn24179065\n",
    "\n",
    "To test the command, please download and decompress the mwe folder, copy this file in it, and run the following command within the mwe folder.\n",
    "\n",
    "Alternativly, the options below can be changed based on respective relative paths.\n",
    "\n",
    "The time it take to run this MWE shall be around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "# Test the pipeline with MWE\n",
    "\n",
    "sos run ./mv_susie.ipynb mv_susie_cv  \\\n",
    "--molecular_pheno_dir \"molecular_phenotype_list\"   \\\n",
    "--region_list region_list  \\\n",
    "--wd ./   \\\n",
    "--name_prefix \"geneTpmResidualsAgeGenderAdj_rename\" \\\n",
    "--container /mnt/mfs/statgen/containers/twas_latest.sif --impute TRUE \\\n",
    "--cv_times 2  &\n",
    "\n",
    "# Test with prior\n",
    "sos run ~/GIT/neuro-twas/Workflow/mv_susie.ipynb mv_susie_cv \\\n",
    "--molecular_pheno_dir \"molecular_phenotype_list\"   \\\n",
    "--region_list region_list  \\\n",
    "--wd ./   \\\n",
    "--name_prefix \"geneTpmResidualsAgeGenderAdj_rename\" \\\n",
    "--container /mnt/mfs/statgen/containers/twas_latest.sif --impute TRUE \\\n",
    "--cv_times 2  \\\n",
    "--mixture_prior '~/Project/Genome_prior/merge/output/geneTpmResidualsAgeGenderAdj_rename.Both.flash.FL_PC3.teem.UD_ED.rds'&\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run ../../GIT/freshcopy/neuro-twas/Workflow/mv_susie.ipynb fusion_tf_cv \\\n",
    "--molecular_pheno_dir mole_pheno_ls   \\\n",
    "--region_list cand_rgs.txt  \\\n",
    "--wd ./   \\\n",
    "--name_prefix \"geneTpmResidualsAgeGenderAdj_rename\" \\\n",
    "--container gaow/twas --impute TRUE \\\n",
    "--cv_times 2  &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run ~/GIT/neuro-twas/Workflow/mv_susie.ipynb fusion_tf \\ \n",
    "--molecular_pheno_dir \"molecular_phenotype_list\"   \\\n",
    "--region_list region_list  \\\n",
    "--wd ./   \\\n",
    "--name_prefix \"geneTpmResidualsAgeGenderAdj_rename\" \\\n",
    "--container /mnt/mfs/statgen/containers/twas_latest.sif --impute TRUE \\\n",
    "--cv_times 2  &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Global parameter settings\n",
    "The section outlined the parameters that can be set in the command interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to a list of molecular phenotypes that are to be analysised, shall contains a cache file within it.\n",
    "parameter: molecular_pheno_dir = path\n",
    "\n",
    "parameter: region_list = path\n",
    "# Path to the work directory of this pipeline,where the output will be stored.\n",
    "parameter: wd = path\n",
    "# Path to store the output folder\n",
    "parameter: output_path = f'{wd:a}/result'\n",
    "# Specify the number of jobs per run.\n",
    "parameter: job_size = 2\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = 'gaow/twas'\n",
    "# List of regions that are shared upon all three diretory, needs to have ID\tCHR\tP0\tP1, the same way as that of the twas_fusion_susie pipeline.\n",
    "parameter: region_list = path\n",
    "# name prefix of the molecular_pheno\n",
    "parameter: name_prefix = \"chr\"\n",
    "# Whether impute the missing values\n",
    "parameter: impute = \"TRUE\"\n",
    "# propotion of samples set into testing, set to zero if no cv are needed.\n",
    "parameter: testing_prop = 0.2\n",
    "# Number of training & testing samples used\n",
    "parameter: cv_times = 100\n",
    "# Number of training & testing samples used\n",
    "parameter: cv_times = 100\n",
    "# Prior: list of prior of cov structure, an RDS file that is a list with an element \"U\" containing the cov structurer and an element \"w\" containintg the weights\n",
    "# Preferably the output of wgs_prior_genome pipeline.\n",
    "parameter: mixture_prior = \"NULL\"\n",
    "# SNPs to be included in the final analysis\n",
    "parameter: extract_snp = path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get regions of interest to focus on.\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "molecular_pheno = [x.strip().split() for x in open(molecular_pheno_dir).readlines() if x.strip() and not x.strip().startswith('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge of X (plink) and Y (R)\n",
    "Creat merge list, and then merged based on merged list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "input:  molecular_pheno_dir,for_each = \"regions\"\n",
    "output: f'{molecular_pheno[0]}/cache/{name_prefix}.{_regions[0]}',\n",
    "        f'{molecular_pheno[1]}/cache/{name_prefix}.{_regions[0]}',\n",
    "        f'{molecular_pheno[2]}/cache/{name_prefix}.{_regions[0]}'\n",
    "bash: expand = \"$[ ]\"\n",
    "     echo $[_output[0]]\n",
    "     echo $[_output[1]]\n",
    "     echo $[_output[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[snp_exclude_1,mv_susie_1,mv_susie_cv_1]\n",
    "input:  molecular_pheno_dir, for_each = \"regions\"\n",
    "output: f'{wd:a}/cache/{name_prefix}.{_regions[0]}.merged_list',\n",
    "        f'{wd:a}/cache/{name_prefix}.{_regions[0]}.merged.bed',\n",
    "        f'{wd:a}/cache/{name_prefix}.{_regions[0]}.merged.exp'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = '6G', tags = f'{step_name}_{_output[0]:bn}'  \n",
    "\n",
    "R: expand = \"$[ ]\", stderr = f'{_output[2]}.stderr', stdout = f'{_output[2]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    molecular_pheno = read_delim(\"$[molecular_pheno_dir]\",delim = \"\\t\")\n",
    "    molecular_pheno = molecular_pheno%>%mutate(dir = map_chr(`#molc_pheno`,~paste(c(`.x`,\"/cache/$[name_prefix].$[_regions[0]]\"),collapse = \"\")))\n",
    "    n = nrow(molecular_pheno)\n",
    "    # For every tissues read plink, and extract the fam df.\n",
    "    genos = tibble( i = 1:n)\n",
    "    genos = genos%>%mutate(fam = map(i, ~read_plink(molecular_pheno[[.x,2]])$fam%>%as_tibble()%>%mutate(name = paste(V1,\":\",V2,sep = \"\"))%>%select(name,V6)))\n",
    "    \n",
    "    # Join two tissues\n",
    "    genos_join_phe_$[_regions[0]] = full_join((genos%>%pull(fam))[[1]],(genos%>%pull(fam))[[2]],by = \"name\")\n",
    "    \n",
    "    # If there are more tissues, join the rest\n",
    "    if(n > 2){\n",
    "    for(j in 3:n){\n",
    "    genos_join_phe_$[_regions[0]] = full_join(genos_join_phe_$[_regions[0]],(genos%>%pull(fam))[[j]],by = \"name\")\n",
    "    }\n",
    "    }\n",
    "    genos_join_phe_$[_regions[0]]%>%readr::write_delim(\"$[_output[2]]\",delim = \"\\t\")\n",
    "    \n",
    "    # Create merge list\n",
    "    molecular_pheno[2]%>%readr::write_delim(\"$[_output[0]]\",delim = \"\\t\",col_names=FALSE)\n",
    "\n",
    "\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout',container = container\n",
    "\n",
    "    # create the merged output X\n",
    "    plink --bfile '$[next(iter(molecular_pheno[0]))]/cache/$[name_prefix].$[_regions[0]]'\\\n",
    "          --merge-list $[_output[0]] \\\n",
    "          --mac 1 \\\n",
    "          --make-bed \\\n",
    "          --out $[_output[1]:n] \\\n",
    "          --allow-no-sex \\\n",
    "          --extract $[extract_snp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performed MV susie\n",
    "This step filtered out some of the snvs that are deemed worthless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[snp_exclude_2]\n",
    "parameter: bed_list = path\n",
    "input: group_by = 3, group_with = 'regions'\n",
    "output: f'{wd:a}/cache_snp/{name_prefix}.{_regions[0]}.merged.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = '10G', tags = f'{step_name}_{_output[0]:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    # create the merged output X\n",
    "    plink --bfile $[_input[1]:n] \\\n",
    "          --mac 1 \\\n",
    "          --make-bed \\\n",
    "          --out $[_output:n] \\\n",
    "          --allow-no-sex \\\n",
    "          --extract $[extract_snp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Performed MV susie\n",
    "This step take the merged files from the previous step to performed mv susies. Before MV susie are done, the X are filter, mean-imputed, and then scaled. The Y are scaled. The covariance matrix of Y are computed via flashier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mv_susie_2,mv_susie_cv_2,susie]\n",
    "input: group_by = 3, group_with = 'regions'\n",
    "output:  f'{wd:a}/result/{_input[0]:bn}.mv_susie.model.RData',\n",
    "         f'{wd:a}/result/{_input[0]:bn}.transformed_XY.RData',\n",
    "         f'{wd:a}/result/{_input[0]:bn}.mv_wgt.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"mashr\")\n",
    "    library(\"mvsusieR\")  \n",
    "    library(\"flashier\")\n",
    "    library(\"modelr\")\n",
    "    # Define functions\n",
    "    ###Functions to compute MAF and missing genotype rate\n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "    \n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "    \n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "    \n",
    "    is_zero_variance <- function(x) {\n",
    "      if (length(unique(x%>%na.omit))==1) return(T)\n",
    "      else return(F)\n",
    "    }\n",
    "    ### Filter X matrix\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, is_zero_variance))\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(mean_impute(X))\n",
    "    }\n",
    "    ###Function to calculate the covariance matrix of Y via flash\n",
    "    compute_cov_flash <- function(Y, miss=NULL){\n",
    "      if(is.null(miss)){\n",
    "        fl <- flashier::flash(Y, var.type = 2, prior.family = c(flashier::prior.normal(), flashier::prior.normal.scale.mix()), backfit = TRUE, verbose.lvl=0)\n",
    "      } else {\n",
    "        fl <- flashier::flash(Y[-miss, ], var.type = 2, prior.family = c(flashier::prior.normal(), flashier::prior.normal.scale.mix()), backfit = TRUE, verbose.lvl=0)\n",
    "      }  \n",
    "      if(fl$n.factors==0){\n",
    "        covar <- diag(fl$residuals.sd^2)\n",
    "      } else {\n",
    "        fsd <- sapply(fl$fitted.g[[1]], '[[', \"sd\")\n",
    "        covar <- diag(fl$residuals.sd^2) + crossprod(t(fl$flash.fit$EF[[2]]) * fsd)\n",
    "      }\n",
    "      return(covar)\n",
    "    }\n",
    "    ###Function to impute the missing X with means and then scale and center X\n",
    "      impute_and_transform = function(genos,impute = TRUE){\n",
    "      tmp = genos\n",
    "      if(impute == TRUE){\n",
    "      for(i in 1:ncol(tmp)){\n",
    "        tmp[,i]=coalesce(tmp[,i],mean(tmp[,i]%>%na.omit()))%>%scale()}\n",
    "        return(tmp)\n",
    "      } else {\n",
    "    for(i in 1:ncol(tmp)){\n",
    "        tmp[,i]=tmp[,i]%>%scale()}\n",
    "        return(tmp)}}\n",
    "    if ($[impute] == TRUE){\n",
    "    # Load X data\n",
    "    X_$[_regions[0]]_raw = read_plink(\"$[_input[1]:n]\")$bed\n",
    "    # Filter X by 0.1 NA and 0.01 MAF\n",
    "    X_$[_regions[0]]_ftr = filter_X(X_$[_regions[0]]_raw,0.1,0.01)\n",
    "    X_$[_regions[0]] = impute_and_transform(X_$[_regions[0]]_ftr)\n",
    "    # Load Y data\n",
    "    Y_$[_regions[0]] = read_delim(\"$[_input[2]]\",delim = \"\\t\")\n",
    "    # Reorder Y based on X\n",
    "    Y_$[_regions[0]] = Y_$[_regions[0]]%>%arrange(match(name,rownames(X_$[_regions[0]])))%>%select(-name)%>%as.matrix()\n",
    "    # Compute the Cov matrix for Y via flashier\n",
    "    Y_$[_regions[0]] = impute_and_transform(Y_$[_regions[0]], impute = FALSE)\n",
    "    Y_$[_regions[0]]_cov = Y_$[_regions[0]]%>%compute_cov_flash()\n",
    "    # Get prior\n",
    "    prior_covar <- create_mash_prior(sample_data = list(X=X_$[_regions[0]],Y=Y_$[_regions[0]], residual_variance= Y_$[_regions[0]]_cov, max_mixture_len=-1))\n",
    "    } else {\n",
    "    # Load data\n",
    "    Y_$[_regions[0]] = read_delim(\"$[_input[2]]\",delim = \"\\t\")\n",
    "    # Remove NA from bed\n",
    "    X_$[_regions[0]] = read_plink(\"$[_input[1]:n]\")$bed%>%t()%>%na.omit()%>%t()%>%impute_and_transform(impute = FALSE)\n",
    "    # Reorder Y based on X\n",
    "    Y_$[_regions[0]] = Y_$[_regions[0]]%>%arrange(match(name,rownames(X_$[_regions[0]])))%>%select(-name)%>%as.matrix()\n",
    "    # Scale Y\n",
    "    Y_complete_$[_regions[0]] = Y_$[_regions[0]]%>%na.omit()\n",
    "    Y_$[_regions[0]] = impute_and_transform(Y_$[_regions[0]], impute = FALSE)\n",
    "    # Get prior\n",
    "    # Compute the Cov matrix for Y_complete\n",
    "    Y_$[_regions[0]]_cov = cov(Y_complete_$[_regions[0]])}\n",
    "   \n",
    "   \n",
    "    if('$[mixture_prior]' == 'NULL'){\n",
    "    prior_covar <- create_mash_prior(sample_data = list(X=X_$[_regions[0]],Y=Y_$[_regions[0]], residual_variance= Y_$[_regions[0]]_cov, max_mixture_len=-1,center=F,scale=F))\n",
    "    } else {\n",
    "    mx_prior = readRDS('$[mixture_prior]')\n",
    "    prior_covar <- create_mash_prior(mixture_prior = list( weights = mx_prior$w, matrices = mx_prior$U))\n",
    "    }\n",
    "   \n",
    "    m_$[_regions[0]] = mvsusie(X_$[_regions[0]], \n",
    "                Y_$[_regions[0]], \n",
    "                L=10, \n",
    "                prior_variance=prior_covar,\n",
    "                residual_variance = Y_$[_regions[0]]_cov,\n",
    "                precompute_covariances = TRUE)\n",
    " \n",
    "    #Add a hsq sub for the msusie object\n",
    "    hsq_$[_regions[0]]=rep(0,ncol(Y_$[_regions[0]]))\n",
    "    for (i in 1:ncol(Y_$[_regions[0]])){\n",
    "      hsq_$[_regions[0]][i] = var(predict(m_$[_regions[0]])[,i])/var(Y_$[_regions[0]][,i]%>%na.omit())}\n",
    "    m_$[_regions[0]]$hsq = hsq_$[_regions[0]]\n",
    "    #Output: model with hsq estimated\n",
    "    save(m_$[_regions[0]],file = \"$[_output[0]]\")\n",
    "    #Output: scaled data\n",
    "    scaled_$[_regions[0]] = list(X_$[_regions[0]],Y_$[_regions[0]])\n",
    "    save(scaled_$[_regions[0]],file = \"$[_output[1]]\")\n",
    "    #Output: Weight\n",
    "    m_$[_regions[0]]$coef%>%as.data.frame()%>%write_delim(\"$[_output[2]]\",delim = \"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Perform Crossvalidation and stored the relevent matrixs\n",
    "This step load the scaled X,Y output from the previouse step, perform CV, and calculate the diagnosis paramters: R2,P-value, and RMSE. The P value here is the indication of probability of observing the data under the null that there is no association between the predicted and actual Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mv_susie_cv_3,cv]\n",
    "input: group_by = 3, group_with = 'regions'\n",
    "output:  f'{wd:a}/result/{_input[0]:bn}.cv.RData',\n",
    "         f'{wd:a}/result/{_input[0]:bn}.cv_diag.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '8G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"mashr\")\n",
    "    library(\"mmbr\")  \n",
    "    library(\"flashier\")\n",
    "    library(\"purrr\")\n",
    "    library(\"modelr\")\n",
    "    \n",
    "    # Define functions\n",
    "    compute_cov_flash <- function(Y, miss=NULL){\n",
    "      if(is.null(miss)){\n",
    "        fl <- flashier::flash(Y, var.type = 2, prior.family = c(flashier::prior.normal(), flashier::prior.normal.scale.mix()), backfit = TRUE, verbose.lvl=0)\n",
    "      } else {\n",
    "        fl <- flashier::flash(Y[-miss, ], var.type = 2, prior.family = c(flashier::prior.normal(), flashier::prior.normal.scale.mix()), backfit = TRUE, verbose.lvl=0)\n",
    "      }  \n",
    "      if(fl$n.factors==0){\n",
    "        covar <- diag(fl$residuals.sd^2)\n",
    "      } else {\n",
    "        fsd <- sapply(fl$fitted.g[[1]], '[[', \"sd\")\n",
    "        covar <- diag(fl$residuals.sd^2) + crossprod(t(fl$flash.fit$EF[[2]]) * fsd)\n",
    "      }\n",
    "      return(covar)\n",
    "    }\n",
    "    \n",
    "    ## Compute rmse function\n",
    "    compute_rmse = function(raw,fitted){\n",
    "    rmse = rep(0,ncol(raw))\n",
    "    for (i in 1:ncol(raw)){\n",
    "      rmse[i] = ((fitted - raw)[,i])^2%>%mean(na.rm = TRUE)%>%sqrt() \n",
    "      }\n",
    "    return(rmse)\n",
    "    }\n",
    "    \n",
    "    ## Compute r2 function\n",
    "    compute_r2 = function(raw,fitted){\n",
    "      r2 = rep(0,ncol(raw))\n",
    "      for (j in 1:ncol(raw)){\n",
    "       r2[j] = summary(lm( fitted[,j] ~ raw[,j] ))$adj.r.sq\n",
    "      }\n",
    "      return(r2)\n",
    "    }\n",
    "    \n",
    "    ## Compute r2 raw\n",
    "    \n",
    "    compute_r2_raw = function(raw,fitted){\n",
    "      r2 = rep(0,ncol(raw))\n",
    "      for (j in 1:ncol(raw)){\n",
    "        r2[j] =  cor(fitted[,j][which(!is.na(raw[,j]))],raw[,j]%>%na.omit())^2\n",
    "      }\n",
    "      return(r2)\n",
    "    }\n",
    "    \n",
    "    ## Get P.value\n",
    "    compute_pval = function(raw,fitted){\n",
    "      pval = rep(0,ncol(raw))\n",
    "      for (k in 1:ncol(raw)){\n",
    "        pval[k] = summary(lm( fitted[,k] ~ raw[,k] ))$coef[2,4]\n",
    "      }\n",
    "      return(pval)\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    ###Functions to compute MAF and missing genotype rate\n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "    \n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "    \n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "    \n",
    "    is_zero_variance <- function(x) {\n",
    "      if (length(unique(x))==1) return(T)\n",
    "      else return(F)\n",
    "    }\n",
    "    ### Filter X matrix\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, is_zero_variance))\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(mean_impute(X))\n",
    "    }\n",
    "    \n",
    "    ### Produce CV dataset\n",
    "    cv_data_gen = function(X,Y,times,test_prop){\n",
    "    # Merged the X and Y for producing testing and training set for modelr cv\n",
    "    cv_df_raw = cbind(X,Y)%>%as_tibble() \n",
    "    cv_df = crossv_mc(cv_df_raw, times,test = test_prop)%>%mutate(\n",
    "      train_X = map(train,~as_tibble(.x)[1:ncol(X)]%>%as.matrix),\n",
    "      train_Y = map(train,~as_tibble(.x)[(ncol(X)+1):(ncol(X)+ncol(Y))]%>%as.matrix),\n",
    "      test_X = map(test,~as_tibble(.x)[1:ncol(X)]%>%as.matrix),\n",
    "      test_Y = map(test,~as_tibble(.x)[(ncol(X)+1):(ncol(X)+ncol(Y))]%>%as.matrix)\n",
    "    )  \n",
    "    \n",
    "    # Filter Train X with maf and missing, filter test X with the same col as Train X\n",
    "    cv_df = cv_df%>%mutate(\n",
    "    train_X = map(train_X,~filter_X(.x,0.1,0.01)),\n",
    "    test_X = map2(test_X,train_X,~.x%>%as_tibble()%>%select(colnames(.y))%>%as.matrix())\n",
    "    )\n",
    "    return(cv_df)\n",
    "    }\n",
    "    \n",
    "    # Load data\n",
    "    full_model = attach('$[_input[0]]')\n",
    "    full_model = full_model$m_$[_regions[0]]\n",
    "    X = attach('$[_input[1]]')$scaled_$[_regions[0]][[1]]\n",
    "    Y = attach('$[_input[1]]')$scaled_$[_regions[0]][[2]]\n",
    "    # Generate cv dataaset\n",
    "    \n",
    "    \n",
    "    cv_df = cv_data_gen(X,Y,$[cv_times],$[testing_prop])\n",
    "    \n",
    "                                                      \n",
    "    # Compute the cov matrix for training set Y based on the choice of imputation                  \n",
    "                         \n",
    "    if ($[impute] == TRUE){\n",
    "        cv_df = cv_df%>%mutate( \n",
    "        cov = map(train_Y,~.x%>%compute_cov_flash())\n",
    "      )\n",
    "        }else{\n",
    "      cv_df = cv_df%>%mutate(\n",
    "        cov = map(train_Y,~cov(.x%>%na.omit)))}\n",
    "\n",
    "    # Actual cv\n",
    "    \n",
    "    if('$[mixture_prior]'=='NULL'){\n",
    "\n",
    "    \n",
    "    cv_df = cv_df%>%mutate(\n",
    "    \n",
    "    ## Get the prior\n",
    "    \n",
    "        prior = pmap(list(train_X,train_Y,cov),function(first,second,third)(\n",
    "        create_mash_prior(sample_data = list( X = first, Y = second, residual_variance = third, max_mixture_len =-1,center =F,scale =F)\n",
    "        ))) ,\n",
    "        \n",
    "    ## Do msusie\n",
    "    \n",
    "      msusie = pmap(list(train_X,train_Y,cov,prior),function(first,second,third,forth)(\n",
    "        mvsusie(first,second, L=10, prior_variance = forth,residual_variance = third,precompute_covariances = TRUE)\n",
    "        ))\n",
    "        \n",
    "        )} else {\n",
    "   \n",
    "       mx_prior = readRDS('$[mixture_prior]')\n",
    "    ## Get the prior\n",
    "       prior_covar <- create_mash_prior(mixture_prior = list( weights = mx_prior$w, matrices = mx_prior$U))\n",
    "       \n",
    "       cv_df = cv_df%>%mutate(\n",
    "        \n",
    "    ## Do msusie\n",
    "    \n",
    "      msusie = pmap(list(train_X,train_Y,cov),function(first,second,third)(\n",
    "        msusie(first,second, L=10, prior_variance = prior_covar,residual_variance = third,precompute_covariances = TRUE)\n",
    "        )))\n",
    "    }\n",
    "    # Extract data \n",
    "    \n",
    "    cv_df = cv_df%>%mutate(\n",
    "      weight = map(msusie,~.x$coef),\n",
    "      test_fitted = map2(msusie,test_X,~predict.mmbr(.x,.y)),\n",
    "      rmse = map2(test_Y,test_fitted,~compute_rmse(.x,.y)),\n",
    "      r2 = map2(test_Y,test_fitted,~compute_r2(.x,.y)),\n",
    "      r2_raw = map2(test_Y,test_fitted,~compute_r2_raw(.x,.y)),\n",
    "      pval = map2(test_Y,test_fitted,~compute_pval(.x,.y))\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    \n",
    "    mean_rmse = cv_df%>%pull(rmse)%>%as.data.frame()%>%t()%>%as_tibble()%>%na.omit()%>%colMeans()\n",
    "    mean_r2 = cv_df%>%pull(r2)%>%as.data.frame()%>%t()%>%as_tibble()%>%na.omit()%>%colMeans()\n",
    "    mean_r2_raw = cv_df%>%pull(r2_raw)%>%as.data.frame()%>%t()%>%as_tibble()%>%na.omit()%>%colMeans()\n",
    "    mean_pval = cv_df%>%pull(pval)%>%as.data.frame()%>%t()%>%as_tibble()%>%na.omit()%>%colMeans()\n",
    "\n",
    "  \n",
    "    # Save metrics\n",
    "    full_model$rmse = mean_rmse\n",
    "    full_model$r2 = mean_r2 \n",
    "    full_model$r2_raw = mean_r2_raw    \n",
    "    full_model$pval = mean_pval\n",
    "    full_model$snps = colnames(X)\n",
    "\n",
    "    # Save the CV data\n",
    "    save(cv_df,file = \"$[_output[1]]\")\n",
    "    \n",
    "    #Output\n",
    "    save(full_model,file = \"$[_output[0]]\")\n",
    "    \n",
    "   \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merging all the RData file\n",
    "THis step merged the output from  the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mv_susie_3]\n",
    "input: group_by = \"all\"\n",
    "output:  f'{wd:a}/mv.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load a template\n",
    "    region = read_delim(\"$[region_list]\",delim =\"\\t\")%>%select(ID = `#region` )\n",
    "    # get the path\n",
    "    dir = \"$[_input[0]:d]/\"\n",
    "    pre = \"$[name_prefix]\"\n",
    "    sur = \".mv_susie.model.RData\"\n",
    "    region = region%>%mutate(path = map(ID, ~paste(collapse = \"\", c(dir,pre,\".\",.x,sur))))\n",
    "    # Load the data\n",
    "    output = region%>%mutate(env = map(path,~attach(.x)),\n",
    "                            tb_name = map_chr(ID,~paste(collapse = \"_\", c(\"m\",.x))),\n",
    "                             model = map2(env,tb_name , ~get(.y,env = .x)))\n",
    "    # Save the combined output\n",
    "    save(output,file = \"$[_output]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mv_susie_cv_4]\n",
    "input: group_by = \"all\"\n",
    "output:  f'{wd:a}/mv_cv.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load a template\n",
    "    region = read_delim(\"$[region_list]\",delim =\"\\t\")%>%select(ID = `#region` )\n",
    "    # get the path\n",
    "    dir = \"$[_input[0]:d]/\"\n",
    "    pre = \"$[name_prefix]\"\n",
    "    sur = \".mv_susie.model.cv.RData\"\n",
    "    region = region%>%mutate(path = map(ID, ~paste(collapse = \"\", c(dir,pre,\".\",.x,sur))))\n",
    "    # Load the data\n",
    "    output = region%>%mutate(env = map(path,~attach(.x)),\n",
    "                            tb_name = \"full_model\",\n",
    "                             model = map2(env,tb_name , ~get(.y,env = .x)))\n",
    "    # Save the combined output\n",
    "    save(output,file = \"$[_output]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion transformed\n",
    "These step seperate the output from the previous step into the wgt file for each tissues that can be input to the Fusion Association testing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:2:1: unexpected '['\n1: # Create wgs.RDat file\n2: [\n   ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:2:1: unexpected '['\n1: # Create wgs.RDat file\n2: [\n   ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Create wgs.RDat file\n",
    "[fusion_tf_cv_1]\n",
    "input:  molecular_pheno_dir,for_each = 'regions'\n",
    "output: dynamic(f'{wd:a}/wgt/*/{name_prefix}.{_regions[0]}.mv.wgt.RDat')\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_index}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_input[0]}.split.stderr', stdout = f'{_input[0]}.split.stderr',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    #Load the input\n",
    "    genos = read_plink('$[wd:a]/cache/$[name_prefix].$[_regions[0]].merged')\n",
    "    molecular_pheno = read_delim('$[_input[0]]',delim = '\\t')\n",
    "    load('$[wd:a]/result/$[name_prefix].$[_regions[0]].mv_susie.model.cv.RData')\n",
    "    #Get all the components\n",
    "    pval = full_model$pval\n",
    "    rsq = full_model$r2\n",
    "    \n",
    "    hsq.pv = NA\n",
    "    N.tot = nrow(genos$bed)\n",
    "    \n",
    "    cv.performance_tol = rbind(\n",
    "    rsq = rsq, \n",
    "    pval = pval\n",
    "    )\n",
    "    ## Filter out the snps that are not in the bim for consistancy\n",
    "    snps = genos$bim%>%filter(V2 %in%full_model$snps )\n",
    "    \n",
    "    # Create output for each tissue saperately\n",
    "\n",
    "    for(i in 1:nrow(molecular_pheno) ){\n",
    "    wgt.matrix = full_model$coef[2:nrow(full_model$coef),i]%>%as.matrix()\n",
    "    hsq = full_model$hsq[i]\n",
    "    dir = \"$[wd:a]/wgt/\"\n",
    "    tis = read.table(text = molecular_pheno[[i,1]], sep = \"/\", as.is = TRUE)\n",
    "    tis = tis[[length(tis)]]\n",
    "    sur = \"/$[name_prefix].$[_regions[0]].mv.cv.wgt.RDat\"\n",
    "    out = paste(collapse = \"\",c(dir,tis,sur))\n",
    "    cv.performance = cv.performance_tol[,i]%>%as.matrix()\n",
    "    colnames(cv.performance) = \"mv_susie\"\n",
    "    # make the folders\n",
    "    cmd0 = paste(c(\"mkdir \",dir),collapse = \"\")\n",
    "    system(cmd0,ignore.stdout=TRUE,ignore.stderr=TRUE)\n",
    "    cmd1 = paste(c(\"mkdir \",dir,tis),collapse = \"\")\n",
    "    system(cmd1,ignore.stdout=TRUE,ignore.stderr=TRUE)\n",
    "    # save the files\n",
    "    save(\n",
    "    wgt.matrix,\n",
    "    snps,\n",
    "    cv.performance,\n",
    "    hsq, hsq.pv, N.tot,\n",
    "    file = out\n",
    "    )    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wgs.RDat file\n",
    "[fusion_tf_1]\n",
    "input:  molecular_pheno_dir,for_each = 'regions'\n",
    "output: dynamic(f'{wd:a}/wgt/*/{name_prefix}.{_regions[0]}.mv.wgt.RDat')\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_index}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_input[0]}.split.stderr', stdout = f'{_input[0]}.split.stderr',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    #Load the input\n",
    "    genos = read_plink('$[wd:a]/cache/$[name_prefix].$[_regions[0]].merged')\n",
    "    molecular_pheno = read_delim('$[_input[0]]',delim = '\\t')\n",
    "    full_model = attach('$[wd:a]/result/$[name_prefix].$[_regions[0]].mv_susie.model.RData')$m_$[_regions[0]]\n",
    "    X_dat = attach('$[wd:a]/result/$[name_prefix].$[_regions[0]].transformed_XY.RData')$scaled_$[_regions[0]]\n",
    "    X_snps = colnames(X_dat[[1]])\n",
    "    #Get all the components\n",
    "    pval = NA\n",
    "    rsq = NA\n",
    "    hsq.pv = NA\n",
    "    N.tot = nrow(genos$bed)\n",
    "    cv.performance_tol = rbind(\n",
    "    rsq = rsq, \n",
    "    pval = pval\n",
    "    )\n",
    "    ## Filter out the snps that are not in the bim for consistancy\n",
    "    snps = genos$bim%>%filter(V2 %in% X_snps )\n",
    "    \n",
    "    # Create output for each tissue saperately\n",
    "\n",
    "    for(i in 1:nrow(molecular_pheno) ){\n",
    "    wgt.matrix = full_model$coef[2:nrow(full_model$coef),i]%>%as.matrix()\n",
    "    hsq = full_model$hsq[i]\n",
    "    dir = \"$[wd:a]/wgt/\"\n",
    "    tis = read.table(text = molecular_pheno[[i,1]], sep = \"/\", as.is = TRUE)\n",
    "    tis = tis[[length(tis)]]\n",
    "    sur = \"/$[name_prefix].$[_regions[0]].mv.wgt.RDat\"\n",
    "    out = paste(collapse = \"\",c(dir,tis,sur))\n",
    "    cv.performance = cv.performance_tol\n",
    "    colnames(cv.performance) = \"mv_susie\"\n",
    "    # make the folders\n",
    "    cmd0 = paste(c(\"mkdir \",dir),collapse = \"\")\n",
    "    system(cmd0,ignore.stdout=TRUE,ignore.stderr=TRUE)\n",
    "    cmd1 = paste(c(\"mkdir \",dir,tis),collapse = \"\")\n",
    "    system(cmd1,ignore.stdout=TRUE,ignore.stderr=TRUE)\n",
    "    # save the files\n",
    "    save(\n",
    "    wgt.matrix,\n",
    "    snps,\n",
    "    cv.performance,\n",
    "    hsq, hsq.pv, N.tot,\n",
    "    file = out\n",
    "    )    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fusion_tf_cv_2]\n",
    "molecular_pheno = [x.strip().split(\"/\") for x in open(molecular_pheno_dir).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: region_list, for_each = \"molecular_pheno\"\n",
    "output: f'{wd:a}/wgt/{_molecular_pheno[1]}/All_wgt_list.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_index}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load the template\n",
    "    temp = read_delim('$[_input]',delim = \"\\t\")\n",
    "    # Create name\n",
    "    dir = \"$[wd:a]/wgt/\"\n",
    "    tis = \"$[_molecular_pheno[1]]\"\n",
    "    pre = \"/$[name_prefix].\"\n",
    "    sur = \".mv.cv.wgt.RDat\"\n",
    "    res = temp%>%mutate(\n",
    "    WGT = map_chr(`#region`,~paste(collapse = \"\", c(dir,tis,pre,.x,sur)))\n",
    "    )%>%select(WGT,ID = `#region`,CHR = chr, P0 = start_position, P1 = end_position)\n",
    "    res%>%write_delim(\"$[_output]\",delim = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fusion_tf_2]\n",
    "molecular_pheno = [x.strip().split(\"/\") for x in open(molecular_pheno_dir).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: region_list, for_each = \"molecular_pheno\"\n",
    "output: f'{wd:a}/wgt/{_molecular_pheno[1]}/All_wgt_list.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '6G', tags = f'{step_name}_{_index}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load the template\n",
    "    temp = read_delim('$[_input]',delim = \"\\t\")\n",
    "    # Create name\n",
    "    dir = \"$[wd:a]/wgt/\"\n",
    "    tis = \"$[_molecular_pheno[1]]\"\n",
    "    pre = \"/$[name_prefix].\"\n",
    "    sur = \".mv.wgt.RDat\"\n",
    "    res = temp%>%mutate(\n",
    "    WGT = map_chr(`#region`,~paste(collapse = \"\", c(dir,tis,pre,.x,sur)))\n",
    "    )%>%select(WGT,ID = `#region`,CHR = chr, P0 = start_position, P1 = end_position)\n",
    "    res%>%write_delim(\"$[_output]\",delim = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
