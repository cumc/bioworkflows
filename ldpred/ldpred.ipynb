{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# LDpred2 Pipeline for Polygenic Risk Score Prediction\n",
    "\n",
    "This notebook shows the pipepline for genome-wide PRS prediction using R package [bigsnpr](https://privefl.github.io/bigsnpr/) and [PLINK v1.9](https://zzz.bwh.harvard.edu/plink/) implementing the [LDpred2](https://pubmed.ncbi.nlm.nih.gov/33326037/)  method referenced on the tutorials from [Florian Privé](https://privefl.github.io/bigsnpr/articles/LDpred2.html) and [Shing Wan Choi](https://choishingwan.github.io/PRS-Tutorial/ldpred/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "*Author: Mengyu Zhang, mengyu1307@gmail.com with input from Gao Wang*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim\n",
    "\n",
    "The pipeple was developed to predict PRS using infinitesimal, grid and auto model to estimate effect size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### PRS model\n",
    "\n",
    "Typically, phenotype $Y$ for $N$ individuals is modeled as a linear combination of $M$ genetic effects, $P$ covaritates and an independent random noise shown as formula (1). \n",
    "\n",
    "$$\n",
    "Y = \\sum_{i=j}^{M} X_{j} \\beta_{j} + \\sum_{j=1}^{P} Z_{j} \\alpha_{j} + \\varepsilon \\tag{1}\n",
    "$$\n",
    "\n",
    "Assuming genotype $X$ is centered and scaled, the (marginal) least-squares estimate of an individual marker effect is $\\hat\\beta_j=X_j^\\prime Y/N$. \n",
    "\n",
    "[LDpred](https://pubmed.ncbi.nlm.nih.gov/26430803/) is a Bayesian PRS that account for the effects of linkage disequilibrium (LD). It estimates posterior mean causaul effect sizes from GWAS summary statistics by assuming **genetic *architecture* prior** and **LD information from a reference panel**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### LD reference panel\n",
    "\n",
    "The choice of reference panel is crucial to the prediction performance of LDpred model. Population structure should ideally be the same (and in practice as similar as possible) between reference panel and training data that summary statistics are calculated from. \n",
    "\n",
    "Also, a [preliminary quality control](https://www.nature.com/articles/s41596-020-0353-1) on genotype reference data should be conducted. This includes but not limited to \n",
    "\n",
    "1. Filter individuals with much (>10%) genotype calls missing and filter SNPs that had a missing rate more than 1% and a minor allele frequency (MAF) greater than 1%\n",
    "2. Remove SNPs that have ambiguous nucleotides, i.e., A/T and G/C. \n",
    "\n",
    "In addition to SNP filtering, [SNP flipping](http://statgen.us/lab-wiki/compbio_tutorial/allele_qc) may be necessary. It is of importance that GWAS summary stats has the same effect allele, and non-effect allele. Therefore, if the alleles of a SNP in the summary stats is the reverse of the alleles of the reference panel, the sign of z-scores (also effect size, log odds ratio, etc) is need to be flipped. At the end, summary statistics and reference panel will be matched on the basis of the SNP rsID.\n",
    "\n",
    "Independent validation cohort or dataset can be used as LD reference panel. Here is an example in the literature: [Bjarni J. Vilhja´lmsson (2015)](https://pubmed.ncbi.nlm.nih.gov/26430803/) used 1000 Genome, Hapmap imputed cohort validation dataset as reference panel. He analyzed six large summary-statistics datasets in his study, including schizophrenia with European and non-European ancestry, multiple sclerosis (MS), breast cancer (BC), coronary crtery cisease (CAD), type II diabetes (T2D) and height. For schizophrenia with European ancestry, they used the Psychiatric Genomics Consortium 2 (PGC2) SCZ summary statistics excluding the ISC (International Schizophrenia Consortium) cohorts and the MGS (Molecular Genetics of Schizophrenia) cohorts. ISC and MGS datasets are used as validation datasets. For non-European ancestry, MGS validation datasets was used as an LD reference. To coordinate the summary statistics from Asian population, they used overlap among 1000 Genomes imputed MGS genotypes and the 1000 Genomes imputed validation genotypes for the three Asian validation datasets (JPN1, TCR1, and HOK2), respectively. For African-American (AFAM) population, they used overlap among the 1000 Genomes imputed MGS genotypes and the HapMap 3 imputed AFAM genotypes.\n",
    "\n",
    "The reference panel applied in this pipeline is 1000 genomes project (phase 3) data including 503 (mostly unrelated) European individuals and ~1.7M SNPs in common with either HapMap3 or the UK Biobank. EUR includes Utah Residents (CEPH) with Northern and Western European Ancestry, Toscani in Italia, Finnish in Finland, British in England and Scotland and Iberian Population in Spain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### LDpred prior effect size model\n",
    "\n",
    "The **prior for effect sizes** is a point-normal mixture distribution with 2 hyper-parameters: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Heritability (parameter) explained by the genotypes\n",
    "\n",
    "The heritability $h_g^2$ is estimated from LD score regression and is used as initial parameter for LDpred2 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Fraction of causal markers (i.e., the fraction of markers with non-zero effects)\n",
    "\n",
    "The distribution of effect size for variant $j$ is given as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "$$\n",
    "\\beta_{j}  \\sim\\left\\{\\begin{array}{ll}\n",
    "\\mathcal{N}\\left(0, \\frac{h_g^{2}}{M p}\\right) & \\text { with probability } \\mathrm{p} \\\\\n",
    "0 & \\text { otherwise }\n",
    "\\end{array}\\right. \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### LDpred-inf (infinitesimal model)\n",
    "    \n",
    "In this case, all markers are **causal** ($p$=1), and effect drawn from a Gaussian distribution, i.e., $\\beta_{ij} \\sim_{i i d} N\\left(0,\\left(h_{g}^{2} / M\\right)\\right)$. The posterior mean can be derived analytically\n",
    "\n",
    "$$\n",
    "E(\\beta_j \\mid \\tilde{\\beta}_j, D) \\approx\\left(\\frac{M}{N h_{g}^{2}} I+D\\right)^{-1} \\tilde{\\beta}_j \\tag{3}\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\beta}_{j}$ denotes a vector of marginally estimated least-squares estimates obtained from the GWAS summary statistics. $D$ denotes the LD matrix between the markers in the training data.\n",
    "    \n",
    "#### LDpred-grid/auto (non-infinitesimal model) \n",
    "\n",
    "Without considering LD, the posterior mean of effect size can be derived as \n",
    "\n",
    "$$\n",
    "\\mathrm{E}\\left(\\beta_{j} \\mid \\tilde{\\beta}_{j}\\right)=\\left(\\frac{ h_{g}^{2}}{h_{g}^{2}+\\frac{M p}{N}}\\right) \\bar{p}_{j} \\tilde{\\beta}_{j} \\tag{4}\n",
    "$$\n",
    "\n",
    "where $\\bar p_j$ is the posterior probability that the $j^{th}$ marker is causal.\n",
    "\n",
    "However, it is very difficult to derive a analytical expression for the posterior mean under a non-infinitesimal Gaussian mixture prior. Therefore, LDpred approximates it numerically by using an approximate MCMC Gibbs sampler. Once posterior mean effect sizes are estimated, they will be applied to genotype data to obtain **PRSs**. \n",
    "\n",
    "Grid model tries a grid of parameters that $p$ ranges from 0 to 1 and three $h^2$ which are 0.7/1/1.4 times of initial $h^2$ estimated by LD score regression. The best combination of $p$ and $h^2$ will be selected according to the t score associated with each variants and covariates in phenotype model. Auto model runs the algorithm for 30 different $p$ values ranging from 10e-4 to 0.9. $h^2$ estimated from LD score regression is the initial value of algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### LDpred2\n",
    "\n",
    "LDpred2 is LDpred 2.0. It can estimate effect size without using validation data to tunning hyper-parameters. Plus, it provides better predictive performance when the causal varients in long-range LD regions and sparse.\n",
    "\n",
    "LDpred2 algorithm relies on an assumption that \n",
    "\n",
    "$$\n",
    "\\operatorname{sd}\\left(G_{j}\\right) \\approx \\frac{\\operatorname{sd}(Y)}{\\operatorname{se}\\left(\\hat{\\gamma}_{j}\\right) \\sqrt{n}} \\tag{5}\n",
    "$$\n",
    "\n",
    "where $G_j$ the genotype vector for variant $j$, and $\\hat{\\gamma}_{j}$ is marginal effect of vairant $j$. For binary traits with logistic model, the approximation is \n",
    "\n",
    "$$\n",
    "\\operatorname{sd}\\left(G_{j}\\right) \\approx \\frac{2}{\\operatorname{se}\\left(\\hat{\\gamma}_{j}\\right) \\sqrt{n_{\\mathrm{eff}}}} \\tag{6}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "n_{\\mathrm{eff}}=\\frac{4}{1 / n_{\\text {case }}+1 / n_{\\text {control }}} \\tag{7}\n",
    "$$\n",
    "\n",
    "To ensure the validity of the assumption, quality control on summary statistics is highly recommanded: remove variants with $SD_{ss} < 0.5\\times SD_{val}$ or $SD_{ss} > 0.1 + SD_{val}$ or $SD_{ss} < 0.1$ or $SD_{val} < 0.05$. $SD_{ss}$ is the standard deviations derived from the summary statistics (right-hand side of equation). $SD_{val}$ is the standard deviations of genotypes of individuals in the validation set (training set) (left-hand side)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Other Methods for PRS Prediction\n",
    "\n",
    "An intuitive and simple method for prediction is **unadjusted PRS**. Given linear model (1), the standard unadjusted polygenic ris score for $i^{th}$ individual is $S_i=\\sum_{j=1}^MX_{ij}\\hat\\beta_j$ under the assumption that $X_j$ are uncorrelated.\n",
    "\n",
    "Pruning/Clumping and thresholding (P $+$ T, C $+$ T) is a commonly used approach to preidct PRS. Variants are filterd based on an empirically determined P-value threshold. Then linked variants will be clumped into the same group. Within each group, calculate correlation among index variants and nearby variants within certain genetic distance and remove correlated nearby variants beyond a certain value. Finally, only SNPs with lowest P values in each group are selected into the prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Method for Phenotype Prediction\n",
    "\n",
    "Target data is splited into train dataset (80%) and test dataset (20%). Fit linear/logistic model on train dataset and then predict the phenotype on testdata. MSE and $R^2$ are calculated to considered as potential metrics to evaluate model performance of prediction. Missing genotypes are imputed with the mean of the genotype dosage for that variant with `snp_fastImputeSimple()` according to [Florian Privé](https://github.com/privefl/bigsnpr/issues/124#issuecomment-668598849)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "1. Reference panel\n",
    "\n",
    "    `--reference_geno`\n",
    "    \n",
    "2. Target data: genotypes and phenotypes \n",
    "\n",
    "    `--target_geno`\n",
    "    \n",
    "    File contians only covariate predictors:\n",
    "    \n",
    "    `--covFile`   \n",
    "    \n",
    "    File contrians only traits one column (phenotype):\n",
    "  \n",
    "    `--phenoFile`\n",
    "  \n",
    "3. Summary statistics of base data\n",
    "\n",
    "    `--ss`  \n",
    "    \n",
    "   Summary statistics should includes columns: \"chr\", \"pos\", \"rsid\", \"a1\", \"a0\", \"beta\", \"beta_se\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "The pipeline saves the results from every steps. Main outputs are\n",
    "\n",
    "* Posterior effect size and PRS (inf/grid/auto)\n",
    "    \n",
    "* Regression model results for phenotype prediction\n",
    "    \n",
    "* Summary of models and evaluation of prediction performance\n",
    "\n",
    "* Plots\n",
    "    - Quality control plot   \n",
    "    - Convergence plot from grid (z socre) and auto model (heritability and proportions of causal variants)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## General workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Preliminary quality control on reference panel\n",
    "\n",
    "Filtered SNPs that had a missing rate less than 1% and a minor allele frequency (MAF) greater than 1% in the reference genotype data. Excludes individuals whoes genotype missingness rate higher than 2%.\n",
    "\n",
    "#### Output\n",
    "\n",
    "* Reference panel after QC saved to `work_dir/ref.work_dir.bed/bim/fam`\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb preprocess:1 \\\n",
    "    --cwd $work_dir \\\n",
    "    --genoFiles <path/to/ref.bed>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Intersect SNPs among summary stats, reference panel and target data\n",
    "\n",
    "This step returns a file `xxx.intersect.snplist` recording the common SNPs among reference panel, base data and target data. Then filter variants in the reference panel, summary statistics and target data. Common variants in target data should be filtered after SNP matching or quality control.\n",
    "\n",
    "#### Output\n",
    "\n",
    "* Summary statistics data after filtering common SNPs saved to `work_dir/sumstats.intersect.rds`\n",
    "* Reference panel after filtering common SNPs saved to `work_dir/ref.work_dir.snp_intersect.extracted.bed/bim/fam`\n",
    "* Target data after filtering common SNPs saved to `work_dir/target.work_dir.snp_intersect.extracted.bed/bim/fam`\n",
    "* Common SNPs saved to three data folders saved to `work_dir/intersect.snplist`\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb snp_intersect \\\n",
    "    --cwd $work_dir \\\n",
    "    --ss <path/to/sumstats.rds> \\\n",
    "    --genoFiles <path/to/ref.work_dir.bed> <path/to/target.bed>\n",
    "    \n",
    "cat $work_dir/gwas_hdl.intersect.stdout\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### SNP Matching\n",
    "\n",
    "Perform SNP matching using `snp_match(sumstats, map)`. Match alleles between summary statistics `sumstats` and SNP information in `map` from reference panel.\n",
    "\n",
    "#### Output\n",
    "\n",
    "* Summary statistics after snp matching saved to `work_dir/sumstats.snp_matched.rds`.\n",
    "* The SNPs left after matching and also the SNPs used to fit LDpred model saved to `work_dir/snp_matched.snplist`.\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb snp_match \\\n",
    "    --cwd $work_dir \\\n",
    "    --reference_geno <work_dir/ref.work_dir.snp_intersect.extracted.rds> \\\n",
    "    --ss <path/to/sumstats.rds>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "###  Quality Control on Summary Statistics\n",
    "\n",
    "See section `Ldpred2`. \n",
    "\n",
    "#### Output\n",
    "\n",
    "* Summary statistics after quality control saved to `work_dir/sumstats.snp_matched.qc.rds`.\n",
    "* Plot showing the removed SNPs saved to `work_dir/sumstats.snp_matched.qc.png`.\n",
    "* The SNPs used to fit LDpred model, also the SNPs we need to predict PRS in target data saved to `work_dir/sumstats.snp_matched.qc.snplist`.\n",
    "\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb sumstats_qc \\\n",
    "    --cwd $work_dir \\\n",
    "    --reference_geno <work_dir/ref.work_dir.snp_intersect.extracted.rds> \\\n",
    "    --ss <path/to/sumstats.snp_matched.rds> \\\n",
    "    --sdy 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Calculate LD matrix and Fit LDSC Model\n",
    "\n",
    "Calculate LD correlation using `snp_cor(Gna, size, infos.pos)`\n",
    "\n",
    "* size: for one SNP, window size around this SNP to compute correlations. Window size of 3 cM is applied in this pipeline which is recommanded by the developer.\n",
    "* infos.pos: specifying the physical position on a chromosome (in base pairs) of each SNP. \n",
    "\n",
    "Fit LDSC model using `snp_ldsc()`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* LD matrix and LDSC model saved to `work_dir/sumstats.snp_matched.ld.rds` or `work_dir/sumstats.snp_matched.qc.ld.rds`.\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb ldsc \\\n",
    "    --cwd $work_dir \\\n",
    "    --ss <work_dir/sumstats.snp_matched.rds> \\\n",
    "    --reference-geno <work_dir/ref.work_dir.snp_intersect.extracted.rds>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Estimate posterior effect sizes and PRS\n",
    "\n",
    "Three models can be applied to predict PRS which are infinitesimal, grid and auto models. \n",
    "\n",
    "* Estimate effect size \n",
    "\n",
    "    - Infinitesimal model: `snp_ldpred2_inf(corr, df_beta, h2)`\n",
    "    - Grid model: `snp_ldpred2_grid(corr, df_beta, grid_param)`\n",
    "        \n",
    "        gird_param: grid of hyper parameters $p$ and $h^2$\n",
    "        \n",
    "    - Auto model: `snp_ldpred2_auto(corr, df_beta, h2_init, vec_p_init)`\n",
    "    \n",
    "        h2_init: estiamted from LD score regression\n",
    "        \n",
    "        vec_p_init: with 30 different initial values for p. Ranges from 0 to 0.9.\n",
    "        \n",
    "* Derive PRS\n",
    "\n",
    "    For grid and auto model, the best combination of p and $h^2$ was selected based on largest t score and mean of 3 times of median absolute deviation of predicted PRS.\n",
    "\n",
    "#### Output\n",
    "\n",
    "* Estimated effect size `adj_beta` and PRS prediction `prs_pred` saved to `work_dir/sumstats.snp_matched.<model>_prs.rds`.\n",
    "\n",
    "For Inf and Auto model\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb <model>_prs \\\n",
    "    --cwd $work_dir \\\n",
    "    --ss <work_dir/sumstats.snp_matched.qc.rds> \\\n",
    "    --target-geno <work_dir/target.snp_intersect.extracted.rds> \\\n",
    "    --ldsc <work_dir/sumstats.snp_matched.qc.ld.rds>\n",
    "```\n",
    "\n",
    "\n",
    "For Grid model\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb grid_prs \\\n",
    "    --cwd $work_dir \\\n",
    "    --ss <work_dir/sumstats.snp_matched.qc.rds> \\\n",
    "    --target-geno <work_dir/target.snp_intersect.extracted.rds> \\\n",
    "    --ldsc <work_dir/sumstats.snp_matched.qc.ld.rds> \\\n",
    "    --phenoFile <path/to/phenofile> \\\n",
    "    --covFile <path/to/covariatefile> \\\n",
    "    --response <continuous/binary>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Predict phenotype\n",
    "\n",
    "Predict phenotypes in target data and evaluate the performance of prediction using MSE and $R^2$.\n",
    "\n",
    "#### Output\n",
    "\n",
    "* Linear/logistic model results saved to `work_dir/pheno.baseline.rds` or `work_dir/pheno.sumstats.snp_matched.<model>.rds`.\n",
    "* Goodness of fit $R^2$, MSE and residual plot saved to `work_dir/pheno.baseline.pdf` or `work_dir/pheno.sumstats.snp_matched.<model>.pdf`.\n",
    "\n",
    "Baseline model: Traits ~ Sex + Age\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb pred_eval \\\n",
    "    --cwd $work_dir \\\n",
    "    --phenoFile <path/to/phenofile> \\\n",
    "    --covFile <path/to/covariatefile> \\\n",
    "    --response <continuous/binary>\n",
    "```\n",
    "\n",
    "Ldpred model: Traits ~ Sex + Age + PRS\n",
    "\n",
    "```\n",
    "sos run ldpred.ipynb pred_eval \\\n",
    "    --cwd $work_dir \\\n",
    "    --prs <work_dir/sumstats.snp_matched.model_prs.rds> \\\n",
    "    --phenoFile <path/to/phenofile> \\\n",
    "    --covFile <path/to/covariatefile> \\\n",
    "    --response <continuous/binary>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example analysis\n",
    "\n",
    "See notebook [HDL_exmple.ipynb](HDL_example.html) for demonstration of results of traits HDL prediction using MVP summary statistics, 1000G as reference panel and UK biobank data as target data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run ldpred.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  preprocess\n",
      "  snp_intersect\n",
      "  snp_subset\n",
      "  snp_match\n",
      "  sumstats_qc\n",
      "  ldsc\n",
      "  prs_core\n",
      "  inf_prs\n",
      "  grid_prs\n",
      "  auto_prs\n",
      "  pred_eval\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --name  f\"{cwd:b}\"\n",
      "\n",
      "                        A string to identify your analysis run\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "\n",
      "Sections\n",
      "  preprocess_1:         Filter SNPs and select individuals\n",
      "    Workflow Options:\n",
      "      --genoFiles  paths\n",
      "\n",
      "                        PLINK binary files\n",
      "      --remove-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to remove (format FID, IID)\n",
      "      --keep-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "      --keep-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to keep\n",
      "      --maf-filter 0.01 (as float)\n",
      "                        minimum MAF filter to use. Notice that PLINK default is\n",
      "                        0.01\n",
      "      --maf-max-filter 0.0 (as float)\n",
      "                        maximum MAF filter to use\n",
      "      --geno-filter 0.01 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.02 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 5e-08 (as float)\n",
      "                        HWE filter\n",
      "  preprocess_2:\n",
      "  snp_intersect_1:      SNP intersect of summary stats and genotype data\n",
      "    Workflow Options:\n",
      "      --genoFiles  paths\n",
      "\n",
      "                        PLNIK binary files\n",
      "      --ss VAL (as path, required)\n",
      "                        summary stats file\n",
      "  snp_intersect_2:\n",
      "    Workflow Options:\n",
      "      --genoFiles  paths\n",
      "\n",
      "                        PLNIK binary files\n",
      "  snp_subset:\n",
      "    Workflow Options:\n",
      "      --genoObj VAL (as path, required)\n",
      "      --keep-variants VAL (as path, required)\n",
      "  snp_match:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        summary stats file\n",
      "      --reference-geno VAL (as path, required)\n",
      "  sumstats_qc:\n",
      "    Workflow Options:\n",
      "      --sdy VAL (as float, required)\n",
      "                        standard deviation of y; set it to 2 for binary traits\n",
      "      --ss VAL (as path, required)\n",
      "                        summary stats file, snp matched\n",
      "      --reference-geno VAL (as path, required)\n",
      "                        reference data geno object previously generated\n",
      "  ldsc:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        summary stats file\n",
      "      --reference-geno VAL (as path, required)\n",
      "  prs_core:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        rds file for summary stats\n",
      "      --target-geno VAL (as path, required)\n",
      "                        rds file of target data generated from bed file\n",
      "      --ldsc VAL (as path, required)\n",
      "                        ldsc file\n",
      "      --method VAL (as str, required)\n",
      "                        method: choose from inf, grid, and auto\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        phenotype file, must have a header\n",
      "      --covFile VAL (as path, required)\n",
      "                        covariates file, must have a header\n",
      "      --response VAL (as str, required)\n",
      "                        either continuous or binary\n",
      "      --suffix prs\n",
      "  inf_prs:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        rds file for summary stats\n",
      "      --target-geno VAL (as path, required)\n",
      "                        rds file of target data generated from bed file\n",
      "      --ldsc VAL (as path, required)\n",
      "                        ldsc file\n",
      "  grid_prs:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        rds file for summary stats\n",
      "      --target-geno VAL (as path, required)\n",
      "                        rds file of target data generated from bed file\n",
      "      --ldsc VAL (as path, required)\n",
      "                        ldsc file\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        phenotype file, must have a header\n",
      "      --covFile VAL (as path, required)\n",
      "                        covariates file, must have a header\n",
      "      --response VAL (as str, required)\n",
      "                        either continuous or binary\n",
      "  auto_prs:\n",
      "    Workflow Options:\n",
      "      --ss VAL (as path, required)\n",
      "                        rds file for summary stats\n",
      "      --target-geno VAL (as path, required)\n",
      "                        rds file of target data generated from bed file\n",
      "      --ldsc VAL (as path, required)\n",
      "                        ldsc file\n",
      "  pred_eval:\n",
      "    Workflow Options:\n",
      "      --prs . (as path)\n",
      "                        rds file for PRS\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        phenotype file, must have a header\n",
      "      --covFile . (as path)\n",
      "                        covariates file, must have a header\n",
      "      --response VAL (as str, required)\n",
      "                        either continuous or binary\n"
     ]
    }
   ],
   "source": [
    "sos run ldpred.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# A string to identify your analysis run\n",
    "parameter: name = f\"{cwd:b}\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Preliminary quality control and preprocessing for genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[preprocess_1 (basic QC filters)]\n",
    "# PLINK binary files\n",
    "parameter: genoFiles = paths\n",
    "# The path to the file that contains the list of samples to remove (format FID, IID)\n",
    "parameter: remove_samples = path('.')\n",
    "# The path to the file that contains the list of samples to keep (format FID, IID)\n",
    "parameter: keep_samples = path('.')\n",
    "# The path to the file that contains the list of variants to keep\n",
    "parameter: keep_variants = path('.')\n",
    "# minimum MAF filter to use. Notice that PLINK default is 0.01\n",
    "parameter: maf_filter = 0.01\n",
    "# maximum MAF filter to use\n",
    "parameter: maf_max_filter = 0.0\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.01\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.02\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 5e-08\n",
    "\n",
    "fail_if(not (keep_samples.is_file() or keep_samples == path('.')), msg = f'Cannot find ``{keep_samples}``')\n",
    "fail_if(not (keep_variants.is_file() or keep_variants == path('.')), msg = f'Cannot find ``{keep_variants}``')\n",
    "fail_if(not (remove_samples.is_file() or remove_samples == path('.')), msg = f'Cannot find ``{remove_samples}``')\n",
    "\n",
    "input: genoFiles, group_by=1\n",
    "output: f'{cwd}/{_input:bn}.{name}{\".extracted\" if keep_variants.is_file() else \"\"}.bed'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter >= 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter >= 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter >= 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % keep_variants) if keep_variants.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[preprocess_2 (convert PLNIK to bigsnpr format with missing data mean imputed)]\n",
    "input: group_by = 1, concurrent = False\n",
    "output: f\"{cwd:a}/{_input:bn}.bk\", f\"{cwd:a}/{_input:bn}.rds\"\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"${ }\"\n",
    "    rm -f ${_output}\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library(bigsnpr)\n",
    "    # generate .bk and .rds file for R code\n",
    "    dat = snp_readBed(${_input:r}, backingfile=${_output[0]:nr})\n",
    "    obj.bigSNP <- snp_attach(dat) \n",
    "    # get the CM information from 1000 Genome\n",
    "    # will download the 1000G file to the current directory (\".\")\n",
    "    obj.bigSNP$map$genetic.dist <- snp_asGeneticPos(obj.bigSNP$map$chromosome, obj.bigSNP$map$physical.pos, dir = ${cwd:r})\n",
    "    obj.bigSNP$genotypes = snp_fastImputeSimple(obj.bigSNP$genotypes, method = \"mean0\")\n",
    "    saveRDS(obj.bigSNP, file = \"${_output[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Find common SNPs among summary statistics, reference panel and test genotypes.\n",
    "\n",
    "1. Find common SNPs\n",
    "2. Get subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# SNP intersect of summary stats and genotype data\n",
    "[snp_intersect_1]\n",
    "# PLNIK binary files\n",
    "parameter: genoFiles = paths\n",
    "# summary stats file\n",
    "parameter: ss = path\n",
    "input: ss, [x.with_suffix(\".bim\") for x in genoFiles]\n",
    "output: substats = f\"{cwd:a}/{_input[0]:bn}.intersect.rds\",\n",
    "        snp = f\"{cwd:a}/{_input[0]:bn}.intersect.snplist\"\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    suppressMessages(library(tidyverse))\n",
    "    sumstats <- readRDS(${_input[0]:r})\n",
    "    geno_snps = lapply(c(${paths(_input[1:]):r,}), function(x) read.table(x, stringsAsFactors=F)[,2])\n",
    "    common_snp <- Reduce(intersect, c(list(sumstats$rsid), geno_snps))\n",
    "    # filter snps in sumstat\n",
    "    new_sumstats <- sumstats %>%\n",
    "        filter(rsid %in% common_snp)\n",
    "    print(paste(\"There are\", length(common_snp), \"shared SNPs.\"))\n",
    "    saveRDS(new_sumstats, file = \"${_output[\"substats\"]}\")\n",
    "    write.table(common_snp, file = \"${_output[\"snp\"]}\", sep = \" \", \n",
    "                row.names = FALSE, col.names = FALSE, quote=FALSE)\n",
    "  \n",
    "[snp_intersect_2]\n",
    "# PLNIK binary files\n",
    "parameter: genoFiles = paths\n",
    "output: [(f\"{cwd}/{x:bn}.snp_intersect.extracted.bed\", f\"{cwd}/{x:bn}.snp_intersect.extracted.rds\") for x in genoFiles]\n",
    "sos_run(\"preprocess\", genoFiles=genoFiles, keep_variants=_input['snp'], \n",
    "                    maf_filter=0, geno_filter=1, mind_filter=1, hwe_filter=-9, \n",
    "                    cwd=cwd, name=\"snp_intersect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[snp_subset]\n",
    "parameter: genoObj = path\n",
    "parameter: keep_variants = path\n",
    "input: genoObj, keep_variants\n",
    "output: f\"{cwd}/{_input[0]:bn}.{name}.subset.rds\"\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'   \n",
    "    library(bigsnpr)\n",
    "    dat <- readRDS(\"${_input[0]}\")\n",
    "    snps <- as.vector(unlist(data.table::fread(\"${_input[1]}\",header=F)))\n",
    "    snp_subset(dat,  ind.col = match(snps, dat$map$marker.ID), backingfile = ${_output:nr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Convert reference genotype to bigsnpr format and get the genetic distance cM information\n",
    "\n",
    "Will take a while to download the genetic distance database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Allele harmonizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[snp_match]\n",
    "# summary stats file\n",
    "parameter: ss = path\n",
    "parameter: reference_geno = path\n",
    "input: ss, reference_geno\n",
    "output: match = f'{cwd:a}/{_input[0]:bn}.snp_matched.rds',\n",
    "        snplist = f'{cwd:a}/{_input[0]:bn}.snp_matched.snplist'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'   \n",
    "    library(bigsnpr)\n",
    "    sumstats <- readRDS(\"${_input[0]}\")\n",
    "    # now attach the genotype object\n",
    "    obj.bigSNP <- snp_attach(\"${_input[1]}\")\n",
    "    # extract the SNP information from the genotype\n",
    "    map <- obj.bigSNP$map[-(2:3)]\n",
    "    names(map) <- c(\"chr\", \"pos\", \"a1\", \"a0\")  \n",
    "    # perform SNP matching\n",
    "    updated_ss <- snp_match(sumstats, map)\n",
    "    write.table(updated_ss$rsid, file = \"${_output[\"snplist\"]}\", sep = \" \", \n",
    "            row.names = FALSE, col.names = FALSE,quote=FALSE)\n",
    "    saveRDS(updated_ss, file = \"${_output[\"match\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Summary statistics quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sumstats_qc]\n",
    "# standard deviation of y; set it to 2 for binary traits\n",
    "parameter: sdy = float\n",
    "# summary stats file, snp matched\n",
    "parameter: ss = path\n",
    "# reference data geno object previously generated\n",
    "parameter: reference_geno = path\n",
    "input: ss, reference_geno\n",
    "\n",
    "output: qc_plot = f'{cwd}/{_input[0]:bn}.qc.png', \n",
    "        snplist = f'{cwd}/{_input[0]:bn}.qc.snplist',\n",
    "        qc_res = f'{cwd}/{_input[0]:bn}.qc.rds'\n",
    "\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library(bigsnpr)\n",
    "    suppressMessages(library(tidyverse))\n",
    "    attach(readRDS(\"${_input[1]}\"))\n",
    "    info_snp = readRDS(${_input[0]:r})\n",
    "    NCORES = bigparallelr::nb_cores()\n",
    "    NCORES = tryCatch({bigparallelr::assert_cores(NCORES); NCORES }, error = function(e) 1)\n",
    "    ind.val = 1:nrow(genotypes)\n",
    "    sd <- sqrt(big_colstats(genotypes, ind.val, ncores = NCORES)$var)  \n",
    "    sd_val <- sd[info_snp$`_NUM_ID_`]\n",
    "\n",
    "    sdy = ${sdy}\n",
    "    sd_ss <- with(info_snp, sdy / sqrt(n_eff * beta_se^2))\n",
    "\n",
    "    is_bad <- sd_ss < (0.5 * sd_val) | \n",
    "            sd_ss > (sd_val + 0.1) |\n",
    "            sd_ss < 0.1 | \n",
    "            sd_val < 0.05\n",
    "      \n",
    "    p = qplot(sd_val, sd_ss, color = is_bad, alpha = I(0.5)) +\n",
    "      theme_bigstatsr() +\n",
    "      coord_equal() +\n",
    "      scale_color_viridis_d(direction = -1) +\n",
    "      geom_abline(linetype = 2, color = \"red\") +\n",
    "      labs(x = \"Standard deviations in the validation set\",\n",
    "           y = \"Standard deviations derived from the summary statistics\",\n",
    "           color = \"Removed?\")\n",
    "    png(\"${_output[\"qc_plot\"]}\")\n",
    "    print(p)\n",
    "    dev.off()\n",
    "      \n",
    "    n = nrow(info_snp)\n",
    "    print(paste(length(which(is_bad==\"TRUE\")), \"over\", n, \"were removed in summary statistics QC.\"))\n",
    "           \n",
    "    info_snp = info_snp[!is_bad, ]\n",
    "    \n",
    "    write.table(info_snp$rsid, file = ${_output[\"snplist\"]:r}, sep = \" \", \n",
    "            row.names = FALSE, col.names = FALSE,quote=FALSE)\n",
    "    saveRDS(info_snp, file=${_output[\"qc_res\"]:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Calculate LD matrix and perform LD score regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ldsc]\n",
    "# summary stats file\n",
    "parameter: ss = path\n",
    "parameter: reference_geno = path\n",
    "input: ss, reference_geno\n",
    "output: f'{cwd}/{_input[0]:bn}.ld.rds'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library(bigsnpr)\n",
    "    library(data.table)\n",
    "    library(bigsparser)\n",
    "    suppressMessages(library(tidyverse))\n",
    "    info_snp = readRDS(\"${_input[0]}\")\n",
    "    attach(readRDS(\"${_input[1]}\"))\n",
    "    NCORES = bigparallelr::nb_cores()\n",
    "    NCORES = tryCatch({bigparallelr::assert_cores(NCORES); NCORES }, error = function(e) 1)\n",
    "    # Initialize variables for storing the LD score and LD matrix\n",
    "    corr = NULL\n",
    "    ld = NULL\n",
    "    # Open a temporary file\n",
    "    tmp = tempfile(tmpdir = \"${cwd}/ld-cache\")\n",
    "    on.exit(file.remove(paste0(tmp, \".sbk\")), add = TRUE)\n",
    "    \n",
    "    for (chr in 1:22) {\n",
    "      # Extract SNPs that are included in the chromosome\n",
    "      ind.chr <- which(info_snp$chr == chr)\n",
    "      ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr]\n",
    "      # Calculate the LD\n",
    "      corr0 <- snp_cor(\n",
    "        genotypes,\n",
    "        ind.col = ind.chr2,\n",
    "        ncores = NCORES,\n",
    "        infos.pos = map$genetic.dist[ind.chr2],\n",
    "        size = 3 / 1000\n",
    "      )\n",
    "      if (chr == 1) {\n",
    "        ld <- Matrix::colSums(corr0^2)\n",
    "        corr <- as_SFBM(corr0, tmp)\n",
    "      } else {\n",
    "        ld <- c(ld, Matrix::colSums(corr0^2))\n",
    "        corr$add_columns(corr0, nrow(corr))\n",
    "      }\n",
    "    }\n",
    "       \n",
    "    ldsc <- snp_ldsc(ld, \n",
    "                    length(ld), \n",
    "                    chi2 = (info_snp$beta / info_snp$beta_se)^2,\n",
    "                    sample_size = info_snp$n_eff,\n",
    "                    blocks = NULL)\n",
    "    saveRDS(list(ld=ld,corr=corr,ldsc=ldsc), file = \"${_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get adjusted betas and PRS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[prs_core]\n",
    "# rds file for summary stats\n",
    "parameter: ss = path\n",
    "# rds file of target data generated from bed file\n",
    "parameter: target_geno = path\n",
    "# ldsc file\n",
    "parameter: ldsc = path\n",
    "# method: choose from inf, grid, and auto\n",
    "parameter: method = str\n",
    "# phenotype file, must have a header\n",
    "parameter: phenoFile = path\n",
    "# covariates file, must have a header\n",
    "parameter: covFile = path\n",
    "# either continuous or binary\n",
    "parameter: response = str\n",
    "parameter: suffix = \"prs\"\n",
    "input: ss, ldsc, target_geno\n",
    "output: f'{cwd}/{_input[0]:bn}.{suffix}.rds'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    library(bigsnpr)\n",
    "    library(data.table)\n",
    "    suppressMessages(library(tidyverse))\n",
    "\n",
    "    ## load correlation data ##\n",
    "    ldsc = readRDS(\"${_input[1]}\")\n",
    "    ## load summary stats ##\n",
    "    info_snp = readRDS(\"${_input[0]}\")\n",
    "    ## load test data ##\n",
    "    obj.test <- snp_attach(\"${_input[2]}\")\n",
    "    ind.test = 1:nrow(obj.test$genotypes)\n",
    "    map2 <- obj.test$map[-3]\n",
    "    names(map2) <- c(\"chr\", \"rsid\", \"pos\", \"a0\", \"a1\")\n",
    "    info_snp_test = snp_match(info_snp[, -which(names(info_snp) %in% c(\"_NUM_ID_.ss\",\"_NUM_ID_\"))], map2, \n",
    "                          join_by_pos = FALSE)\n",
    "    rsid = intersect(info_snp_test$rsid,info_snp$rsid)\n",
    "    index = which(info_snp$rsid %in% rsid)\n",
    "    print(paste(length(index), \"SNPs are used for PRS calculations\"))\n",
    "    NCORES = bigparallelr::nb_cores()\n",
    "    NCORES = tryCatch({bigparallelr::assert_cores(NCORES); NCORES }, error = function(e) 1)\n",
    "    df_beta <- info_snp[,c(\"beta\", \"beta_se\", \"n_eff\", \"_NUM_ID_\")]\n",
    "\n",
    "    if (\"${method}\" == 'inf') {\n",
    "        ## adjusted beta ##\n",
    "        adj_beta <- snp_ldpred2_inf(ldsc$corr, df_beta, h2 = ldsc$ldsc['h2'])\n",
    "        ## Predict PRS ##\n",
    "        prs_pred <- big_prodVec(obj.test$genotypes, adj_beta[index], \n",
    "        ind.row = ind.test, ind.col = info_snp_test$`_NUM_ID_`)\n",
    "        saveRDS(list(beta = adj_beta, prs = prs_pred), file = \"${_output}\")\n",
    "    } else if (\"${method}\" == 'grid') {\n",
    "        response = \"${response}\"\n",
    "        `%notin%` <- Negate(`%in%`)\n",
    "        if (response %notin% c(\"continuous\", \"binary\")) stop(\"--response variable should be either 'continous' or 'binary'\")\n",
    "        # Prepare data for grid model\n",
    "        p_seq <- signif(seq_log(1e-4, 1, length.out = 10), 2)\n",
    "        h2_seq <- round(ldsc$ldsc['h2'] * c(0.7, 1, 1.4), 4)\n",
    "        grid.param <-\n",
    "            expand.grid(p = p_seq,\n",
    "                    h2 = h2_seq,\n",
    "                    sparse = c(FALSE, TRUE))\n",
    "\n",
    "        # Get adjusted beta from grid model\n",
    "        gird_beta <- snp_ldpred2_grid(ldsc$corr, df_beta, grid.param, ncores = NCORES)\n",
    "\n",
    "        # Prediction\n",
    "        grid_pred <- big_prodMat(obj.test$genotypes, gird_beta[index,], \n",
    "        ind.row = ind.test, ind.col = info_snp_test$`_NUM_ID_`)\n",
    "\n",
    "        ## find best betas\n",
    "        # load covariates data\n",
    "        covariates = read.table(\"${covFile}\", header = T)\n",
    "        y = read.table(\"${phenoFile}\", header = T)\n",
    "        data = cbind(covariates, y)\n",
    "\n",
    "        # split train (80%) and test data (20%)\n",
    "        set.seed(2021)\n",
    "        train.ind = sample(nrow(data), 0.8*nrow(data))\n",
    "        test.ind = setdiff(rows_along(data), train.ind) \n",
    "\n",
    "        # find best p and h2 \n",
    "        response = \"${response}\"\n",
    "        reg.formula <- paste(colnames(covariates), collapse = '+') %>%\n",
    "            paste0(colnames(y),\"~PRS+\", .) %>%\n",
    "            as.formula\n",
    "        if(response == \"continuous\"){\n",
    "            grid.model = big_univLinReg(as_FBM(grid_pred[train.ind,]), \n",
    "                        y[train.ind,1], covar = as.matrix(covariates[train.ind,]))\n",
    "        }\n",
    "        if(response == \"binary\"){\n",
    "            grid.model = big_univLogReg(as_FBM(grid_pred[train.ind,]), \n",
    "                        y[train.ind,1], covar = as.matrix(covariates[train.ind,]))\n",
    "        }\n",
    "\n",
    "        # find best betas according to z score\n",
    "        grid.param$score = grid.model$score\n",
    "        adj_beta <- grid.param %>%\n",
    "          mutate(id = row_number()) %>%\n",
    "          arrange(desc(abs(score))) %>%\n",
    "          slice(1) %>%\n",
    "          pull(id) %>%\n",
    "          gird_beta[, .]\n",
    "        prs_pred <- big_prodVec(obj.test$genotypes, adj_beta[index], \n",
    "            ind.row = ind.test, ind.col = info_snp_test$`_NUM_ID_`)\n",
    "\n",
    "        library(ggplot2)\n",
    "        ggplot(grid.param, aes(x = p, y = score, color = as.factor(h2))) +\n",
    "          theme_bigstatsr() +\n",
    "          geom_point() +\n",
    "          geom_line() +\n",
    "          scale_x_log10(breaks = 10^(-5:0), minor_breaks = grid.param$p) +\n",
    "          facet_wrap(~ sparse, labeller = label_both) +\n",
    "          labs(y = \"Z-Score\", color = \"h2\") +\n",
    "          theme(legend.position = \"top\", panel.spacing = unit(1, \"lines\"))\n",
    "        ggsave(\"${_output:n}.png\")\n",
    "      saveRDS(list(beta = adj_beta, prs = prs_pred, grid.param = grid.param), file = \"${_output}\")\n",
    "    } else if (\"${method}\" == 'auto') {\n",
    "        # Get adjusted beta from the auto model\n",
    "        multi_auto <- snp_ldpred2_auto(\n",
    "            ldsc$corr,\n",
    "            df_beta,\n",
    "            h2_init = ldsc$ldsc['h2'],\n",
    "            vec_p_init = seq_log(1e-4, 0.9, length.out = 30),\n",
    "            ncores = NCORES\n",
    "        )\n",
    "        beta_auto <- sapply(multi_auto, function(auto)\n",
    "            auto$beta_est)\n",
    "        pred_auto <- big_prodMat(obj.test$genotypes, beta_auto[index,], \n",
    "        ind.row = ind.test, ind.col = info_snp_test$`_NUM_ID_`) \n",
    "\n",
    "        ## Find best beta (take average)\n",
    "        sc <- apply(pred_auto, 2, sd)\n",
    "        keep <- abs(sc - median(sc)) < 3 * mad(sc)\n",
    "        adj_beta <- rowMeans(beta_auto[, keep])\n",
    "        prs_pred <- rowMeans(pred_auto[, keep])\n",
    "\n",
    "        auto <- multi_auto[[1]]\n",
    "        plot_grid(\n",
    "          qplot(y = auto$path_p_est) +\n",
    "            theme_bigstatsr() +\n",
    "            geom_hline(yintercept = auto$p_est, col = \"blue\") +\n",
    "            scale_y_log10() +\n",
    "            labs(y = \"p\"),\n",
    "          qplot(y = auto$path_h2_est) +\n",
    "            theme_bigstatsr() +\n",
    "            geom_hline(yintercept = auto$h2_est, col = \"blue\") +\n",
    "            labs(y = \"h2\"),\n",
    "          ncol = 1, align = \"hv\"\n",
    "        )\n",
    "        ggsave(\"${_output:n}.png\")\n",
    "        saveRDS(list(beta = adj_beta, prs = prs_pred), file = \"${_output}\")\n",
    "    } else {\n",
    "      stop(\"Wrong --method specified\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Infinitesimal model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[inf_prs]\n",
    "# rds file for summary stats\n",
    "parameter: ss = path\n",
    "# rds file of target data generated from bed file\n",
    "parameter: target_geno = path\n",
    "# ldsc file\n",
    "parameter: ldsc = path\n",
    "input: ss, target_geno, ldsc\n",
    "output: f'{cwd}/{_input[0]:bn}.inf_prs.rds'\n",
    "sos_run(\"prs_core\", ss=ss,target_geno=target_geno, ldsc=ldsc, method=\"inf\", phenoFile=\".\", covFile=\".\", response=\"\", suffix=\"inf_prs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Grid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[grid_prs]\n",
    "# rds file for summary stats\n",
    "parameter: ss = path\n",
    "# rds file of target data generated from bed file\n",
    "parameter: target_geno = path\n",
    "# ldsc file\n",
    "parameter: ldsc = path\n",
    "# phenotype file, must have a header\n",
    "parameter: phenoFile = path\n",
    "# covariates file, must have a header\n",
    "parameter: covFile = path\n",
    "# either continuous or binary\n",
    "parameter: response = str\n",
    "input: ss, target_geno, ldsc\n",
    "output: f'{cwd}/{_input[0]:bn}.grid_prs.rds'\n",
    "sos_run(\"prs_core\", ss=ss,target_geno=target_geno, ldsc=ldsc, method=\"grid\", phenoFile=phenoFile, covFile=covFile, response=response, suffix=\"grid_prs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Auto model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[auto_prs]\n",
    "# rds file for summary stats\n",
    "parameter: ss = path\n",
    "# rds file of target data generated from bed file\n",
    "parameter: target_geno = path\n",
    "# ldsc file\n",
    "parameter: ldsc = path\n",
    "input: ss, target_geno, ldsc\n",
    "output: f'{cwd}/{_input[0]:bn}.auto_prs.rds'\n",
    "sos_run(\"prs_core\", ss=ss,target_geno=target_geno, ldsc=ldsc,method=\"auto\", phenoFile=\".\", covFile=\".\", response=\"\", suffix=\"auto_prs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Predict phenotype\n",
    "\n",
    "**FIXME: in the future we should do K-fold cross validation and summarize average results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pred_eval]\n",
    "# rds file for PRS\n",
    "parameter: prs = path(\".\")\n",
    "# phenotype file, must have a header\n",
    "parameter: phenoFile = path\n",
    "# covariates file, must have a header\n",
    "parameter: covFile = path(\".\")\n",
    "# either continuous or binary\n",
    "parameter: response = str\n",
    "\n",
    "fail_if(not (covFile.is_file() or covFile == path('.')), msg = f'Cannot find ``{covFile}``')\n",
    "fail_if(not (prs.is_file() or prs == path('.')), msg = f'Cannot find ``{prs}``')\n",
    "fail_if(not (prs.is_file() or covFile.is_file()), msg = 'At least one of ``--prs`` or ``--covFile`` has to be specified')\n",
    "\n",
    "if not prs.is_file():\n",
    "    # fake a PRS file name to get proper filename for later\n",
    "    prs = path(\"baseline.out\")\n",
    "input: phenoFile\n",
    "output: f'{cwd}/{_input:bn}.{prs:bn}.rds'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    options(digits=7)\n",
    "    library(bigsnpr)\n",
    "    suppressMessages(library(gplots))\n",
    "    suppressMessages(library(tidyverse))\n",
    "    dat = read.table(\"${_input}\", header = T)\n",
    "    model = paste0(colnames(dat),\"~\")\n",
    "    if (${\"T\" if covFile.is_file() else \"F\"}) {\n",
    "        covariates = read.table(\"${covFile}\", header = T)\n",
    "        dat = cbind(dat,covariates)\n",
    "        model = paste(model, paste(colnames(covariates), collapse = '+'))\n",
    "    }\n",
    "    if (${\"T\" if prs.is_file() else \"F\"}) {\n",
    "      dat$PRS = readRDS(\"${prs}\")$prs\n",
    "      model = paste(model, \"+PRS\")\n",
    "    }\n",
    "    # split train (80%) and test data (20%)\n",
    "    set.seed(2021)\n",
    "    train.ind = sample(nrow(dat), 0.8*nrow(dat))\n",
    "    test.ind = setdiff(rows_along(dat), train.ind)\n",
    "    # fit model\n",
    "    response = \"${response}\"\n",
    "    if(response==\"continuous\"){\n",
    "      fitted = model %>%\n",
    "        as.formula %>%\n",
    "        lm(.,data = dat[train.ind,])\n",
    "    } else if(response==\"binary\"){\n",
    "      fitted = model %>%\n",
    "        as.formula %>%\n",
    "        glm(.,data = dat[train.ind,], family = binomial)\n",
    "    } else {\n",
    "      stop(\"response parameter should be continuous or binary\")\n",
    "    }\n",
    "       \n",
    "    # Predict\n",
    "    pheno_pred = predict(fitted, dat[test.ind,])\n",
    "    residual = pheno_pred-dat[test.ind,1]\n",
    "    tbl = tibble(model = c(\"model${prs:bnx}\"), \n",
    "                   R2 = round(summary(fitted)$adj.r.squared,5),\n",
    "                   MSE = round(mean(residual^2),5))    \n",
    "    # save output\n",
    "    pdf(file = \"${_output:n}.pdf\",width=10, height=10,)   \n",
    "    textplot(print(tbl))\n",
    "    title(\"Goodness of fit and MSE\")\n",
    "    hist(residual,prob = T)\n",
    "    plot(residual, xlab = \"individuals\", main = \"Residual Plot\")\n",
    "    abline(h=0, lty = 2)\n",
    "    dev.off()\n",
    "    \n",
    "    saveRDS(list(fitted = fitted, summary = tbl, predicted = pheno_pred, residual = residual), file = \"${_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
