{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Multivariate prediction workflow\n",
    "\n",
    "This notebook applies mr.mash on data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "RDS format of a list of objects, in which case you can specify the names of objects corresponding to the quantities `X`, `Y`, etc. Optionally univariate summary statistics information are provided to compute scaling factor of the prior (summary statistics will be computed on the fly if not provided).\n",
    "\n",
    "**FIXME: need to document the input data structure**\n",
    "**Also for prior files should they be stored similarly with data for each fold as `fold_??` tables**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis unit we output:\n",
    "\n",
    "1. Analysis results in RDS format\n",
    "2. Default visualization plots\n",
    "\n",
    "**FIXME: at this point we dont have output figure yet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis examples\n",
    "\n",
    "```\n",
    "sos run /project/mstephens/fmorgante/bioworkflows/multivariate-prediction/mrmash.ipynb joint_weights_update \\\n",
    "    --analysis-units ../data/gtex-v8-manifest-2ormore-tissues-nopath-nosuffix-test.txt \\\n",
    "    --data-dir ../data/cis_eqtl_analysis_ready  \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name fold_1 \\\n",
    "    --wd ../output/gtex_mr_mash_analysis/prediction \\\n",
    "    --prior-grid ../output/gtex_mr_mash_analysis/grid/fold_1_grid.rds \\\n",
    "    --prior-matrices ../output/gtex_mr_mash_analysis/data_driven_matrices/output/fold_1.ted_unconstrained.rds \\\n",
    "    --sample-partition ../data/gtex-v8-ids-folds.txt \\\n",
    "    --fold 1 \\\n",
    "    -c midway2.yml -q midway2\n",
    "    \n",
    "sos run /project/mstephens/fmorgante/bioworkflows/multivariate-prediction/mrmash.ipynb mr_mash \\\n",
    "    --analysis-units ../data/gtex-v8-manifest-2ormore-tissues-nopath-nosuffix-test.txt \\\n",
    "    --data-dir ../data/cis_eqtl_analysis_ready  \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name fold_1 \\\n",
    "    --wd ../output/gtex_mr_mash_analysis/prediction \\\n",
    "    --prior-grid ../output/gtex_mr_mash_analysis/grid/fold_1_grid.rds \\\n",
    "    --prior-matrices ../output/gtex_mr_mash_analysis/data_driven_matrices/output/fold_1.ted_unconstrained.rds \\\n",
    "    --prior-weights ../output/gtex_mr_mash_analysis/grid/fold_1_updated_weights.rds \\\n",
    "    --sample-partition ../data/gtex-v8-ids-folds.txt \\\n",
    "    --fold 1 \\\n",
    "    -c midway2.yml -q midway2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# single column file each line is the data filename\n",
    "parameter: analysis_units = path\n",
    "# Path to data directory\n",
    "parameter: data_dir = path\n",
    "# data file suffix\n",
    "parameter: data_suffix = str\n",
    "# Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "# An identifier for your run of analysis\n",
    "parameter: name = str\n",
    "# Only analyze `cis` variants -- cis = N means using N variants around the center column of X matrix  \n",
    "parameter: cis = 'NULL'\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = [f\"{data_dir:a}/{x}.{data_suffix}\" for x in regions if path(f\"{data_dir:a}/{x}.{data_suffix}\").exists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mr_mash, joint_weights_update_1]\n",
    "# Path to prior data file: an RDS file with `U` for prior matrices\n",
    "parameter: prior_matrices = path('.')\n",
    "# Path to prior grid data file: an RDS file with scaling factors\n",
    "parameter: prior_grid = path('.')\n",
    "# Path to prior weights data file: an RDS file with prior weights\n",
    "parameter: prior_weights = path('.')\n",
    "# Path to residual cor/cov data file\n",
    "parameter: resid_cor = path('.')\n",
    "# Path to summary statistics directory\n",
    "parameter: sumstats_dir = path('.')\n",
    "# Path to summary statistics directory\n",
    "parameter: sample_partition = path\n",
    "parameter: fold = 1\n",
    "parameter: imiss = 0.05\n",
    "parameter: maf = 0.05\n",
    "parameter: var_cutoff = 0.05\n",
    "parameter: nthreads = 1\n",
    "parameter: n_nonmiss_Y = 100\n",
    "parameter: canonical_mats = \"FALSE\"\n",
    "parameter: standardize = \"TRUE\"\n",
    "parameter: update_w0 = \"TRUE\"\n",
    "parameter: w0_threshold = 0.0\n",
    "parameter: update_V = \"TRUE\"\n",
    "parameter: update_V_method = \"full\"\n",
    "parameter: B_init_method = \"enet\"\n",
    "parameter: max_iter = 5000\n",
    "parameter: tol = 1e-2\n",
    "parameter: verbose = \"FALSE\"\n",
    "parameter: save_model = \"FALSE\"\n",
    "parameter: glmnet_pred = \"FALSE\"\n",
    "analysis_stage = \"first_pass\" if not prior_weights.is_file() else \"second_pass\"\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/fold_{fold}/{_input:bn}_{name}_mrmash.{analysis_stage}.rds'\n",
    "task: trunk_workers = 2, trunk_size = 18, walltime = '2h', mem = '10G', cores = nthreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:n}.stdout\", stderr = f\"{_output[0]:n}.stderr\"\n",
    "\n",
    "    options(stringsAsFactors = FALSE)\n",
    "\n",
    "    set.seed(1)\n",
    "\n",
    "    ###Set some parameter variables (These should be set in the SoS script)\n",
    "    fold <- ${fold}\n",
    "    nthreads <- ${nthreads}\n",
    "    missing_rate_cutoff <- ${imiss}\n",
    "    maf_cutoff <- ${maf}\n",
    "    var_cutoff <- ${var_cutoff}\n",
    "    n_nonmiss_Y <- ${n_nonmiss_Y}\n",
    "    canonical_mats <- ${canonical_mats}\n",
    "    standardize <- ${standardize}\n",
    "    update_w0 <- ${update_w0}\n",
    "    w0_threshold <- ${w0_threshold}\n",
    "    update_V <- ${update_V}\n",
    "    update_V_method <- \"${update_V_method}\"\n",
    "    B_init_method <- \"${B_init_method}\"\n",
    "    max_iter <- ${max_iter}\n",
    "    tol <- ${tol}\n",
    "    verbose <- ${verbose}\n",
    "    save_model <- ${save_model}\n",
    "    glmnet_pred <- ${glmnet_pred}\n",
    "  \n",
    "    ###\n",
    "    # Utility functions\n",
    "    ###\n",
    "\n",
    "    ###Functions to compute MAF, missing genotype rate, impute missing, and filter X accordingly \n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "\n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "\n",
    "    compute_non_missing_y <- function(y){\n",
    "      nonmiss <- sum(!is.na(y))\n",
    "      return(nonmiss)\n",
    "    }\n",
    "\n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh, var_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      X <- mean_impute(X)\n",
    "      rm_col <- which(matrixStats::colVars(X) < var_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(X)\n",
    "    }\n",
    "\n",
    "    filter_Y <- function(Y, n_nonmiss){\n",
    "      rm_col <- which(apply(Y, 2, compute_non_missing_y) < n_nonmiss)\n",
    "      if (length(rm_col)) Y <- Y[, -rm_col]\n",
    "      return(Y)\n",
    "    }\n",
    "\n",
    "    ###Function to compute the grid\n",
    "    autoselect_mixsd <- function(data, mult=2){\n",
    "      include <- !(data$Shat==0 | !is.finite(data$Shat) | is.na(data$Bhat))\n",
    "      gmax <- grid_max(data$Bhat[include], data$Shat[include])\n",
    "      gmin <- grid_min(data$Bhat[include], data$Shat[include])\n",
    "      if (mult == 0) {\n",
    "        return(c(0, gmax/2))\n",
    "      }\n",
    "      else {\n",
    "        npoint = ceiling(log2(gmax/gmin)/log2(mult))\n",
    "        return(mult^((-npoint):0) * gmax)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    ###Compute the minimum value for the grid\n",
    "    grid_min = function(Bhat,Shat){\n",
    "      min(Shat)\n",
    "    }\n",
    "\n",
    "    ###Compute the maximum value for the grid\n",
    "    grid_max = function(Bhat,Shat){\n",
    "      if (all(Bhat^2 <= Shat^2)) {\n",
    "        8 * grid_min(Bhat,Shat) # the unusual case where we don't need much grid\n",
    "      }  else {\n",
    "        2 * sqrt(max(Bhat^2 - Shat^2))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    ###Function to compute initial estimates of the coefficients from group-lasso\n",
    "    compute_coefficients_glasso <- function(X, Y, standardize, nthreads, Xnew=NULL, version=c(\"Rcpp\", \"R\")){\n",
    "\n",
    "      version <- match.arg(version)\n",
    "\n",
    "      n <- nrow(X)\n",
    "      p <- ncol(X)\n",
    "      r <- ncol(Y)\n",
    "      Y_has_missing <- any(is.na(Y))\n",
    "      tissue_names <- colnames(Y)\n",
    "\n",
    "      if(Y_has_missing){\n",
    "        ###Extract per-individual Y missingness patterns\n",
    "        Y_miss_patterns <- mr.mash.alpha:::extract_missing_Y_pattern(Y)\n",
    "\n",
    "        ###Compute V and its inverse\n",
    "        V <- mr.mash.alpha:::compute_V_init(X, Y, matrix(0, p, r), method=\"flash\")\n",
    "        Vinv <- chol2inv(chol(V))\n",
    "\n",
    "        ###Initialize missing Ys\n",
    "        muy <- colMeans(Y, na.rm=TRUE)\n",
    "        for(l in 1:r){\n",
    "          Y[is.na(Y[, l]), l] <- muy[l]\n",
    "        }\n",
    "\n",
    "        ###Compute expected Y (assuming B=0)\n",
    "        mu <- matrix(rep(muy, each=n), n, r)\n",
    "\n",
    "        ###Impute missing Ys \n",
    "        Y <- mr.mash.alpha:::impute_missing_Y(Y=Y, mu=mu, Vinv=Vinv, miss=Y_miss_patterns$miss, non_miss=Y_miss_patterns$non_miss, \n",
    "                                              version=version)$Y\n",
    "      }\n",
    "\n",
    "      ##Fit group-lasso\n",
    "      if(nthreads>1){\n",
    "        doMC::registerDoMC(nthreads)\n",
    "        paral <- TRUE\n",
    "      } else {\n",
    "        paral <- FALSE\n",
    "      }\n",
    "\n",
    "      cvfit_glmnet <- glmnet::cv.glmnet(x=X, y=Y, family=\"mgaussian\", alpha=1, standardize=standardize, parallel=paral)\n",
    "      coeff_glmnet <- coef(cvfit_glmnet, s=\"lambda.min\")\n",
    "\n",
    "      ##Build matrix of initial estimates for mr.mash\n",
    "      B <- matrix(as.numeric(NA), nrow=p, ncol=r)\n",
    "\n",
    "      for(i in 1:length(coeff_glmnet)){\n",
    "        B[, i] <- as.vector(coeff_glmnet[[i]])[-1]\n",
    "      }\n",
    "\n",
    "      ##Make predictions if requested\n",
    "      if(!is.null(Xnew)){\n",
    "        Yhat_glmnet <- drop(predict(cvfit_glmnet, newx=Xnew, s=\"lambda.min\"))\n",
    "        colnames(Yhat_glmnet) <- tissue_names\n",
    "        res <- list(Bhat=B, Ytrain=Y, Yhat_new=Yhat_glmnet)\n",
    "      } else {\n",
    "        res <- list(Bhat=B, Ytrain=Y)\n",
    "      }\n",
    "\n",
    "      return(res)\n",
    "    }\n",
    "\n",
    "    compute_coefficients_univ_glmnet <- function(X, Y, alpha, standardize, nthreads, Xnew=NULL){\n",
    "\n",
    "      r <- ncol(Y)\n",
    "\n",
    "      linreg <- function(i, X, Y, alpha, standardize, nthreads, Xnew){\n",
    "        if(nthreads>1){\n",
    "          doMC::registerDoMC(nthreads)\n",
    "          paral <- TRUE\n",
    "        } else {\n",
    "          paral <- FALSE\n",
    "        }\n",
    "\n",
    "        samples_kept <- which(!is.na(Y[, i]))\n",
    "        Ynomiss <- Y[samples_kept, i]\n",
    "        Xnomiss <- X[samples_kept, ]\n",
    "\n",
    "        cvfit <- glmnet::cv.glmnet(x=Xnomiss, y=Ynomiss, family=\"gaussian\", alpha=alpha, standardize=standardize, parallel=paral)\n",
    "        coeffic <- as.vector(coef(cvfit, s=\"lambda.min\"))\n",
    "        lambda_seq <- cvfit$lambda\n",
    "\n",
    "        ##Make predictions if requested\n",
    "        if(!is.null(Xnew)){\n",
    "          yhat_glmnet <- drop(predict(cvfit, newx=Xnew, s=\"lambda.min\"))\n",
    "          res <- list(bhat=coeffic, lambda_seq=lambda_seq, yhat_new=yhat_glmnet)\n",
    "        } else {\n",
    "          res <- list(bhat=coeffic, lambda_seq=lambda_seq)\n",
    "        }\n",
    "\n",
    "        return(res)\n",
    "      }\n",
    "\n",
    "      out <- lapply(1:r, linreg, X, Y, alpha, standardize, nthreads, Xnew)\n",
    "\n",
    "      Bhat <- sapply(out,\"[[\",\"bhat\")\n",
    "\n",
    "      if(!is.null(Xnew)){\n",
    "        Yhat_new <- sapply(out,\"[[\",\"yhat_new\")\n",
    "        colnames(Yhat_new) <- colnames(Y)\n",
    "        results <- list(Bhat=Bhat[-1, ], intercept=Bhat[1, ], Yhat_new=Yhat_new)\n",
    "      } else {\n",
    "        results <- list(Bhat=Bhat[-1, ], intercept=Bhat[1, ])\n",
    "      }\n",
    "\n",
    "      return(results)\n",
    "    }\n",
    "\n",
    "    load_prior_grid = function(prior_grid, sumstats=NULL) {\n",
    "      res <- tryCatch(readRDS(prior_grid), \n",
    "                       error = function(e) {\n",
    "                         return(NULL)\n",
    "                       },\n",
    "                       warning = function(w) {\n",
    "                         return(NULL)\n",
    "                     }\n",
    "        )\n",
    "       ###Compute prior covariance\n",
    "      if(is.null(res) && !is.null(sumstats)){\n",
    "        res <- autoselect_mixsd(sumstats, mult=sqrt(2))^2\n",
    "      }\n",
    "       return(res)\n",
    "    } \n",
    "  \n",
    "    ###Filter S0 and w0Drop mixture components with weight equal to 0\n",
    "    filter_S0_w0 <- function(S0, w0, thresh=.Machine$double.eps){\n",
    "      comps_to_keep <- which(w0 > thresh)\n",
    "      S0 <- S0[comps_to_keep]\n",
    "      w0 <- w0[comps_to_keep]\n",
    "      \n",
    "      return(list(S0=S0, w0=w0))\n",
    "    }\n",
    "\n",
    "    ###Filter data-driven matrices and summary stats based on tissues used\n",
    "    filter_datadriven_mats_and_sumstats <- function(Y, datadriven_mats, sumstats){\n",
    "      tissues_to_keep <- colnames(Y)\n",
    "      #Handle different data structure between udr and Bovy's ed\n",
    "      if(!is.list(datadriven_mats$U[[1]])){\n",
    "        datadriven_mats_filt <- lapply(datadriven_mats$U, function(x, to_keep){x[to_keep, to_keep]}, tissues_to_keep)\n",
    "      } else {\n",
    "        datadriven_mats_filt <- lapply(datadriven_mats$U, function(x, to_keep){x$mat[to_keep, to_keep]}, tissues_to_keep)\n",
    "      }\n",
    "      if(!is.null(sumstats)){\n",
    "        sumstats_filt <- lapply(sumstats[[1]], function(x, to_keep){x[, to_keep]}, tissues_to_keep)\n",
    "      }\n",
    "      \n",
    "      return(list(datadriven_mats_filt=datadriven_mats_filt, sumstats_filt=sumstats_filt))\n",
    "    }\n",
    "  \n",
    "    ###Split the data in training and test\n",
    "    split_data <- function(X, Y, gtex_ids_folds, fold){\n",
    "      test_ids <- gtex_ids_folds[which(gtex_ids_folds$fold == fold), \"id\"]\n",
    "      Xtrain <- X[!(rownames(X) %in% test_ids), ]\n",
    "      Ytrain <- Y[!(rownames(Y) %in% test_ids), ]\n",
    "      Xtest <- X[rownames(X) %in% test_ids, ]\n",
    "      Ytest <- Y[rownames(Y) %in% test_ids, ]\n",
    "      \n",
    "      return(Xtrain=Xtrain, Ytrain=Ytrain, Xtest=Xtest, Ytest=Ytest)\n",
    "    }\n",
    "\n",
    "    ###Compute prior weights from coefficients estimates\n",
    "    compute_w0 <- function(Bhat, ncomps){\n",
    "      prop_nonzero <- sum(rowSums(abs(Bhat))>0)/nrow(Bhat)\n",
    "      w0 <- c((1-prop_nonzero), rep(prop_nonzero/(ncomps-1), (ncomps-1)))\n",
    "      \n",
    "      return(w0)\n",
    "    }\n",
    "\n",
    "    ###Compute column sums of the posterior assignment probabilities\n",
    "    compute_posterior_weight_colsum <- function(w, selected_labels)\n",
    "      w1_colsums <- colSums(w)\n",
    "      if(!is.null(selected_labels)){\n",
    "        tmp <- rep(0, length(selected_labels))\n",
    "        names(tmp) <- selected_labels\n",
    "        tmp[which(labels %in% names(w1_colsums))] <- w1_colsums\n",
    "        w1_colsums <- tmp\n",
    "      }\n",
    "      return(w1_colsums)\n",
    "    }\n",
    "  \n",
    "    ###\n",
    "    # mr.mash code\n",
    "    ###\n",
    "  \n",
    "    ###Read in the data\n",
    "    dat <- readRDS(${_input:r})   \n",
    "    sumstats <- tryCatch(readRDS(\"${sumstats_dir}/${_input:bn}_sumstats_cv.rds\"), \n",
    "                     error = function(e) {\n",
    "                       return(NULL)\n",
    "                     },\n",
    "                     warning = function(w) {\n",
    "                       return(NULL)\n",
    "                     }\n",
    "    )\n",
    "    tryCatch({\n",
    "        datadriven_mats <- readRDS(${prior_matrices:r})\n",
    "      }, error = function(e) {\n",
    "        # FIXME: we can implement it and provide a warning instead\n",
    "        stop(\"Default prior is not yet implemented. Please provide a prior to use.\")\n",
    "    })\n",
    "    w0_init <- tryCatch(readRDS(${prior_weights:r}), \n",
    "                    error = function(e) {\n",
    "                      message(\"Prior weights not provided. Computing them from initial estimates of the coefficients.\")\n",
    "                      return(NULL)\n",
    "                    },\n",
    "                    warning=function(w){\n",
    "                      message(\"Prior weights not provided. Computing them from initial estimates of the coefficients.\")\n",
    "                      return(NULL)\n",
    "                    }\n",
    "    )\n",
    "    gtex_ids_folds <- read.table(${sample_partition:r}, header=TRUE, sep=\"\\t\")\n",
    "\n",
    "    ###Extract sumstats and only for specified fold\n",
    "    fold_name <- paste0(\"fold_\", fold)\n",
    "    sumstats <- sumstats[fold_name]\n",
    "\n",
    "    ###Extract and filter Y and X\n",
    "    Y <- filter_Y(dat$y_res, n_nonmiss_Y)\n",
    "    X <- filter_X(dat$X, missing_rate_cutoff, maf_cutoff, var_cutoff)\n",
    "\n",
    "    ###Drop tissues with < n_nonmiss_Y in data-driven matrices and sumstats\n",
    "    datadriven_mats_sumstats_filt <- filter_datadriven_mats_and_sumstats(Y, datadriven_mats, sumstats)\n",
    "    S0_data <- datadriven_mats_sumstats_filt$datadriven_mats_filt\n",
    "    sumstats <- datadriven_mats_sumstats_filt$sumstats_filt\n",
    "    rm(datadriven_mats_sumstats_filt)\n",
    "  \n",
    "    prior_grid = load_prior_grid(${prior_grid:r}, sumstats)\n",
    "    if(is.null(sumstats) && is.null(prior_grid)){\n",
    "      # FIXME: we can implement it and provide a warning instead\n",
    "      stop(\"Computing summary stats and grid on the fly is not yet implemented. Please provide either proper summary stats path or prior grid file.\")\n",
    "    }\n",
    "  \n",
    "    ###Split the data in training and test sets\n",
    "    dat_split <- split_data(X, Y, gtex_ids_folds, fold)\n",
    "    Xtrain <- dat_split$Xtrain\n",
    "    Ytrain <- dat_split$Ytrain\n",
    "    Xtest <- dat_split$Xtest\n",
    "    Ytest <- dat_split$Ytest\n",
    "    rm(dat_split)\n",
    "  \n",
    "    ###Compute canonical matrices, if requested\n",
    "    if(canonical_mats){\n",
    "      S0_can <- mr.mash.alpha::compute_canonical_covs(ncol(Ytrain), singletons=TRUE, hetgrid=c(0, 0.25, 0.5, 0.75, 1))\n",
    "      S0_raw <- c(S0_can, S0_data)\n",
    "    } else {\n",
    "      S0_raw <- S0_data\n",
    "    }\n",
    "    \n",
    "    ###Compute prior covariance\n",
    "    S0 <- mr.mash.alpha::expand_covs(S0_raw, prior_grid, zeromat=TRUE)\n",
    "    \n",
    "    time1 <- proc.time()\n",
    "\n",
    "    ###Compute initial estimates of regression coefficients and prior weights (if not provided)\n",
    "    if(glmnet_pred){\n",
    "      Xnew <- Xtest\n",
    "    } else {\n",
    "      Xnew <- NULL\n",
    "    }\n",
    "\n",
    "    if(B_init_method == \"enet\"){\n",
    "      out <- compute_coefficients_univ_glmnet(Xtrain, Ytrain, alpha=0.5, standardize=standardize, nthreads=nthreads, Xnew=Xnew)\n",
    "    } else if(B_init_method == \"glasso\"){\n",
    "      out <- compute_coefficients_glasso(Xtrain, Ytrain, standardize=standardize, nthreads=nthreads, Xnew=Xnew)\n",
    "    }\n",
    "\n",
    "    if(is.null(w0_init)){\n",
    "      external_w0 <- FALSE\n",
    "      w0 <- compute_w0(out$Bhat, length(S0))\n",
    "    } else {\n",
    "      external_w0 <- TRUE\n",
    "      w0 <- w0_init\n",
    "    }\n",
    "  \n",
    "    ###Filter prior components based on weights\n",
    "    comps_filtered <- filter_S0_w0(S0=S0, w0=w0)\n",
    "    S0 <- comps_filtered$S0\n",
    "    w0 <- comps_filtered$w0\n",
    "    rm(comps_filtered)\n",
    "\n",
    "    ###Fit mr.mash\n",
    "    fit_mrmash <- tryCatch({mr.mash.alpha::mr.mash(X=Xtrain, Y=Ytrain, S0=S0, w0=w0, update_w0=update_w0, tol=tol,\n",
    "                                                   max_iter=max_iter, convergence_criterion=\"ELBO\", compute_ELBO=TRUE,  \n",
    "                                                   standardize=standardize, verbose=verbose, update_V=update_V, update_V_method=update_V_method,\n",
    "                                                   w0_threshold=w0_threshold, nthreads=nthreads, mu1_init=out$Bhat)\n",
    "                            },\n",
    "                           error=function(e) {\n",
    "                                message(\"Original mr.mash error message:\")\n",
    "                                message(e)\n",
    "                                return(NULL)\n",
    "                            },\n",
    "                           warning=function(w) {\n",
    "                                message(\"Original mr.mash warning message:\")\n",
    "                                message(w)\n",
    "                                return(NULL)\n",
    "                            })\n",
    "\n",
    "    \n",
    "    if(!is.null(fit_mrmash)){\n",
    "      time2 <- proc.time()\n",
    "      elapsed_time <- time2[\"elapsed\"] - time1[\"elapsed\"]\n",
    "      ###Make predictions\n",
    "      Yhat_test <- predict(fit_mrmash, Xtest)\n",
    "      ###Save results\n",
    "      if (external_w0) {\n",
    "           resu <- list(Ytest=Ytest, Yhat_test=Yhat_test, elapsed_time=elapsed_time)\n",
    "      } else {\n",
    "          if (w0_threshold > 0) selected_labels = names(S0)\n",
    "          else selected_labels = NULL\n",
    "          w1_colsums <- compute_posterior_weight_colsum(fit_mrmash$w1, selected_labels)     \n",
    "          resu <- list(w1_colsums=w1_colsums, Bhat=fit_mrmash$mu1, Ytest=Ytest, Yhat_test=Yhat_test, elapsed_time=elapsed_time)\n",
    "      }\n",
    "      if(save_model){\n",
    "       resu$model <-  fit_mrmash\n",
    "      }\n",
    "\n",
    "      if(glmnet_pred){\n",
    "        resu$Yhat_test_glmnet <- out$Yhat_new\n",
    "      }\n",
    "      saveRDS(resu, ${_output[0]:r})\n",
    "    } else {\n",
    "      saveRDS(NULL, ${_output[0]:r})\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[joint_weights_update_2]\n",
    "parameter: seed = 999\n",
    "input: group_by = \"all\"\n",
    "output: f\"{wd:a}/{name}_updated_weights.rds\"\n",
    "task: trunk_workers = 1, walltime = '6h', trunk_size = 1, mem = '2G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    options(stringsAsFactors=FALSE)\n",
    "    set.seed(${seed})\n",
    " \n",
    "    i = 0\n",
    "\n",
    "    for (f in c(${_input:r,})) {\n",
    "      i = i+1    \n",
    "      \n",
    "      dat = readRDS(f)$w1_colsums\n",
    "      if (is.null(dat)) {\n",
    "          message(paste(\"Dataset\", f, \"has no valid w1_colsums quantity\"))\n",
    "          next\n",
    "      }\n",
    "      if(i > 1){\n",
    "        weights = weights + dat\n",
    "      } else {\n",
    "        weights = dat\n",
    "      }\n",
    "\n",
    "    }\n",
    "   \n",
    "    weights = weights/sum(weights)  \n",
    "\n",
    "    saveRDS(weights, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
