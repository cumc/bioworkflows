{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b6395b-9eb5-4507-b3ba-68c28df18ece",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Annotation of exome variants using Annovar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f48c0-74e6-42a1-9bbf-83fb40f5bd00",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim\n",
    "\n",
    "Prepare the data for further association analyses using the LMM.ipynb on rare variants. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b8439-4541-486f-b532-4bc367650670",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054409a-f632-4930-a076-3e3bffefd848",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This pipeline provides 3 different possibilities depending on the type of input data you are starting with:\n",
    "\n",
    "### Scenario 1 : you have multiple bim files (e.g. one per chromosome) and you want to merge them into one file for later annotation with annovar\n",
    "\n",
    "Run `bim_merge` to concatenate all the bim files and then run `annovar` to annotate all the variants at once\n",
    "\n",
    "### Scenario 2: you either want to work with common or rare variants.\n",
    "\n",
    "Run `get_snps` using the `--maf` or `max-maf` depending on the type of variants you would like to extract and then run `annovar`\n",
    "\n",
    "### Scenario 3: you already have a specific list of variants you would like to annotate stored in a bim file. \n",
    "\n",
    "Run `annovar`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac9036-a064-427d-b722-159ebfc9baf1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4dbe44-140b-4cc2-83ed-71fcda3bf757",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR\u001b[0m: \u001b[91mNotebook JSON is invalid: %s\u001b[0m\n",
      "usage: sos run annovar.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  bim_merge\n",
      "  get_snps\n",
      "  annovar\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --numThreads 2 (as int)\n",
      "                        Specific number of threads to use\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --build hg38\n",
      "                        Human genome build\n",
      "  --bim-name VAL (as path, required)\n",
      "                        Name for the merged bimfiles\n",
      "  --name-prefix VAL (as str, required)\n",
      "                        Prefix for the name based on common/rare variant\n",
      "                        filtering\n",
      "  --annovar-module '\\nmodule load ANNOVAR/2020Jun08-foss-2018b-Perl-5.28.0\\necho \"Module annovar loaded\"\\n{cmd}\\n'\n",
      "                        Load annovar module from cluster\n",
      "  --container-annovar 'gaow/gatk4-annovar'\n",
      "                        Software container option\n",
      "  --container-lmm 'statisticalgenetics/lmm:2.0'\n",
      "\n",
      "Sections\n",
      "  bim_merge:            Merge all the bimfiles into a single file to use later\n",
      "                        with awk Only need to run this cell once\n",
      "    Workflow Options:\n",
      "      --bimfiles  paths\n",
      "\n",
      "  get_snps_1:           Get a list of common SNPs above (--maf) or rare SNPs\n",
      "                        below (--max-maf) certain MAF\n",
      "    Workflow Options:\n",
      "      --bfiles  paths\n",
      "\n",
      "                        bed files plink format\n",
      "      --maf-filter 0.0 (as float)\n",
      "                        Filter based on minor allele frequency (use when\n",
      "                        filtering common variants)\n",
      "      --max-maf-filter 0.001 (as float)\n",
      "                        Filter based on the maximum maf allowed (use when\n",
      "                        filtering rare variants)\n",
      "      --geno-filter 0.0 (as float)\n",
      "                        Filter out variants with missing call rate higher that\n",
      "                        this value\n",
      "      --hwe-filter 0.0 (as float)\n",
      "                        Filter according to Hardy Weiberg Equilibrium\n",
      "      --mind-filter 0.0 (as float)\n",
      "                        Fitler out samples with missing rate higher than this\n",
      "                        value\n",
      "  get_snps_2:           Merge all of the common_var.snplist into a single file\n",
      "                        and all the rare_var.snplist into another single file\n",
      "  get_snps_3:           Search for common or rare variants in bimfile and\n",
      "                        generate annovar input file\n",
      "  annovar_1:            Create annovar input file\n",
      "  annovar_2:            Annotate vcf file using ANNOVAR\n",
      "    Workflow Options:\n",
      "      --humandb VAL (as path, required)\n",
      "                        humandb path for ANNOVAR\n",
      "      --ukbb VAL (as path, required)\n",
      "      --x-ref  path(f\"{ukbb}/mart_export_2019_LOFtools3.txt\")\n",
      "\n",
      "                        add xreffile to option without -exonicsplicing\n",
      "                        mart_export_2019_LOFtools3.txt #xreffile latest option\n",
      "                        -> Phenotype description,HGNC symbol,MIM morbid descript\n",
      "                        ion,CGD_CONDITION,CGD_inh,CGD_man,CGD_comm,LOF_tools\n",
      "      --protocol refGene refGeneWithVer knownGene ensGene phastConsElements30way encRegTfbsClustered gwasCatalog gnomad211_genome gnomad211_exome gme kaviar_20150923 abraom avsnp150 dbnsfp41a dbscsnv11 regsnpintron clinvar_20200316 gene4denovo201907 (as list)\n",
      "                        Annovar protocol\n",
      "      --operation g g g gx r r r f f f f f f f f f f f (as list)\n",
      "                        Annovar operation\n",
      "      --arg \"-splicing 12 -exonicsplicing\" \"-splicing 30\" \"-splicing 12 -exonicsplicing\" \"-splicing 12\"               (as list)\n",
      "                        Annovar args\n"
     ]
    }
   ],
   "source": [
    "!sos run annovar.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbeb4c-3b07-4ea6-81b9-f6633325abd0",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Illustration with minimal working example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb66841-ac70-4c90-9802-05b81ed424e8",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**Scenario 3:** On Yale's cluster, here modify humandb and ukbb paths to match the location of the databases needed by annovar to function\n",
    "\n",
    "```\n",
    "sos run ~/project/bioworkflows/variant-annotation/annovar.ipynb annovar \\\n",
    "    --cwd output \\\n",
    "    --bim_name ukb23156_c22.merged.filtered.bim \\\n",
    "    --humandb /gpfs/ysm/datasets/db/annovar/humandb \\\n",
    "    --ukbb /gpfs/gibbs/pi/dewan/data/UKBiobank \\\n",
    "    --job_size 1 \\\n",
    "    --name_prefix mwe_chr22 \\\n",
    "    --container_annovar /gpfs/gibbs/pi/dewan/data/UKBiobank/annovar.sif\n",
    "```\n",
    "\n",
    "On Columbia's cluster running `annovar`\n",
    "\n",
    "```\n",
    "sos run ~/project/bioworkflows/variant-annotation/annovar.ipynb annovar \\\n",
    "    --cwd output \\\n",
    "    --bim_name /mnt/mfs/statgen/UKBiobank/data/exome_files/project_VCF/plink_files/ukb23156_c22.merged.filtered.bim \\\n",
    "    --humandb /mnt/mfs/statgen/isabelle/REF/humandb  \\\n",
    "    --ukbb /mnt/mfs/statgen/isabelle/REF/humandb \\\n",
    "    --job_size 1 \\\n",
    "    --name_prefix mwe_chr22 \\\n",
    "    --container_annovar /mnt/mfs/statgen/containers/gatk4-annovar.sif\n",
    "```\n",
    "On Columbia's cluster running `burden_files`\n",
    "```\n",
    "sos run ~/project/bioworkflows/variant-annotation/annovar.ipynb burden_files\\\n",
    "    --cwd ~/output \\\n",
    "    --annotated_file /mnt/mfs/statgen/UKBiobank/results/annovar_exome/ukb32285_exomespb_chr1_22.hg38.hg38_multianno.csv\\\n",
    "    --bim_name /mnt/mfs/statgen/UKBiobank/data/exome_files/project_VCF/plink_files/ukb23156_c1.merged.filtered.bim \\\n",
    "    --job_size 1 \\\n",
    "    --name_prefix test \\\n",
    "    --container_lmm /mnt/mfs/statgen/containers/lmm.sif\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4d682-f59e-4065-8c63-ee530dd6abe7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Name for the merged bimfiles to use\n",
    "parameter: bim_name = path\n",
    "# Human genome build hg19 or hg38\n",
    "parameter: build = 'hg38'\n",
    "# Prefix for the name based on common/rare variant filtering\n",
    "parameter: name_prefix = str\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"15h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"30G\"\n",
    "# Load annovar module from cluster\n",
    "parameter: annovar_module = '''\n",
    "module load ANNOVAR/2020Jun08-foss-2018b-Perl-5.28.0\n",
    "echo \"Module annovar loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "# Software container option\n",
    "parameter: container_annovar = 'gaow/gatk4-annovar'\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:2.4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e71a7-cf17-4115-a297-2e08590f3c9f",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Format file for plink .bim\n",
    "\n",
    "A text file with no header line, and one line per variant with the following six fields:\n",
    "1. Chromosome code (either an integer, or 'X'/'Y'/'XY'/'MT'; '0' indicates unknown) or name\n",
    "2. Variant identifier\n",
    "3. Position in morgans or centimorgans (safe to use dummy value of '0')\n",
    "4. Base-pair coordinate (1-based; limited to 231-2)\n",
    "5. Allele 1 (corresponding to clear bits in .bed; usually minor)\n",
    "6. Allele 2 (corresponding to set bits in .bed; usually major)\n",
    "\n",
    "In the bim file the second column e.g `1:930232:C:T` contains the alleles in ref/alt mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0baeb-a4a5-4ca1-b223-d7ebb9d8cc70",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step to merge *.bim files from plink formatted data (e.g exome data in the UKBB, genotype array data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72eac11-73dc-4e33-90b1-15084fe839ff",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the *.bim files into a single file. Needs to be run once per type of data (e.g. genotype, exome)\n",
    "[bim_from_plink]\n",
    "# Path to the *.bim files to merge\n",
    "parameter: bimfiles= paths\n",
    "# Specify path of the merged bim file\n",
    "parameter: bim_name = path\n",
    "input: bimfiles \n",
    "output: bim_name\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "      cat ${_input} >> ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1726d3-efb8-4e3a-92a1-5b19e93b0f69",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step to create a list of variants from *.bgen files and a merged *.bim file to annotate (e.g imputed genotype data UKBB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4403da-2df6-40a7-83b7-30031698e0fd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Create a merged *.bim file from *.bgen files\n",
    "[bim_from_bgen]\n",
    "# Specify bgen files path\n",
    "parameter: genoFile = paths\n",
    "# Specify name of the merged bim file\n",
    "parameter: bim_name = str\n",
    "# The input here is the bgen file from which to extract the list of variants\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}.bim'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bgenix -g ${_input} -list | awk 'NR>2 { gsub(\"_\",\":\",$1); print $3, $1, $4, $7, $6 }' | awk 'BEGIN{FS=OFS=\" \"}{$2 = $2 OFS 0}1'  > ${_output}\n",
    "    cat ${_output} | awk '{x=$1+0;print x,$2,$3,$4,$5,$6}' >> ${cwd}/${bim_name}.merged.bim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e65d55-b655-49d8-9229-9025412089b9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Get a list of common SNPs above (--maf) or rare SNPs below (--max-maf) certain MAF\n",
    "[get_snps_1]\n",
    "# bed files plink format\n",
    "parameter: bfiles = paths\n",
    "# Filter based on minor allele frequency (use when filtering common variants)\n",
    "parameter: maf_filter = 0.0\n",
    "# Filter based on the maximum maf allowed (use when filtering rare variants)\n",
    "parameter: max_maf_filter = 0.001\n",
    "# Filter out variants with missing call rate higher that this value\n",
    "parameter: geno_filter = 0.0\n",
    "# Filter according to Hardy Weiberg Equilibrium\n",
    "parameter: hwe_filter = 0.0\n",
    "# Fitler out samples with missing rate higher than this value\n",
    "parameter: mind_filter = 0.0\n",
    "input: bfiles, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.{name_prefix}.snplist'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    plink2 \\\n",
    "      --bfile ${_input:n}\\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--max-maf %s' % max_maf_filter) if max_maf_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --no-id-header\\\n",
    "      --freq \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc6e52-c982-4856-aac9-0d72f9126f53",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all of the common_var.snplist into a single file and all the rare_var.snplist into another single file\n",
    "[get_snps_2]\n",
    "input: group_by='all'\n",
    "output: f'{cwd}/cache/{name_prefix}.snplist'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "      cat ${_input} > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b640bbf-0566-43ed-9cae-5a34ade46af9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Search for common or rare variants in bimfile and generate annovar input file\n",
    "[get_snps_3]\n",
    "depends: bim_name\n",
    "output: f'{cwd}/{_input:bn}.avinput'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    awk -F\" \" 'FNR==NR {lines[$1]; next} $2 in lines ' ${_input} ${bim_name} > ${_output:n}.tmp\n",
    "    awk '{if ($2 ~ /D/) {print $1, $4, $4 + (length ($6) - length ($5)), $6, $5 } else {print $1, $4, $4, $6, $5 }}'  ${_output:n}.tmp >  ${_output}\n",
    "    # remove temporary files\n",
    "    rm -f ${_output:n}.tmp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1db150-cd37-41ab-824d-f34ce3f39972",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Annovar details\n",
    "\n",
    "For a list of available [databases](https://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/)\n",
    "\n",
    "On Farnam's Yale HPC there is a folder for shared databases\n",
    "```/gpfs/ysm/datasets/db/annovar/humandb``` \n",
    "\n",
    "and a folder for the x_ref database ```/gpfs/gibbs/pi/dewan/data/UKBiobank/mart_export_2019_LOFtools3.txt```\n",
    "\n",
    "On Columbia's cluster there folder for shared databases for build hg19 is under Isabelle's folder\n",
    "```/mnt/mfs/statgen/isabelle/REF/humandb```\n",
    "\n",
    "and the x_ref database is under that same folder ```/mnt/mfs/statgen/isabelle/REF/humandb```\n",
    "\n",
    "\n",
    "### Important note\n",
    "\n",
    "Please make sure you are using the correct build for your annotations UKBB exome data for 200K individuals need hg38 build\n",
    "\n",
    "### Format file for annovar input\n",
    "\n",
    "On each line, the first five space- or tab- delimited columns represent \n",
    "\n",
    "1. chromosome \n",
    "2. start position \n",
    "3. end position \n",
    "4. the reference nucleotides\n",
    "5. the observed nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7492b-9409-4ddf-9f43-7f914172fec6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Create annovar input file\n",
    "[annovar_1]\n",
    "# Input is the file to be annotated and can be a bim file, a pvar file or a summary stats file generated by regenie\n",
    "## Format of sumstats should be CHROM, GENPOS, ID, ALLELE0 (REF) and ALLELE1 (ALT)\n",
    "## Format of the pvar file should be #CHROM POS ID REF ALT\n",
    "input: bim_name\n",
    "output: f'{cwd}/{_input:bn}.{build}.avinput'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.err', stdout = f'{_output:n}.out' \n",
    "    # $1 chromosome, $2 variant_id, $3 cM, $4 POS, $6 ref_allele (allele 2 usually major), $5 alt_allele (allele 1 usually minor) in the bim files \n",
    "    # Output as annovar avinput chr, start, end (has to be calculated depending on reference allele length), reference, alternative\n",
    "    filename=\"${_input}\"\n",
    "    suffix=$(echo \"$filename\" | awk -F. '{print $NF}')\n",
    "    echo $suffix\n",
    "    if [[ \"$suffix\" == \"bim\" ]]; then\n",
    "        echo \"Input file has a .bim extension\"\n",
    "        awk '{if (length ($6) > 1) {print $1, $4, $4 + (length ($6) - 1), $6, $5, $2} else {print $1, $4, $4, $6, $5, $2}}'   ${_input} >  ${_output}\n",
    "    elif [[ \"$suffix\" == \"pvar\" ]]; then\n",
    "        echo \"Input file has .pvar extension, it will be considered as a plink pvar format and the columns are CHROM, POS, ID,  REF, ALT. Please confirm that your input file has this format\"\n",
    "        awk  'NR>1 {if (length ($4) > 1) {print $1,$2,$2 + (length ($4) - 1),$4,$5} else {print $1,$2,$2,$4,$5}}'   ${_input} >  ${_output}\n",
    "    else\n",
    "        echo \"Input file does not have .bim extension, it will be considered as a summary stats and the columns are chrom, genpos, ID, allele0(ref), allele1(alt). Please confirm that your file has this format\"\n",
    "        awk 'NR>1 {if (length ($4) > 1) {print $1, $2, $2 + (length ($4) - 1), $4, $5, $3} else {print $1, $2, $2, $4, $5, $3}}'   ${_input} >  ${_output}\n",
    "    fi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1156effe-e5c0-4fe0-9aa8-e8a436007a17",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Create annovar input file\n",
    "[annovar_1]\n",
    "# Input is the file to be annotate and can be a bim file or a summary stats file generated by regenie\n",
    "## Format of sumstats should be CHROM, GENPOS, ID, ALLELE0 (REF) and ALLELE1 (ALT)\n",
    "input: bim_name\n",
    "output: f'{cwd}/{_input:bn}.{build}.avinput'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.err', stdout = f'{_output:n}.out' \n",
    "    \n",
    "        import subprocess\n",
    "        import os\n",
    "\n",
    "        # Determine the file format based on the file extension\n",
    "        file_name, file_extension = os.path.splitext(str(${_input}))\n",
    "\n",
    "        if file_extension == \".bim\":\n",
    "            print(\"Input file has a .bim extension\")\n",
    "            # Define the awk command for .bim files\n",
    "            awk_command = f'awk \\'{{if (length ($6) > 1) {{print $1, $4, $4 + (length ($6) - 1), $6, $5, $2}} else {{print $1, $4, $4, $6, $5, $2}}}}\\' {input_file} > {output_file}'\n",
    "            # Run the awk command using subprocess\n",
    "            subprocess.run(awk_command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        else:\n",
    "            print(\"Input file does not have .bim extension\")\n",
    "            # Define the awk command for other file types\n",
    "            awk_command = f'awk \\'{{if (length ($4) > 1) {{print $1, $2, $2 + (length ($4) - 1), $4, $5}} else {{print $1, $2, $2, $4, $5}}}}\\' {input_file} > {output_file}'\n",
    "            # Run the awk command using subprocess\n",
    "            subprocess.run(awk_command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171169d-3a59-44a3-ba49-64950e4862f2",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## The version of annovar used to annotate for the RAP system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbd68-99fb-4be6-840f-9fbc2eedf022",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Annotate variants file using ANNOVAR\n",
    "[annovar_2]\n",
    "# humandb path for ANNOVAR\n",
    "parameter: humandb = path\n",
    "# Path to x-ref file\n",
    "parameter: xref_path = path\n",
    "# Annovar protocol\n",
    "if build == 'hg19':\n",
    "    protocol = ['refGene', 'refGeneWithVer', 'knownGene', 'ensGene', 'phastConsElements46way', 'gwasCatalog', 'gnomad211_exome', 'avsnp150', 'dbnsfp42a', 'dbscsnv11', 'gene4denovo201907']\n",
    "    operation = ['g', 'g', 'g', 'g', 'r', 'r', 'f', 'f', 'f', 'f', 'f']\n",
    "    arg = ['\"-splicing 12\"', '\"-splicing 2\"', '\"-splicing 12\"', '\"-splicing 12\"', '', '', '', '', '', '', '']\n",
    "else:\n",
    "    protocol = ['refGene', 'refGeneWithVer', 'knownGene', 'ensGene', 'gwasCatalog', 'gnomad312_genome', 'gnomad211_exome', 'avsnp150', 'dbnsfp42a', 'dbscsnv11', 'clinvar_20220320', 'gene4denovo201907']\n",
    "    operation = ['g', 'g', 'g', 'gx', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f']\n",
    "    arg = ['\"-splicing 12\"', '\"-splicing 2\"', '\"-splicing 12\"', '\"-splicing 12\"', '', '', '', '', '', '', '', '']\n",
    "\n",
    "#add xreffile to option without -exonicsplicing\n",
    "#mart_export_2019_LOFtools3.txt #xreffile latest option -> Phenotype description,HGNC symbol,MIM morbid description,CGD_CONDITION,CGD_inh,CGD_man,CGD_comm,LOF_tools\n",
    "parameter: x_ref = path(f\"{xref_path}/mart_export_2021_LOFtools.txt\")\n",
    "output: f'{cwd}/{_input:bn}.{build}_multianno.csv'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}', template = '{cmd}' if executable('annotate_variation.pl').target_exists() else annovar_module\n",
    "bash: container=container_annovar, volumes=[f'{humandb:a}:{humandb:a}', f'{x_ref:ad}:{x_ref:ad}'], expand=\"${ }\", stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    #do not add -intronhgvs as option -> writes cDNA variants as HGVS but creates issues (+2 splice site reported only)\n",
    "    #-nastring . can only be . for VCF files\n",
    "    #regsnpintron might cause shifted lines (be carefull using)\n",
    "    table_annovar.pl \\\n",
    "        ${_input} \\\n",
    "        ${humandb} \\\n",
    "        -buildver ${build} \\\n",
    "        -out ${_output:nn}\\\n",
    "        -otherinfo\\\n",
    "        -remove \\\n",
    "        -polish \\\n",
    "        -nastring . \\\n",
    "        -protocol ${\",\".join(protocol)}\\\n",
    "        -operation ${\",\".join(operation)} \\\n",
    "        -arg ${\",\".join(arg)} \\\n",
    "        -csvout "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5db42-ee83-4b5d-bab9-023019a21d56",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Generate files for burden_test regenie from the annotated file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73213611-67c2-4250-9b03-821f5c3d2962",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This workflow's aim is to generate the `--anno_file` and the `--set_list` files needed to run regenie_burden in the LMM.ipynb\n",
    "\n",
    "Required files\n",
    "1. The anno_files: define variant sets and functional annotations that will be used to generate the masks. The format is `chr:start:ref:alt gene_name functional_annot`\n",
    "2. The set-list-files: lists variants within each set/gene to use when building masks. The format is set/gene chr start_pos and a comma separated list of variants included in that gene\n",
    "3. Mask file: this file specifies which annotation categories should be combined into masks\n",
    "\n",
    "Optional files\n",
    "\n",
    "4. Set inclusion/exclusion file: one column with a list of sets/genes to be included/excluded from the set-list-file\n",
    "5. Alternative allele frequency file (AAF): by default the AAF is computed by the sample but you can specify an AAF for each variant using this file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d4f1a-1c3d-4ecf-baa0-1f3a8adc1ddf",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[burden_files]\n",
    "parameter: annovar_anno = paths\n",
    "parameter: vep_anno = paths\n",
    "parameter: rsid = False\n",
    "input: annovar_anno, vep_anno, group_by = 'pairs'\n",
    "output:f'{cwd}/{_input[0]:bn}.anno_file',\n",
    "       f'{cwd}/{_input[0]:bn}.aaf_file',\n",
    "       f'{cwd}/{_input[0]:bn}.set_list_file'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = mem, cores = numThreads, tags = f'{_output[0]:bn}'\n",
    "R:  expand=\"${ }\", stderr=f'{_output[0]:n}.err', stdout=f'{_output[0]:n}.out'\n",
    "  rm(list = ls())\n",
    "  # R.version\n",
    "  packages_list <- c(\"devtools\", \"readr\", \"dplyr\", \"tidyr\", \"data.table\", \"R.utils\", \"knitr\", \"stringr\", \"stringi\")\n",
    "  invisible(lapply(packages_list, library, character.only = TRUE, warn.conflicts = F, quietly = T))\n",
    "  # Read in the annotated file with annovar\n",
    "  df_anno <- fread(${_input[0]:r},na.strings = \".\")\n",
    "  dim(df_anno)\n",
    "  # Read in the annotated file with VEP\n",
    "  df_vep <- fread(${_input[1]:r})\n",
    "  dim(df_vep)\n",
    "  # subset the columns we care about\n",
    "  df_vep_cadd <- df_vep[, c(\"Uploaded_variation\", \"CADD_PHRED\")]\n",
    "  # change the name of the columns\n",
    "  setnames(df_vep_cadd , c(\"Uploaded_variation\", \"CADD_PHRED\"), c(\"Otherinfo1\",\"CADD_PHRED_VEP\"))\n",
    "  # Remove the duplicates in the VEP file\n",
    "  df_vep_nondup <- df_vep_cadd[!duplicated(df_vep_cadd)]\n",
    "  dim(df_vep_nondup)\n",
    "  # Merge the two databases \n",
    "  df_orig_orig <- merge(df_anno, df_vep_nondup, by=\"Otherinfo1\", all=T)\n",
    "  # Create another database appling the gnomAD_nfe rule and flipping the alleles with REF/ALT issues\n",
    "  df_orig<- df_orig_orig %>%\n",
    "  mutate(ID_r = case_when(gnomad312_AF_nfe>0.5 & AF_nfe>0.5 ~ paste(Chr, Start, Alt, Ref, sep = \":\"),\n",
    "                          gnomad312_AF_nfe>0.5 & is.na(AF_nfe) ~ paste(Chr, Start, Alt, Ref, sep = \":\"),\n",
    "                          is.na(gnomad312_AF_nfe) & AF_nfe>0.5 ~ paste(Chr, Start, Alt, Ref, sep = \":\"),\n",
    "                          TRUE ~ paste(Chr, Start, Ref, Alt, sep = \":\"))) %>%\n",
    "  mutate(AF_gnomAD=case_when(gnomad312_AF_nfe>0.5 & AF_nfe>0.5 ~ as.character(1 - pmax(gnomad312_AF_nfe, AF_nfe, na.rm=TRUE)),\n",
    "                          gnomad312_AF_nfe>0.5 & is.na(AF_nfe) ~ as.character(1 - gnomad312_AF_nfe),\n",
    "                          is.na(gnomad312_AF_nfe) & AF_nfe>0.5 ~ as.character(1 - AF_nfe),\n",
    "                          TRUE ~ as.character(pmax(gnomad312_AF_nfe, AF_nfe, na.rm=TRUE))))\n",
    "\n",
    "  # Print some summaries of the file\n",
    "  dim(df_orig_orig)\n",
    "  \n",
    "  # Keep only the categories we need for creation of burden files\n",
    "  categories_to_keep <- c('exonic', 'exonic;splicing', 'splicing', 'ncRNA_exonic;splicing')\n",
    "  mask_column1 <- df_orig$Func.refGene %in% categories_to_keep\n",
    "  mask_column2 <- df_orig$Func.refGeneWithVer %in% categories_to_keep\n",
    "  df <- df_orig[mask_column1 | mask_column2, ]\n",
    "  \n",
    "  # Print a cross table of the two columns that contain the important annotations\n",
    "  kable(table(df$Func.refGene, df$Func.refGeneWithVer))\n",
    "  # add a unique ID to each row\n",
    "  df$uniqueID <- c(1:nrow(df))\n",
    "  df$Func.refGene.num <- str_count(df$Func.refGene, \";\") + 1\n",
    "  df$Gene.refGene.num <- str_count(df$Gene.refGene, \";\") + 1\n",
    "  df$Func.refGeneWithVer.num <- str_count(df$Func.refGeneWithVer, \";\") + 1\n",
    "  df$Gene.refGeneWithVer.num <- str_count(df$Gene.refGeneWithVer, \";\") + 1\n",
    "  #Single gene and single function\n",
    "  df_1111 <- df %>%\n",
    "    filter(Func.refGene.num == 1 & Gene.refGene.num == 1 & Func.refGeneWithVer.num == 1 & Gene.refGeneWithVer.num == 1)\n",
    "    dim(df_1111)\n",
    "    df_1111_output <- df_1111\n",
    "  table(df_1111_output$Func.refGene.num, df_1111_output$Gene.refGene.num)\n",
    "  table(df_1111_output$Func.refGeneWithVer.num, df_1111_output$Gene.refGeneWithVer.num)\n",
    "  # Equal number of genes and functions\n",
    "  df_equal <- df %>%\n",
    "    filter(!(Func.refGene.num == 1 & Gene.refGene.num == 1 & Func.refGeneWithVer.num == 1 & Gene.refGeneWithVer.num == 1)) %>%\n",
    "    filter(Func.refGene.num == Gene.refGene.num & Func.refGeneWithVer.num == Gene.refGeneWithVer.num)\n",
    "  dim(df_equal)\n",
    "  table(df_equal$Func.refGene.num, df_equal$Gene.refGene.num)\n",
    "  table(df_equal$Func.refGeneWithVer.num, df_equal$Gene.refGeneWithVer.num)\n",
    "  # separate this into different rows\n",
    "  df_equal_output_1 <- df_equal %>%\n",
    "  separate_longer_delim(c(Func.refGene, Gene.refGene), delim = \";\")\n",
    "  df_equal_output_2 <- df_equal_output_1 %>%\n",
    "  separate_longer_delim(c(Func.refGeneWithVer, Gene.refGeneWithVer), delim = \";\")\n",
    "  dim(df_equal_output_2)\n",
    "  df_equal_output_2$Func.refGene.num <- str_count(df_equal_output_2$Func.refGene, \";\") + 1\n",
    "  df_equal_output_2$Gene.refGene.num <- str_count(df_equal_output_2$Gene.refGene, \";\") + 1\n",
    "  df_equal_output_2$Func.refGeneWithVer.num <- str_count(df_equal_output_2$Func.refGeneWithVer, \";\") + 1\n",
    "  df_equal_output_2$Gene.refGeneWithVer.num <- str_count(df_equal_output_2$Gene.refGeneWithVer, \";\") + 1\n",
    "\n",
    "  table(df_equal_output_2$Func.refGene.num, df_equal_output_2$Gene.refGene.num)\n",
    "  table(df_equal_output_2$Func.refGeneWithVer.num, df_equal_output_2$Gene.refGeneWithVer.num)\n",
    "  ## Multiple genes to one function or viceversa\n",
    "  df_1_to_n <- df %>%\n",
    "    filter( (Func.refGene.num == 1 & Gene.refGene.num != 1 | Func.refGene.num != 1 & Gene.refGene.num == 1) & (Func.refGeneWithVer.num == 1 & Gene.refGeneWithVer.num != 1 | Func.refGeneWithVer.num != 1 & Gene.refGeneWithVer.num == 1))\n",
    "  # we do the 1-n column in Func.refGene.num and Gene.refGene.num on the output of the step above\n",
    "  tmp1 <- df_1_to_n %>%\n",
    "    filter(Func.refGene.num == 1 & Gene.refGene.num != 1)\n",
    "  tmp1_separated <- tmp1 %>%\n",
    "    separate_longer_delim(c(Gene.refGene), delim = \";\")\n",
    "  tmp1_separated_excluding <- df_1_to_n %>% filter(!(Func.refGene.num == 1 & Gene.refGene.num != 1))\n",
    "  tmp1_separated_output = rbind(tmp1_separated, tmp1_separated_excluding)\n",
    "  # then we do the n-1 column in Func.refGene.num and Gene.refGene.num on the output of the step above\n",
    "  tmp2 <- tmp1_separated_output %>%\n",
    "    filter(Func.refGene.num != 1 & Gene.refGene.num == 1)\n",
    "  tmp2_separated <- tmp2 %>%\n",
    "    separate_longer_delim(c(Func.refGene), delim = \";\")\n",
    "  tmp2_separated_excluding <- tmp1_separated_output %>% filter(!(Func.refGene.num != 1 & Gene.refGene.num == 1))\n",
    "  tmp2_separated_output = rbind(tmp2_separated, tmp2_separated_excluding)\n",
    "  # then we do the 1-n column in Func.refGeneWithVer.num and Gene.refGeneWithVer.num on the output of the step above\n",
    "  tmp3 <- tmp2_separated_output %>%\n",
    "    filter(Func.refGeneWithVer.num == 1 & Gene.refGeneWithVer.num != 1)\n",
    "  tmp3_separated <- tmp3 %>%\n",
    "    separate_longer_delim(c(Gene.refGeneWithVer), delim = \";\")\n",
    "  tmp3_separated_excluding <- tmp2_separated_output %>% filter(!(Func.refGeneWithVer.num == 1 & Gene.refGeneWithVer.num != 1))\n",
    "  tmp3_separated_output = rbind(tmp3_separated, tmp3_separated_excluding)\n",
    "\n",
    "  # at last we do the n-1 column in Func.refGeneWithVer.num and Gene.refGeneWithVer.num on the output of the step above\n",
    "  tmp4 <- tmp3_separated_output %>%\n",
    "    filter(Func.refGeneWithVer.num != 1 & Gene.refGeneWithVer.num == 1)\n",
    "  tmp4_separated <- tmp4 %>%\n",
    "    separate_longer_delim(c(Func.refGeneWithVer), delim = \";\")\n",
    "  tmp4_separated_excluding <- tmp3_separated_output %>% filter(!(Func.refGeneWithVer.num != 1 & Gene.refGeneWithVer.num == 1))\n",
    "  tmp4_separated_output = rbind(tmp4_separated, tmp4_separated_excluding)\n",
    "\n",
    "  tmp4_separated_output$Func.refGene.num <- str_count(tmp4_separated_output$Func.refGene, \";\") + 1\n",
    "  tmp4_separated_output$Gene.refGene.num <- str_count(tmp4_separated_output$Gene.refGene, \";\") + 1\n",
    "  tmp4_separated_output$Func.refGeneWithVer.num <- str_count(tmp4_separated_output$Func.refGeneWithVer, \";\") + 1\n",
    "  tmp4_separated_output$Gene.refGeneWithVer.num <- str_count(tmp4_separated_output$Gene.refGeneWithVer, \";\") + 1\n",
    "\n",
    "  table(tmp4_separated_output$Func.refGene.num, tmp4_separated_output$Gene.refGene.num)\n",
    "  table(tmp4_separated_output$Func.refGeneWithVer.num, tmp4_separated_output$Gene.refGeneWithVer.num)\n",
    "  # Combine single valued dataframes\n",
    "  df_output <- rbind(df_1111_output, df_equal_output_2)\n",
    "  df_output <- rbind(df_output, tmp4_separated_output)\n",
    "  ## Set the Func to nan for splice variants\n",
    "  df_splicing = df_output %>% filter(Func.refGeneWithVer == \"splicing\")\n",
    "  print(\"--before conversion, ExonicFunc.refGene column:--\")\n",
    "  table(df_splicing$ExonicFunc.refGene)\n",
    "  print(\"--before conversion, ExonicFunc.refGeneWithVer column:--\")\n",
    "  table(df_splicing$ExonicFunc.refGeneWithVer)\n",
    "  df_output_splicing_adjusted <- df_output %>%\n",
    "    mutate(ExonicFunc.refGeneWithVer = ifelse(Func.refGeneWithVer == \"splicing\", \"nan\", ExonicFunc.refGeneWithVer))\n",
    "  df_output_splicing_adjusted_only_splicing = df_output_splicing_adjusted %>% filter(Func.refGeneWithVer == \"splicing\")\n",
    "  print(\"--after conversion, ExonicFunc.refGeneWithVer:--\")\n",
    "  table(df_output_splicing_adjusted_only_splicing$ExonicFunc.refGeneWithVer)\n",
    "  \n",
    "  ## From now on work on the file with separated and non-duplicated rows \n",
    "  df <- df_output_splicing_adjusted %>%\n",
    "    mutate(if_match = ifelse(Func.refGeneWithVer == Func.refGene, TRUE, FALSE),\n",
    "          ExonicFunc.refGeneWithVer.1 = ifelse(Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer == \"unknown\", ExonicFunc.knownGene, ExonicFunc.refGeneWithVer),\n",
    "          condition1 = ifelse(\n",
    "            CADD_phred > 20 | dbscSNV_ADA_SCORE > 0.8 | dbscSNV_RF_SCORE > 0.8, TRUE, FALSE\n",
    "        ))\n",
    "  table(df$condition1)\n",
    "  matched <- df %>%\n",
    "    filter(if_match)\n",
    "  unmatched <- df %>% filter(!if_match)\n",
    "  print(paste0(\"There are \", as.character(nrow(matched)), \" matched rows, and \", as.character(nrow(unmatched)), \" unmatched rows.\"))\n",
    "  kable(table(matched$Func.refGeneWithVer, matched$ExonicFunc.refGeneWithVer))\n",
    "  kable(table(matched$Func.refGeneWithVer, matched$ExonicFunc.knownGene))\n",
    "  # for the matched ones\n",
    "  matched <- matched %>%\n",
    "    mutate(consequence = case_when(\n",
    "        Func.refGeneWithVer == \"splicing\" ~ \"LOF\",\n",
    "        Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer.1 == \"nonsynonymous SNV\" ~ \"missense\",\n",
    "        Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer.1 == \"synonymous SNV\" ~ \"synonymous\",\n",
    "        Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer.1 %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\") ~ \"LOF\",\n",
    "        Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer.1 == \"nonframeshift substitution\" ~ \"inframe\",\n",
    "        Func.refGeneWithVer == \"exonic\" & ExonicFunc.refGeneWithVer.1 == \"unknown\" ~ ExonicFunc.knownGene,\n",
    "        TRUE ~ \"zzz\")\n",
    "           )\n",
    "  print(\"--For the matched functions these are the consequences:--\")\n",
    "  table(matched$consequence)\n",
    "  # for the unmatched\n",
    "  kable(table(unmatched$Func.refGeneWithVer, unmatched$Func.refGene))\n",
    "  kable(table(unmatched$Func.refGeneWithVer, unmatched$ExonicFunc.refGeneWithVer))\n",
    "  unmatched <- unmatched %>%\n",
    "    mutate(consequence = case_when(\n",
    "        Func.refGeneWithVer == \"exonic\" & Func.refGene == \"exonic;splicing\" & ExonicFunc.refGeneWithVer %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\") ~ \"LOF\",\n",
    "        Func.refGeneWithVer == \"exonic\" & Func.refGene == \"exonic;splicing\" & !(ExonicFunc.refGeneWithVer %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\")) & condition1 ~ \"LOF\",\n",
    "        Func.refGeneWithVer == \"exonic\" & Func.refGene == \"exonic;splicing\" & !(ExonicFunc.refGeneWithVer %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\")) & (!condition1 | is.na(condition1)) ~ \"splicing\",\n",
    "        Func.refGeneWithVer == \"splicing\" & Func.refGene %in% c(\"exonic\", \"ncRNA_exonic\", \"exonic;splicing\")  ~ \"LOF\",\n",
    "        Func.refGeneWithVer %in% c(\"UTR3\", \"UTR5\", \"intronic\", \"ncRNA_exonic\", \"ncRNA_intronic\") & Func.refGene == \"splicing\" ~ \"splicing\",\n",
    "        Func.refGeneWithVer == \"exonic\" & Func.refGene == \"splicing\" & ExonicFunc.refGeneWithVer %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\") ~ \"LOF\",\n",
    "        Func.refGeneWithVer == \"exonic\" & Func.refGene == \"splicing\" & !(ExonicFunc.refGeneWithVer %in% c(\"frameshift substitution\", \"stoploss\", \"stopgain\", \"startloss\")) ~ \"splicing\",\n",
    "        TRUE ~ \"zzz\"\n",
    "    ))\n",
    "  print(\"--For the unmatched functions these are the consequences:--\")\n",
    "  table(unmatched$consequence)\n",
    "  df_output_wf = rbind(matched,unmatched)\n",
    "  df_output_wf_no_zzz <- df_output_wf %>% filter(consequence != \"zzz\")\n",
    "  ## Please note that to this point duplicated variants have not been removed and they will be removed below in the generation of the output files\n",
    "  ## Create output files\n",
    "  ### Annotation file\n",
    "  df_annotation_file <- df_output_wf_no_zzz %>%\n",
    "    select(Chr, Start, Ref, Alt,gnomad312_AF_nfe, AF_nfe, Gene.refGeneWithVer, consequence, ID_r, AF_gnomAD, CADD_PHRED_VEP)\n",
    "  \n",
    "  head(df_annotation_file, 2)\n",
    "  dim(df_annotation_file)\n",
    "  print(\"=== after removing duplicated === \")\n",
    "  # Remove duplicated variants in the annotation file\n",
    "  df_annotation_file_no_dup <- df_annotation_file[!duplicated(df_annotation_file, by = c(\"Gene.refGeneWithVer\", \"ID_r\", \"consequence\")), ]\n",
    "  dim(df_annotation_file_no_dup)\n",
    "  table(df_annotation_file_no_dup$consequence)\n",
    "\n",
    "  print(\"=== after removing duplicated then keep the most damaging function === \") # update on 20230925\n",
    "  df_annotation_file_no_dup$consequence <- factor(df_annotation_file_no_dup$consequence, levels = c(\"LOF\", \"splicing\", \"missense\", \"synonymous\", \"inframe\", \"unknown\"))\n",
    "  df_annotation_file_no_dup_in_order = df_annotation_file_no_dup %>%\n",
    "     arrange(ID_r, Gene.refGeneWithVer, consequence)\n",
    "  df_annotation_file_no_dup_in_order_most_damaging = df_annotation_file_no_dup_in_order[!duplicated(df_annotation_file_no_dup_in_order, by = c(\"Chr\", \"Start\", \"Ref\", \"Alt\",\"gnomad312_AF_nfe\", \"AF_nfe\", \"Gene.refGeneWithVer\", \"ID_r\",\"CADD_PHRED_VEP\")),]\n",
    "  table(df_annotation_file_no_dup_in_order_most_damaging$consequence)\n",
    "  dim(df_annotation_file_no_dup_in_order_most_damaging)\n",
    "\n",
    "  df_annotation_file_no_dup_in_order_most_damaging_output <- df_annotation_file_no_dup_in_order_most_damaging %>%\n",
    "    select(ID_r, Gene.refGeneWithVer, consequence, CADD_PHRED_VEP)\n",
    "  # This step is to make sure we deal with non-numeric characters in the VEP annotated files\n",
    "  df_annotation_cadd <- df_annotation_file_no_dup_in_order_most_damaging_output %>%\n",
    "    mutate(CADD_PHRED_VEP = ifelse(CADD_PHRED_VEP == \"-\", NA, CADD_PHRED_VEP))\n",
    "  # Now we have to deal with the NA's and we generate the CADD_consequence for the burden analysis including CADD_phred\n",
    "  df_annotation_cadd_nona <- df_annotation_cadd %>%\n",
    "    mutate(CADD_cat = case_when(\n",
    "            is.na(CADD_PHRED_VEP) ~ \"NA\",\n",
    "            as.numeric(CADD_PHRED_VEP) <10 ~ \"[0-10)\",\n",
    "            as.numeric(CADD_PHRED_VEP) >=10 & as.numeric(CADD_PHRED_VEP) <20 ~ \"[10-20)\",\n",
    "            as.numeric(CADD_PHRED_VEP) >=20 ~ \">=20\",\n",
    "            TRUE ~ \"zzz\")) %>%\n",
    "    mutate(CADD_consequence = paste(consequence,CADD_cat, sep = \"\"))\n",
    "  df_annotation_cadd_nona_output <- df_annotation_cadd_nona %>%\n",
    "      select(ID_r, Gene.refGeneWithVer, CADD_consequence)\n",
    "  \n",
    "  ### Set list file\n",
    "  length(unique(df_annotation_file_no_dup$Gene.refGeneWithVer))\n",
    "  df_set_list = df_annotation_file_no_dup %>% \n",
    "    arrange(Gene.refGeneWithVer, Start) %>%\n",
    "    group_by(Gene.refGeneWithVer) %>%\n",
    "    summarise(var_list = list(ID_r), start_list = list(Start), n_var = n())\n",
    "\n",
    "  columns = c(\"Gene.refGeneWithVer\", \"Chr\", \"start\", \"var\")\n",
    "  df_set_list_output = data.frame(matrix(nrow=nrow(df_set_list), ncol = length(columns)))\n",
    "  colnames(df_set_list_output) = columns\n",
    "  Chromosome = unique(df$Chr)\n",
    "  for (index in c(1:nrow(df_set_list))){\n",
    "      df_set_list_output[index,1] = df_set_list$Gene.refGeneWithVer[index]\n",
    "      df_set_list_output$Chr[index] = Chromosome\n",
    "      df_set_list_output$start[index] = min(unlist(df_set_list$start_list[index]))\n",
    "      df_set_list_output$var[index] = stri_paste(unlist(df_set_list$var_list[index]), collapse=',')\n",
    "      }\n",
    "  \n",
    "  ## Allele frequency file\n",
    "  #df_AAF = df_annotation_file_no_dup %>%\n",
    "  #  select(ID_r, AF_nfe) %>% \n",
    "  #  mutate(AF_nfe.1 = ifelse(is.na(AF_nfe) | AF_nfe == 0 | AF_nfe == \".\", \"0.0\", as.character(AF_nfe))) %>%\n",
    "  #  select(!AF_nfe)\n",
    "  #head(df_AAF)\n",
    "  #df_AAF_no_dup <- df_AAF[!duplicated(df_AAF), ]\n",
    "  #head(df_AAF_no_dup)\n",
    "\n",
    "  frequency_df_max_AF <- df_annotation_file_no_dup %>%\n",
    "      mutate(AF_gnomAD = ifelse(is.na(AF_gnomAD) | AF_gnomAD == 0 | AF_gnomAD == \".\", \"0.0\", as.character(AF_gnomAD))) %>%\n",
    "      select(ID_r, AF_gnomAD)\n",
    "\n",
    "  # Final allele frequency file with changes and no duplicated variants\n",
    "  frequency_df_max_AF_no_dup <- frequency_df_max_AF[!duplicated(frequency_df_max_AF),]\n",
    "  \n",
    "  write.table(df_annotation_cadd_nona_output, file = '${_output[0]}', row.names = FALSE, quote = FALSE, col.names = FALSE, sep = \" \", na = \"nan\")\n",
    "  write.table(frequency_df_max_AF_no_dup, file = '${_output[1]}', row.names = FALSE, quote = FALSE, col.names = FALSE, sep = \" \", na = \"nan\")\n",
    "  write.table(df_set_list_output, file = '${_output[2]}', row.names = FALSE, quote = FALSE, col.names = FALSE, sep = \" \", na = \"nan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
