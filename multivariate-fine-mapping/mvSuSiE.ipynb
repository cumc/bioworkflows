{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Multivariate fine-mapping workflow\n",
    "\n",
    "This notebook applies mvSuSiE on data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Three versions of pipelines are implemented:\n",
    "        \n",
    "1. Individual level data input `X`, `Y` and `C` (for covariates).\n",
    "2. Sufficient statistics input `XtX`, `XtY`, `YtY` and `n`. We assume covariates `C` have been removed from `X` and `Y`. We provide a procedure to implement this.\n",
    "3. GWAS summary statistics input `z` and `R`. We assume `z` scores have been computed after removal of covariates `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "Several file formats are supported:\n",
    "\n",
    "1. RDS format of a list of objects, in which case you can specify the names of objects corresponding to the quantities `X`, `Y`, `XtX`, etc.\n",
    "2. `pgen`/`psam`/`pvar` bundle for genotypes and text file for phenotypes.\n",
    "3. `bed`/`fam`/`bim` bundle for genotypes and text file for phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis unit we output:\n",
    "\n",
    "1. Analysis ready data-set in RDS format (in `cache` directory so you can remove at any time)\n",
    "2. Analysis results in RDS format\n",
    "3. Default visualization plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis examples\n",
    "\n",
    "```\n",
    "sos run mvSuSiE.ipynb complete_data_analysis \\\n",
    "    --analysis-units data/27_brain_non_brain_genes_v8.txt \\\n",
    "    --data-dir /project2/compbio/GTEx_eQTL/cis_eqtl_analysis_ready \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name 20210409 \\\n",
    "    --wd /project2/compbio/GTEx_eQTL/mvSuSiE_output/cis_results \\\n",
    "    --prior /project2/compbio/GTEx_eQTL/mvSuSiE_output/GTEx_V8_strong_z.teem.rds \\\n",
    "    -c midway2.yml -q midway2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/bioworkflows/multivariate-fine-mapping/mvSuSiE.ipynb complete_data_preprocess  \\\n",
    "    --analysis-units /home/hs3163/Project/mwe/data/rgs_lst \\\n",
    "    --data-dir /home/hs3163/Project/mwe/data/ \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name 20210509 \\\n",
    "    --wd ~/Project/mwe/new_mvsusie \\\n",
    "    --container /mnt/mfs/statgen/containers/twas_latest.sif \\\n",
    "    --prior /home/hs3163/Project/mwe/data/GTEx_V8_strong_z.teem.rds \\\n",
    "    -J 200 -q csg -c ~/GIT/neuro-twas/code/csg.yml -s build &\n",
    "\n",
    "\n",
    "\n",
    "nohup sos dryrun /home/hs3163/GIT/bioworkflows/multivariate-fine-mapping/mvSuSiE.ipynb complete_data_analysis \\\n",
    "    --analysis-units /home/hs3163/Project/mwe/data/rgs_lst \\\n",
    "    --data-dir /home/hs3163/Project/mwe/data/ \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name 20210509 \\\n",
    "    --wd /mnt/mfs/statgen/neuro-twas/mvsusie_polish \\\n",
    "    --container /mnt/mfs/statgen/containers/twas_latest.sif \\\n",
    "    --prior /home/hs3163/Project/mwe/data/GTEx_V8_strong_z.teem.rds \n",
    "\n",
    "nohup sos dryrun /home/hs3163/GIT/bioworkflows/multivariate-fine-mapping/mvSuSiE.ipynb complete_data_preprocess \\\n",
    "    --analysis-units /home/hs3163/Project/mwe/data/rgs_lst \\\n",
    "    --data-dir /home/hs3163/Project/mwe/data/ \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name 20210509 \\\n",
    "    --wd /mnt/mfs/statgen/neuro-twas/mvsusie_polish \\\n",
    "    --container /mnt/mfs/statgen/containers/twas_latest.sif \\\n",
    "    --prior /home/hs3163/Project/mwe/data/GTEx_V8_strong_z.teem.rds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# single column file each line is the data filename(gene_name)\n",
    "parameter: analysis_units = path\n",
    "# Path to data directory\n",
    "parameter: data_dir = path\n",
    "# An identifier for your run of analysis\n",
    "parameter: name = str\n",
    "# data file suffix\n",
    "parameter: data_suffix = str\n",
    "# data file prefix\n",
    "parameter: data_prefix = \"\"\n",
    "# Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "# Path to prior data file: an RDS file with `U` and `w` for prior matrices and weights\n",
    "parameter: prior = path('.')\n",
    "# Path to residual cor/cov data file\n",
    "parameter: resid_cor = path('.')\n",
    "# Only analyze `cis` variants -- cis = N means using N variants around the center column of X matrix  \n",
    "parameter: cis = 'NULL'\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = [f\"{data_dir:a}/{x}.{data_suffix}\" for x in regions if path(f\"{data_dir:a}/{x}.{data_suffix}\").exists()]\n",
    "# Containers that contains the necessary packages\n",
    "parameter: container = 'gaow/twas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_merging_1]\n",
    "input:  molecular_pheno_dir, for_each = \"regions\"\n",
    "output: f'{wd:a}/cache/{data_prefix}.{_regions[0]}.merged.bed'\n",
    "# Path to a list of molecular phenotypes that are to be merged, shall contains a cache file within it.\n",
    "parameter: molecular_pheno_dir = path\n",
    "molecular_pheno = [x.strip().split() for x in open(molecular_pheno_dir).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = '60G', tags = f'{step_name}_{_output[0]:bn}'  \n",
    "\n",
    "R: expand = \"$[ ]\", stderr = f'{_output[2]}.stderr', stdout = f'{_output[2]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    molecular_pheno = read_delim(\"$[molecular_pheno_dir]\",delim = \"\\t\")\n",
    "    molecular_pheno = molecular_pheno%>%mutate(dir = map_chr(`#molc_pheno`,~paste(c(`.x`,\"/cache/$[data_prefix].$[_regions[0]]\"),collapse = \"\")))\n",
    "    n = nrow(molecular_pheno)\n",
    "    # For every tissues read plink, and extract the fam df.\n",
    "    genos = tibble( i = 1:n)\n",
    "    genos = genos%>%mutate(fam = map(i, ~read_plink(molecular_pheno[[.x,2]])$fam%>%as_tibble()%>%mutate(name = paste(V1,\":\",V2,sep = \"\"))%>%select(name,V6)))\n",
    "    \n",
    "    # Join two tissues\n",
    "    genos_join_phe_$[_regions[0]] = full_join((genos%>%pull(fam))[[1]],(genos%>%pull(fam))[[2]],by = \"name\")\n",
    "    \n",
    "    # If there are more tissues, join the rest\n",
    "    if(n > 2){\n",
    "    for(j in 3:n){\n",
    "    genos_join_phe_$[_regions[0]] = full_join(genos_join_phe_$[_regions[0]],(genos%>%pull(fam))[[j]],by = \"name\")\n",
    "    }\n",
    "    }\n",
    "    genos_join_phe_$[_regions[0]]%>%readr::write_delim(\"$[_output[0]:n].merged.exp\",delim = \"\\t\")\n",
    "    \n",
    "    # Create merge list\n",
    "    molecular_pheno[2]%>%readr::write_delim(\"$[_output[0]:n].list\",delim = \"\\t\",col_names=FALSE)\n",
    "\n",
    "\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout',container = container\n",
    "    # create the merged output X\n",
    "    plink --bfile '$[next(iter(molecular_pheno[0]))]/cache/$[name_prefix].$[_regions[0]]'\\\n",
    "          --merge-list $[_output[0]:n].list \\\n",
    "          --mac 1 \\\n",
    "          --make-bed \\\n",
    "          --out $[_output[0]:n] \\\n",
    "          --allow-no-sex \\\n",
    "          --extract $[extract_snp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This needs pgenlibr package\n",
    "# devtools::install_github(\"chrchang/plink-ng\", subdir=\"/2.0/pgenlibr\")\n",
    "[complete_data_preprocess]\n",
    "# For RDS data\n",
    "parameter: x_table=\"\"\n",
    "parameter: y_table=\"\"\n",
    "parameter: z_table=\"\"\n",
    "# For PLINK data\n",
    "# Phenotype file, assuming a header\n",
    "parameter: phenoFile = path('.')\n",
    "parameter: phenoCols = []\n",
    "parameter: covarFile = path('.')\n",
    "parameter: covarCols = []\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_genes:n}.analysis_ready.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h', mem = '12G', cores = 2, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container\n",
    "\n",
    "    remove_covariate_effects <- function (X, Z, Y) {\n",
    "      # include the intercept term\n",
    "      if (any(Z[,1]!=1)) Z = cbind(1, Z)\n",
    "      # make Y a matrix\n",
    "      if (is.null(dim(Y))) Y = matrix(Y, length(Y), 1)\n",
    "      A   <- Matrix::forceSymmetric(crossprod(Z))\n",
    "      SZy <- as.vector(solve(A,c(y %*% Z)))\n",
    "      SZX <- as.matrix(solve(A,t(Z) %*% X))\n",
    "      SZY <- as.matrix(solve(A,t(Z) %*% Y))\n",
    "      X <- X - Z %*% SZX\n",
    "      y_res <- Y - Z %*% SZY\n",
    "      return(list(X = X,Y = Y, Z = Z, y_res = y_res))\n",
    "    }\n",
    "  \n",
    "    # read PLINK files\n",
    "    read_pvar <- function(pgen){\n",
    "      pvarf <- paste0(tools::file_path_sans_ext(pgen), \".pvar\")\n",
    "      pvardt <- data.table::fread(pvarf, skip = \"#CHROM\")\n",
    "      pvardt <- dplyr::rename(pvardt, \"chrom\" = \"#CHROM\", \"pos\" = \"POS\",\n",
    "                    \"alt\" = \"ALT\", \"ref\" = \"REF\", \"id\" = \"ID\")\n",
    "      pvardt <- pvardt[, c(\"chrom\", \"id\", \"pos\", \"alt\", \"ref\")]\n",
    "      return(pvardt)\n",
    "    }\n",
    "    \n",
    "    read_bim <- function(bed) {\n",
    "      bimf <- paste0(tools::file_path_sans_ext(bed), \".bim\")\n",
    "      bim <- data.table::fread(bimf)\n",
    "      colnames(bim) <- c(\"chrom\", \"id\", \"gpos\", \"pos\", \"a1\", \"a0\")\n",
    "      return(bim)\n",
    "    }\n",
    "    \n",
    "    read_psam <- function(pgen) {\n",
    "      psamf <- paste0(tools::file_path_sans_ext(pgen), \".psam\")\n",
    "      psam = data.table::fread(psamf, header=T)\n",
    "      colnames(psam)[1:2] = c(\"FID\", \"IID\")\n",
    "      return(psam)\n",
    "    }\n",
    "  \n",
    "    read_fam <- function(bed) {\n",
    "        famf <- paste0(tools::file_path_sans_ext(bed), \".fam\")\n",
    "        return(data.table::fread(famf, header = F))\n",
    "    }\n",
    "\n",
    "    # open pgen/pvar PLINK 2 data format\n",
    "    open_pgen <- function(pgenf){\n",
    "        return(pgenlibr::NewPgen(pgenf))\n",
    "    } \n",
    "\n",
    "    # open bed/bim/fam: A PLINK 1 .bed is a valid .pgen\n",
    "    open_bed <- function(bed){\n",
    "        raw_s_ct <- nrow(read_fam(bed))\n",
    "        return(pgenlibr::NewPgen(bed, raw_sample_ct = raw_s_ct))\n",
    "    }\n",
    "\n",
    "    read_pgen <- function(pgen, variantidx = NULL, meanimpute = F ) {\n",
    "      if (is.null(variantidx)){\n",
    "        variantidx <- 1: pgenlibr::GetVariantCt(pgen)}\n",
    "\n",
    "      pgenlibr::ReadList(pgen,\n",
    "                         variant_subset = variantidx,\n",
    "                         meanimpute = meanimpute)\n",
    "    }\n",
    "\n",
    "    genof = ${path(_geno):ar}\n",
    "    ext = tools::file_ext(genof)\n",
    "    if (ext == 'rds') {\n",
    "      dat = readRDS(genof)\n",
    "      X = dat$${x_table}\n",
    "      Y = dat$${y_table}\n",
    "      Z = dat$${z_table}\n",
    "    } else if (ext == 'pgen' || ext == 'bed') {\n",
    "      if (ext == 'pgen') X = read_pgen(open_pgen(genof))\n",
    "      else X = read_pgen(open_bed(genof))\n",
    "      Y = read_sample(${phenoFile:r}, c(${paths(phenoCols):,r})\n",
    "      if (tools::file.exists(${covarFile:r})) {\n",
    "          Z = read_sample(${covarFile:r}, c(${paths(covarCols):,r}) # return this: %>% select(-FID, -IID) %>% as.matrix\n",
    "      } else {\n",
    "          Z = NULL\n",
    "      }\n",
    "    } else {\n",
    "      stop(\"Unsupported genotype format\")\n",
    "    }\n",
    "    # match X and Y data\n",
    "    match.idx = match(rownames(X), rownames(Y))\n",
    "    Y = Y[match.idx,]\n",
    "    # center Y\n",
    "    Y = sweep(Y, 2, colMeans(Y), '-')\n",
    "    if (!is.null(Z)) {\n",
    "        match.idx = match(rownames(Y), rownames(Z))\n",
    "        Z = Z[match.idx,]\n",
    "        Z = sweep(Z, 2, colMeans(Z), '-')\n",
    "    }\n",
    "    \n",
    "   # Remove covariate effect\n",
    "    if(!is.null(Z)){\n",
    "  \n",
    "  }\n",
    "  \n",
    "  \n",
    "    \n",
    "    # FIXME: not working; to be completed\n",
    "    # FIXME: need to remove Z from X and Y\n",
    "    # https://github.com/gaow/mvarbvs/blob/master/workflow/GTEx_V8_preprocessing.ipynb\n",
    "    # What if different Y have different missing? We cannot remove Z from X then ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[complete_data_analysis_1]\n",
    "parameter: x_table = 'X'\n",
    "parameter: y_table = 'y_res'\n",
    "# remove a variant if it has more than imiss missing individual data\n",
    "parameter: imiss = 0.1\n",
    "parameter: maf = 0.05\n",
    "parameter: max_L = 5\n",
    "input: genes, group_by = 1\n",
    "output: mvsusie = f'{wd:a}/{_input:bn}{(\"_cis_%s\" % cis) if cis != \"NULL\" else \"\"}_{name}.mvsusie.rds',\n",
    "        susie = f'{wd:a}/{_input:bn}{(\"_cis_%s\" % cis) if cis != \"NULL\" else \"\"}_{name}.susie.rds',\n",
    "        ss = f'{wd:a}/{_input:bn}{(\"_cis_%s\" % cis) if cis != \"NULL\" else \"\"}_{name}.sumstat.rds',\n",
    "        vary = f'{wd:a}/{_input:bn}{(\"_cis_%s\" % cis) if cis != \"NULL\" else \"\"}_{name}.covY_flash.rds'\n",
    "# task: trunk_workers = 1, trunk_size = 36, walltime = '36h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '36h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container\n",
    "    \n",
    "    ###\n",
    "    # Utility functions\n",
    "    ###\n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "\n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "    \n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "\n",
    "    is_zero_variance <- function(x) {\n",
    "      if (length(unique(x))==1) return(T)\n",
    "      else return(F)\n",
    "    }\n",
    "  \n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh) {\n",
    "        rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "        if (length(rm_col)) X <- X[, -rm_col]\n",
    "        rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "        if (length(rm_col)) X <- X[, -rm_col]\n",
    "        rm_col <- which(apply(X, 2, is_zero_variance))\n",
    "        if (length(rm_col)) X <- X[, -rm_col]\n",
    "        return(mean_impute(X))\n",
    "    }\n",
    "\n",
    "    compute_cov_flash <- function(Y, error_cache = NULL){\n",
    "        covar <- diag(ncol(Y))\n",
    "        tryCatch({\n",
    "        fl <- flashier::flash(Y, var.type = 2, prior.family = c(flashier::prior.normal(), flashier::prior.normal.scale.mix()), backfit = TRUE, verbose.lvl=0)\n",
    "        if(fl$n.factors==0){\n",
    "          covar <- diag(fl$residuals.sd^2)\n",
    "        } else {\n",
    "          fsd <- sapply(fl$fitted.g[[1]], '[[', \"sd\")\n",
    "          covar <- diag(fl$residuals.sd^2) + crossprod(t(fl$flash.fit$EF[[2]]) * fsd)\n",
    "        }\n",
    "        if (nrow(covar) == 0) {\n",
    "          covar <- diag(ncol(Y))\n",
    "          stop(\"Computed covariance matrix has zero rows\")\n",
    "        }\n",
    "        }, error = function(e) {\n",
    "          if (!is.null(error_cache)) {\n",
    "            saveRDS(list(data=Y, message=warning(e)), error_cache)\n",
    "            warning(\"FLASH failed. Using Identity matrix instead.\")\n",
    "            warning(e)\n",
    "          } else {\n",
    "            stop(e)\n",
    "          }\n",
    "        })\n",
    "        s <- apply(Y, 2, sd, na.rm=T)\n",
    "        if (length(s)>1) s = diag(s)\n",
    "        else s = matrix(s,1,1)\n",
    "        covar <- s%*%cov2cor(covar)%*%s\n",
    "        return(covar)\n",
    "    }\n",
    "  \n",
    "    compute_cov_diag <- function(Y){\n",
    "        covar <- diag(apply(Y, 2, var, na.rm=T))\n",
    "        return(covar)\n",
    "    }\n",
    "\n",
    "    get_center <- function(k,n) {\n",
    "      ## For given number k, get the range k surrounding n/2\n",
    "      ## but have to make sure it does not go over the bounds\n",
    "      if (is.null(k)) {\n",
    "          return(1:n)\n",
    "      }\n",
    "      start = floor(n/2 - k/2)\n",
    "      end = floor(n/2 + k/2)\n",
    "      if (start<1) start = 1\n",
    "      if (end>n) end = n\n",
    "      return(start:end)\n",
    "    }\n",
    "    \n",
    "    get_prior_indices <- function(Y, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      y_names = colnames(Y)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(y_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(y_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(y_names, u_names))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    ###\n",
    "    # Core code\n",
    "    ###\n",
    "    dat = readRDS(${_input:r})\n",
    "    y_res = dat$${y_table}\n",
    "    if (file.exists(${_output[3]:r})) {\n",
    "      resid_Y = readRDS(${_output[3]:r})\n",
    "    } else {\n",
    "      resid_Y = compute_cov_flash(y_res)\n",
    "      saveRDS(resid_Y, ${_output[3]:r})\n",
    "    }\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), include_indices = get_prior_indices(y_res, prior$U[[1]]), max_mixture_len=-1)\n",
    "    X = filter_X(dat$${x_table}, ${imiss}, ${maf})\n",
    "    X = X[,get_center(${cis}, ncol(X))]\n",
    "    print(paste(\"Dimension of X matrix:\", nrow(X), ncol(X)))\n",
    "    print(paste(\"Dimension of Y matrix:\", nrow(y_res), ncol(y_res)))\n",
    "      \n",
    "    # Fine-mapping with SuSiE\n",
    "    fitted = list()\n",
    "    non_missing = list()\n",
    "    for (r in 1:ncol(y_res)) {\n",
    "        non_missing[[r]] = which(!is.na(y_res[,r]))\n",
    "        st = proc.time()\n",
    "        fitted[[r]] <- susieR::susie(X[non_missing[[r]],], y_res[non_missing[[r]],r],\n",
    "                           L=${max_L},\n",
    "                           max_iter=1000,\n",
    "                           estimate_residual_variance=TRUE,\n",
    "                           estimate_prior_variance=TRUE,\n",
    "                           refine=TRUE)\n",
    "        fitted[[r]]$time = proc.time() - st\n",
    "        fitted[[r]]$cs_corr = susieR:::get_cs_correlation(fitted[[r]], X=X[non_missing[[r]],])\n",
    "    }\n",
    "\n",
    "    saveRDS(fitted, ${_output[1]:r})\n",
    "    \n",
    "    # GWAS Summary statistics\n",
    "    univariate_res = lapply(1:ncol(y_res), function(r) susieR:::univariate_regression(X[non_missing[[r]], ], y_res[non_missing[[r]], r]))\n",
    "    bhat = do.call(cbind, lapply(1:ncol(y_res), function(r) univariate_res[[r]]$betahat))\n",
    "    sbhat = do.call(cbind, lapply(1:ncol(y_res), function(r) univariate_res[[r]]$sebetahat))\n",
    "    saveRDS(list(bhat=bhat, sbhat=sbhat), ${_output[2]:r})\n",
    "    rm(bhat)\n",
    "    rm(sbhat)\n",
    "    rm(fitted)\n",
    "    rm(non_missing)\n",
    "    # Multivariate fine-mapping\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie(X, y_res, L=${max_L}, \n",
    "                              prior_variance=prior, residual_variance=resid_Y, \n",
    "                              precompute_covariances=F, compute_objective=T, \n",
    "                              estimate_residual_variance=F, estimate_prior_variance=T, estimate_prior_method='EM',\n",
    "                              max_iter = 100, n_thread=1, approximate=F)\n",
    "    mv_res$time = proc.time() - st\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, X=X)\n",
    "    saveRDS(mv_res, ${_output[0]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Convert LD store file to RDS format\n",
    "[ldstore_to_rds]\n",
    "parameter: ld_dir = path\n",
    "ld_files = glob.glob(f\"{ld_dir:a}/{name}*.matrix\")\n",
    "input: ld_files, group_by = 1\n",
    "output: f\"{cwd:a}/{_input:bn}.ld.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h', mem = '20G', cores = 2, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", container = container\n",
    "    ld = as.matrix(data.table::fread(${_input:r}))\n",
    "    saveRDS(ld, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sufficient_summary_stats_preprocessing]\n",
    "parameter: phenoFile = path\n",
    "parameter: covarFile = path\n",
    "# path to z score file\n",
    "parameter: z_dir = path()\n",
    "parameter: z_suffix = str\n",
    "# path to LD file\n",
    "parameter: ld_dir = path()\n",
    "parameter: ld_suffix = str\n",
    "input: genes, group_by = 1\n",
    "output: suffstats = f\"{wd:a}/{_input:bn}.sufficient_stats.rds\", \n",
    "        sumstats =  f\"{wd:a}/{_input:bn}.summary_stats.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h', mem = '200G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container\n",
    "    # FIXME: in practice we might need to \n",
    "    geno_file = ${_input:nr}\n",
    "    z.file = \"${z_dir:a}/${_input:bn}.${z_suffix}\"\n",
    "    ld.file = \"${ld_dir:a}/${_input:bn}.${ld_suffix}\"\n",
    "    library(data.table)\n",
    "    library(dplyr)\n",
    "    \n",
    "    X <- fread(paste0(geno_file, '.raw.gz'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    map <- X[,1:6]\n",
    "    X = X[, c('FID','IID','PAT','MAT','SEX', 'PHENOTYPE') := NULL]\n",
    "    X <- as.matrix(X)\n",
    "    \n",
    "    X.info = fread(paste0(geno_file, '.pvar'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    \n",
    "    # Read phenotype data\n",
    "    cat(\"Reading phenotype data.\\n\")\n",
    "    pheno <- suppressMessages(fread(${phenoFile:r}))\n",
    "\n",
    "    cat(\"Reading covariate file.\\n\")\n",
    "    Z = suppressMessages(fread(${covarFile:r}))\n",
    "\n",
    "    match.idx = match(map$IID, pheno$IID)\n",
    "    pheno = pheno[match.idx,]\n",
    "    match.idx = match(map$IID, Z$IID)\n",
    "    Z = Z[match.idx,]\n",
    "  \n",
    "    Y = pheno %>% select(-FID, -IID) %>% as.matrix\n",
    "    Z = Z %>% select(-FID, -IID) %>% as.matrix\n",
    "  \n",
    "    # centering\n",
    "    Y = sweep(Y, 2, colMeans(Y), '-')\n",
    "    Z = sweep(Z, 2, colMeans(Z), '-')\n",
    "  \n",
    "    A   <- crossprod(Z) # Z'Z\n",
    "    # chol decomposition for (Z'Z)^(-1)\n",
    "    R = chol(solve(A)) # R'R = (Z'Z)^(-1)\n",
    "    W = R %*% crossprod(Z, X) # RZ'X\n",
    "    S = R %*% crossprod(Z, Y) # RZ'Y\n",
    "\n",
    "    SNPnames = colnames(X)\n",
    "    rm(X)\n",
    "    rm(Z)\n",
    "\n",
    "    zscores = readRDS(z.file)\n",
    "\n",
    "    # Load LD matrix from raw genotype\n",
    "    ld = readRDS(ld.file)\n",
    "    XtX = sqrt(zscores$XtXD) * t(ld*sqrt(zscores$XtXD)) - crossprod(W) # W'W = X'ZR'RZ'X = X'Z(Z'Z)^{-1}Z'X\n",
    "    XtX = as.matrix(XtX)\n",
    "    rownames(XtX) = colnames(XtX) = SNPnames\n",
    "    R = cov2cor(XtX)\n",
    "\n",
    "    # X'Y\n",
    "    ## flip sign because X flip the REF, ALT\n",
    "    XtY = -as.matrix(zscores$XtY - crossprod(W, S)) # W'S = X'ZR'RZ'y = X'Z(Z'Z)^{-1}Z'y\n",
    "\n",
    "    # YtY\n",
    "    YtY = as.matrix(crossprod(Y) - crossprod(S))\n",
    "\n",
    "    Z = as.matrix(zscores$Z)\n",
    "    rownames(Z) = SNPnames\n",
    "    \n",
    "    meta = zscores$pos[,1:5]\n",
    "    if(!all.equal(meta, X.info, check.attributes = FALSE)){\n",
    "        stop(\"ALLELE doesn't amtch.\")\n",
    "    }\n",
    "\n",
    "    saveRDS(list(XtX = XtX, XtY = XtY, YtY = YtY, N = nrow(Y), meta = zscores$pos), ${_output[\"suffstats\"]:r})\n",
    "    saveRDS(list(Z = Z, LD = R, meta = zscores$pos, ld.file = ld.file), ${_output[\"sumstats\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[univariate_analysis_1]\n",
    "parameter: max_L = 10\n",
    "input: genes, group_by = 1\n",
    "output: suff = f\"{wd:a}/{_input:bnn}.susiesuff.rds\", \n",
    "        rss_rem_covariates =  f\"{wd:a}/{_input:bnn}.susierss_rem_covariates.rds\",\n",
    "        rss_notrem_covariates =  f\"{wd:a}/{_input:bnn}.susierss_notrem_covariates.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '5h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bnn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container\n",
    "    library(susieR)\n",
    "    dat_suff = readRDS('${_input:nn}.sufficient_stats.rds')\n",
    "    dat_rss = readRDS('${_input:nn}.summary_stats.rds')\n",
    "    R = readRDS(dat_rss$ld.file)\n",
    "    rownames(R) = colnames(R) = rownames(dat_rss$LD)\n",
    "    fitted_suff = list()\n",
    "    fitted_rss_rem_covariates = list()\n",
    "    fitted_rss_notrem_covariates = list()\n",
    "    for (r in 1:ncol(dat_suff$XtY)) {\n",
    "        ## sufficient stats\n",
    "        st = proc.time()\n",
    "        fitted_suff[[r]] <- susieR::susie_suff_stat(XtX = dat_suff$XtX, \n",
    "                                               Xty = dat_suff$XtY[,r],\n",
    "                                               yty = dat_suff$YtY[r,r], n = dat_suff$N,\n",
    "                                               L=${max_L},\n",
    "                                               max_iter=1000,\n",
    "                                               estimate_residual_variance=TRUE,\n",
    "                                               estimate_prior_variance=TRUE,\n",
    "                                               refine=TRUE)\n",
    "        fitted_suff[[r]]$time = proc.time() - st\n",
    "        fitted_suff[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_suff[[r]], Xcorr=cov2cor(dat_suff$XtX))\n",
    "        \n",
    "        ## rss, LD correct for covariates\n",
    "        st = proc.time()\n",
    "        fitted_rss_rem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],\n",
    "                                                            R = dat_rss$LD,\n",
    "                                                            L=${max_L},\n",
    "                                                            max_iter=1000,\n",
    "                                                            estimate_prior_variance=TRUE,\n",
    "                                                            refine=TRUE)\n",
    "        fitted_rss_rem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_rem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_rem_covariates[[r]], \n",
    "                                                                             Xcorr=dat_rss$LD)\n",
    "        \n",
    "        ## rss, LD not correct for covariates\n",
    "        st = proc.time()\n",
    "        fitted_rss_notrem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],R = R,\n",
    "                                                               L=${max_L},max_iter=1000,\n",
    "                                                               estimate_prior_variance=TRUE,\n",
    "                                                               refine=TRUE)\n",
    "        fitted_rss_notrem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_notrem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_notrem_covariates[[r]], \n",
    "                                                                                Xcorr=R)\n",
    "    }\n",
    "    \n",
    "    names(fitted_suff) = colnames(dat_suff$XtY)\n",
    "    names(fitted_rss_rem_covariates) = colnames(dat_suff$XtY)\n",
    "    names(fitted_rss_notrem_covariates) = colnames(dat_suff$XtY)\n",
    "        \n",
    "    saveRDS(fitted_suff, ${_output[\"suff\"]:r})\n",
    "    saveRDS(fitted_rss_rem_covariates, ${_output[\"rss_rem_covariates\"]:r})\n",
    "    saveRDS(fitted_rss_notrem_covariates, ${_output[\"rss_notrem_covariates\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sufficient_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_input:bnn}{resid_cor:bnx}.mvsusiesuff.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    V = readRDS(${resid_cor:r})\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$XtY, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_suff_stat(dat$XtX, dat$XtY, dat$YtY, dat$N, L=${max_L}, \n",
    "                                         prior_variance=prior, residual_variance=V, \n",
    "                                         precompute_covariances=T, compute_objective=T, \n",
    "                                         estimate_residual_variance=F, estimate_prior_variance=T, \n",
    "                                         estimate_prior_method='EM',max_iter = 1000, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    if(mv_res$convergence$converged == FALSE){\n",
    "        stop('Fail to converge.')\n",
    "    }\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=cov2cor(dat$XtX))\n",
    "    saveRDS(mv_res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[summary_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "parameter: ld_type = 'original'\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_input:bnn}.LD{ld_type}{resid_cor:bnx}.mvsusierss.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    V = readRDS(${resid_cor:r})\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$Z, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    if(\"${ld_type}\" == 'original'){\n",
    "        R = readRDS(dat$ld.file)\n",
    "    }else if(\"${ld_type}\" == 'remove_cov'){\n",
    "        R = dat$LD\n",
    "    }\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_rss(dat$Z, R, L=${max_L}, \n",
    "                                   prior_variance=prior, residual_variance=V, \n",
    "                                   precompute_covariances=T, compute_objective=T, \n",
    "                                   estimate_prior_variance=T, estimate_prior_method='EM',\n",
    "                                   max_iter = 1000, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    if(mv_res$convergence$converged == FALSE){\n",
    "        stop('Fail to converge.')\n",
    "    }\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=R)\n",
    "    saveRDS(mv_res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[*_analysis_2]\n",
    "output: f\"{_input[0]:nn}.manhattan.png\", f\"{_input[0]:nn}.bubble_finemap.png\", f\"{_input[0]:nn}.bubble_original.png\"\n",
    "R: expand = '${ }', container = container\n",
    "    res = readRDS(${_input[0]:r})\n",
    "    pdf('${_output[0]:n}.pdf', width=8, height=4)\n",
    "    susieR::susie_plot(res,y='PIP', main = 'Cross-condition Posterior Inclusion Probability', xlab = 'SNP positions', add_legend = F)\n",
    "    dev.off()\n",
    "    p = mvsusieR::mvsusie_plot(res)\n",
    "    pdf('${_output[1]:n}.pdf', width = p$width, height = p$height)\n",
    "    print(p$plot)\n",
    "    dev.off()\n",
    "    p = mvsusieR::mvsusie_plot(res, plot_z=TRUE)\n",
    "    pdf('${_output[2]:n}.pdf', width = p$width, height = p$height)\n",
    "    print(p$plot)\n",
    "    dev.off()\n",
    "\n",
    "bash: expand = '${ }'\n",
    "    convert -density 150 ${_output[0]:n}.pdf ${_output[0]}\n",
    "    convert -density 150 ${_output[1]:n}.pdf ${_output[1]}\n",
    "    convert -density 150 ${_output[2]:n}.pdf ${_output[2]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
