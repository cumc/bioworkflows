{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# A multivariate EBNM approach for mixture multivariate distribution estimate\n",
    "\n",
    "An earlier version of the approach is outlined in Urbut et al 2019. This workflow implements a few improvements including using additional EBMF methods as well as the new `udr` package to fit the mixture model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview of approach\n",
    "\n",
    "1. A workflow step is provided to merge PLINK univariate association analysis results to RDS files for extracting effect estimate samples\n",
    "2. Estimated effects are analyzed by FLASH and PCA to extract patterns of sharing\n",
    "3. Estimate the weights for patterns extracted from previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To see the input requirements and output data formats, please [download a minimal working example here](https://drive.google.com/file/d/1838xUOQuWTszQ0WJGXNiJMszY05cw3RS/view?usp=sharing), and run the following:\n",
    "\n",
    "### Convert PLINK univariate results\n",
    "\n",
    "```\n",
    "sos run mixture_prior.ipynb convert_plink \\\n",
    "    --analysis-units <FIXME> \\\n",
    "    --plink-sumstats <FIXME> \\\n",
    "    --name gtex_mixture\n",
    "```\n",
    "\n",
    "### Select and merge univariate effects\n",
    "\n",
    "```\n",
    "for m in mnm_sumstats/artificial_mixture_identity mnm_sumstats/gtex_mixture_identity; do\n",
    "    cd $m && ls *.rds | sed 's/\\.rds//g' > analysis_units.txt && cd -\n",
    "    sos run mixture_prior.ipynb extract_effects \\\n",
    "        --analysis-units $m/analysis_units.txt \\\n",
    "        --datadir $m --name `basename $m`\n",
    "done &> extract_effects.log\n",
    "```\n",
    "\n",
    "### Perform mixture model fitting\n",
    "\n",
    "```\n",
    "for m in mnm_sumstats/artificial_mixture_identity mnm_sumstats/gtex_mixture_identity; do\n",
    "    sos run mixture_prior.ipynb ud \\\n",
    "        --datadir $m --name `basename $m` &> ed_$m.log\n",
    "    sos run mixture_prior.ipynb ud --ud-method teem \\\n",
    "        --datadir $m --name `basename $m` &> teem_$m.log\n",
    "    sos run mixture_prior.ipynb ed \\\n",
    "        --datadir $m --name `basename $m` &> bovy_$m.log\n",
    "done\n",
    "```\n",
    "\n",
    "Notice that for production use, each `sos run` command should be submitted to the cluster as a job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./output')\n",
    "# The filename prefix for output data\n",
    "parameter: name = str\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca', 'canonical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge univariate association summary statistic to RDS format\n",
    "\n",
    "**FIXME: this step has not been tested**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[convert_plink]\n",
    "parameter: plink_sumstats = path\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "regions = [x.strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input:  plink_sumstats, for_each = \"regions\"\n",
    "output: f'{wd:a}/RDS/{_regions[0]}.rds'\n",
    "\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = '6G', tags = f'{step_name}_{_output:bn}'  \n",
    "\n",
    "R: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    molecular_pheno = read_delim($[plink_sumstats:r], delim = \"\\t\")\n",
    "    molecular_pheno = molecular_pheno%>%mutate(dir = map_chr(`#molc_pheno`,~paste(c(`.x`,\"$[_regions[0]]\"),collapse = \"\")))\n",
    "    n = nrow(molecular_pheno)\n",
    "    # For every condition read rds and extract the bhat and sbhat.\n",
    "    genos = tibble( i = 1:n)\n",
    "    genos = genos%>%mutate(bhat = map(i, ~readRDS(molecular_pheno[[.x,2]])$bhat%>%as.data.frame%>%rownames_to_column),\n",
    "                           sbhat = map(i, ~readRDS(molecular_pheno[[.x,2]])$sbhat%>%as.data.frame%>%rownames_to_column))\n",
    "                      \n",
    "    # Join first two conditions\n",
    "    genos_join_bhat = full_join((genos%>%pull(bhat))[[1]],(genos%>%pull(bhat))[[2]],by = \"rowname\")\n",
    "    genos_join_sbhat = full_join((genos%>%pull(sbhat))[[1]],(genos%>%pull(sbhat))[[2]],by = \"rowname\")\n",
    "    \n",
    "    # If there are more conditions, join the rest\n",
    "    if(n > 2){\n",
    "        for(j in 3:n){\n",
    "            genos_join_bhat = full_join(genos_join_bhat,(genos%>%pull(bhat))[[j]],by = \"rowname\")%>%select(-rowname)%>%as.matrix\n",
    "            genos_join_sbhat = full_join(genos_join_sbhat,(genos%>%pull(sbhat))[[j]],by = \"rowname\")%>%select(-rowname)%>%as.matrix\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # save the rds file\n",
    "    saveRDS(\"$[_output]\", list(bhat=genos_join_bhat, sbhat=genos_join_sbhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get top, random and null effects per analysis unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data for MASH from summary stats\n",
    "[extract_effects_1]\n",
    "parameter: datadir = path\n",
    "parameter: seed = 999\n",
    "parameter: n_random = 4\n",
    "parameter: n_null = 4\n",
    "parameter: z_only = True\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "regions = [x.strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: [f'{datadir}/{x[0]}.rds' for x in regions], group_by = per_chunk\n",
    "output: f\"{cwd}/{name}/cache/{name}_{_index+1}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat)] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    extract_one_data = function(infile, n_random, n_null) {\n",
    "        # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "        dat = tryCatch(readRDS(infile)$sumstats, error = function(e) return(NULL))\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        z = abs(dat$bhat/dat$sbhat)\n",
    "        max_idx = matxMax(z)\n",
    "        # strong effect samples\n",
    "        strong = list(bhat = dat$bhat[max_idx[1],,drop=F], sbhat = dat$sbhat[max_idx[1],,drop=F])\n",
    "        # random samples excluding the top one\n",
    "        if (max_idx[1] == 1) {\n",
    "            sample_idx = 2:nrow(z)\n",
    "        } else if (max_idx[1] == nrow(z)) {\n",
    "            sample_idx = 1:(max_idx[1]-1)\n",
    "        } else {\n",
    "            sample_idx = c(1:(max_idx[1]-1), (max_idx[1]+1):nrow(z))\n",
    "        }\n",
    "        random_idx = sample(sample_idx, min(n_random, length(sample_idx)), replace = F)\n",
    "        random = list(bhat = dat$bhat[random_idx,,drop=F], sbhat = dat$sbhat[random_idx,,drop=F])\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(z), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(bhat = dat$bhat[null_idx,,drop=F], sbhat = dat$sbhat[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(random = remove_rownames(random), null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$random = handle_nan_etc(dat$random)\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        return(dat)\n",
    "    }\n",
    "    reformat_data = function(dat, z_only = TRUE) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(random.z = dat$random$bhat/dat$random$sbhat, \n",
    "                  strong.z = dat$strong$bhat/dat$strong$sbhat,  \n",
    "                  null.z = dat$null$bhat/dat$null$sbhat)\n",
    "        if (!z_only) {\n",
    "          res = c(res, list(random.b = dat$random$bhat,\n",
    "           strong.b = dat$strong$bhat,\n",
    "           null.b = dat$null$bhat,\n",
    "           null.s = dat$null$sbhat,\n",
    "           random.s = dat$random$sbhat,\n",
    "           strong.s = dat$strong$sbhat))\n",
    "      }\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    res = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      res = merge_data(res, reformat_data(extract_one_data(f, ${n_random}, ${n_null}), ${\"TRUE\" if z_only else \"FALSE\"}))\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[extract_effects_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    # compute null correlation matrix\n",
    "    dat$null.cor = cor(dat$null.z)\n",
    "    # compute empirical covariance XtX\n",
    "    dat$XtX = t(as.matrix(dat$strong.z)) %*% as.matrix(dat$strong.z) / nrow(dat$strong.z)\n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Factor analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[flash]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.flash.rds\"\n",
    "task: trunk_workers = 1, walltime = '6h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_flash(dat, factors=\"default\", remove_singleton=${\"TRUE\" if \"canonical\" in mixture_components else \"FALSE\"}, output_model=\"${_output:n}.model.rds\")\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[flash_nonneg]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.flash_nonneg.rds\"\n",
    "task: trunk_workers = 1, walltime = '6h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_flash(dat, factors=\"nonneg\", remove_singleton=${\"TRUE\" if \"canonical\" in mixture_components else \"FALSE\"}, output_model=\"${_output:n}.model.rds\")\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca]\n",
    "parameter: npc = 3\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.pca.rds\"\n",
    "task: trunk_workers = 1, walltime = '2h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_pca(dat, ${npc})\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[canonical]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.canonical.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '8G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_canonical(dat)\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Fit mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Installed commit d6d4c0e\n",
    "[ud]\n",
    "# Method is `ed` or `teem`\n",
    "parameter: ud_method = \"ed\"\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f\"{cwd}/{name}.{ud_method}.rds\"\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    for (f in rds_files[2:length(rds_files)]) U = c(U, readRDS(f))\n",
    "    # Fit mixture model using udr package\n",
    "    library(udr)\n",
    "    message(paste(\"Running ${ud_method.upper()} via udr package for\", length(U), \"mixture components\"))\n",
    "    f0 = ud_init(X = as.matrix(dat$strong.z), V = dat$null.cor, U_scaled = list(), U_unconstrained = U, n_rank1=0)\n",
    "    res = ud_fit(f0, control = list(unconstrained.update = \"${ud_method}\", resid.update = 'none', maxiter=5000, tol = 1e-06), verbose=TRUE)\n",
    "    saveRDS(list(U=res$U, w=res$w, loglik=res$loglik), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ed]\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f\"{cwd}/{name}.ed_bovy.rds\"\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    for (f in rds_files[2:length(rds_files)]) U = c(U, readRDS(f))\n",
    "    # Fit mixture model using ED code by J. Bovy\n",
    "    mash_data = mashr::mash_set_data(dat$strong.z, V=dat$null.cor)\n",
    "    message(paste(\"Running ED via J. Bovy's code for\", length(U), \"mixture components\"))\n",
    "    res = mashr:::bovy_wrapper(mash_data, U, logfile=${_output:nr}, tol = 1e-06)\n",
    "    saveRDS(list(U=res$Ulist, w=res$pi, loglik=scan(\"${_output:n}_loglike.log\")), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Plot patterns of sharing\n",
    "\n",
    "This is a simple utility function that takes the output from the pipeline above and make some heatmap to show major patterns of multivariate effects. The plots will be ordered by their mixture weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plot_U]\n",
    "parameter: model_data = path\n",
    "# number of components to show\n",
    "parameter: max_comp = -1\n",
    "# whether or not to convert to correlation\n",
    "parameter: to_cor = False\n",
    "parameter: remove_label = False\n",
    "input: model_data\n",
    "output: f'{cwd:a}/{_input:bn}{(\".\" + name) if name != \"\" else \"\"}.pdf'\n",
    "R: expand = \"${ }\"\n",
    "    plot_sharing = function(X, to_cor=FALSE, title=\"\", remove_names=F) {\n",
    "        clrs <- colorRampPalette(rev(c(\"#D73027\",\"#FC8D59\",\"#FEE090\",\"#FFFFBF\",\n",
    "                                       \"#E0F3F8\",\"#91BFDB\",\"#4575B4\")))(128)\n",
    "        if (to_cor) lat <- cov2cor(X)\n",
    "        else lat = X/max(diag(X))\n",
    "        lat[lower.tri(lat)] <- NA\n",
    "        n <- nrow(lat)\n",
    "        if (remove_names) {\n",
    "          colnames(lat) = NULL\n",
    "          rownames(lat) = NULL\n",
    "        }\n",
    "        return(lattice::levelplot(lat[n:1,],col.regions = clrs,\n",
    "                                xlab = \"\",ylab = \"\", main=title,\n",
    "                                colorkey = TRUE,at = seq(-1,1,length.out = 128),\n",
    "                                scales = list(cex = 0.6,x = list(rot = 45))))\n",
    "    }\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    model = \"${name}\"\n",
    "    if (model != \"\") {\n",
    "      if (! (model %in% names(dat))) stop(paste(\"Cannot find data\", model, \"Avaiable data are\", paste(names(dat), collapse=\" \")))\n",
    "        dat = dat[[model]]\n",
    "    }\n",
    "    if (is.null(names(dat$U))) names(dat$U) = paste0(\"Comp_\", 1:length(dat$U))\n",
    "    meta = data.frame(names(dat$U), dat$w, stringsAsFactors=F)\n",
    "    print(dim(meta))\n",
    "    colnames(meta) = c(\"U\", \"w\")\n",
    "    tol = 1E-16\n",
    "    n_comp = length(meta$U[which(dat$w>tol)])\n",
    "    meta = head(meta[order(meta[,2], decreasing = T),], ${max_comp if max_comp > 1 else \"nrow(meta)\"})\n",
    "    message(paste(n_comp, \"components out of\", length(dat$w), \"total components have weight greater than\", tol))\n",
    "    res = list()\n",
    "    for (i in 1:nrow(meta)) {\n",
    "        title = paste(model, meta$U[i], \"w =\", round(meta$w[i], 6))\n",
    "        res[[i]] = plot_sharing(dat$U[[meta$U[i]]], to_cor = ${\"T\" if to_cor else \"F\"}, title=title, remove_names = ${\"TRUE\" if remove_label else \"FALSE\"})\n",
    "    }\n",
    "    unit = 4\n",
    "    n_col = 5\n",
    "    n_row = ceiling(nrow(meta) / n_col)\n",
    "    pdf(${_output:r}, width = unit * n_col, height = unit * n_row)\n",
    "    do.call(gridExtra::grid.arrange, c(res, list(ncol = n_col, nrow = n_row)))\n",
    "    dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
