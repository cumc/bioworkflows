{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Identifying loci of interest from GWAS\n",
    "\n",
    "The aim is to select subsets of SNPs of possible interest (low p-value) from GWAS. We use LD clumping method to account for LD between SNPs. The output of LD clumping is a subset of independent SNPs for each locus of interest. We will use these SNPs to establish boundaries for these loci to be investigated further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- Summary statistics\n",
    "- LD reference panel\n",
    "\n",
    "**Settings for clumping analysis:**\n",
    "\n",
    "1. Which reference dataset to use? Options are 1000G_CEU, hapmap_CEU_r23a_filtered, UK10K, HRC reference panel\n",
    "    \n",
    "    * FIXME: if the SNPs are not in the reference panel they won't be outputed as index SNPs\n",
    "    * FIX: use the bgen files with the genotype info for which we are going to extract 1000 individuals\n",
    "    \n",
    "    \n",
    "2. What is the significance threshold for the index variant (p1) we should use for the analyses? \n",
    "    \n",
    "    p=5e-08\n",
    "    \n",
    "3. What significance threshold to use for the SNPs to be clumped? \n",
    "   \n",
    "   p=1 (this will include all the SNPs)\n",
    "   \n",
    "4. What LD r2 to use? \n",
    "   \n",
    "   r2=0.3 or even lower to capture bigger LD blocks\n",
    "   \n",
    "5. What window size in kb to use (research about the average LD in the human genome for CEU population)? \n",
    "   \n",
    "   I decided to use 1Mb (1000Kb), however conversations with the team decided that 2Mb will be better\n",
    "\n",
    "Below are the default options used by PLINK\n",
    "\n",
    "```\n",
    "--clump-p1 0.0001: significance threshold for Index SNPs\n",
    "--clump-p2 0.01: Secondary significance threshold for clumped SNPs\n",
    "--clump-r2 0.50: LD threshold for clumping\n",
    "--clump-kb 250: Physical distance threshold for clumping\n",
    "--clump-field P_BOLT_LMM: To specify the name of the field for P-value\n",
    "--clump-verbose: to add a more detailed report of SNPs in each clump\n",
    "--clump-best: to select the single best proxy\n",
    "--clump-allow-overlap: allow for overlap between clumped regions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "A list of regions in the following format:\n",
    "\n",
    "```\n",
    "chr start end top_snp all_snps\n",
    "```\n",
    "\n",
    "where the last column `all_snps` are SNP IDs in the LD cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LD_Clumping.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  filter_samples\n",
      "  filter_bgen\n",
      "  filter_plink\n",
      "  reference\n",
      "  default\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        Working directory: change accordingly\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype file in plink binary format\n",
      "  --genoFile  paths(\".\")\n",
      "\n",
      "                        Path to bgen or plink files\n",
      "  --sampleFile . (as path)\n",
      "                        Path to sample files\n",
      "  --sumstatsFiles  paths\n",
      "\n",
      "                        Path to summary stats file\n",
      "  --unrelated-samples . (as path)\n",
      "                        Path to samples of unrelated individuals\n",
      "  --ld-sample-size 2000 (as int)\n",
      "                        Number of samples to use to compute LD\n",
      "  --bfile-ref  path(f'{cwd}/{bfile:bn}.{ld_sample_size}.ref_geno.bed')\n",
      "\n",
      "                        Reference bfile\n",
      "  --clump-field VAL (as str, required)\n",
      "                        Clumping parameteres\n",
      "  --clump-annotate VAL (as str, required)\n",
      "  --clump-p1 5e-08 (as float)\n",
      "  --clump-p2 0.001 (as float)\n",
      "  --clump-r2 0.04 (as float)\n",
      "                        r2 = 0.04 => r = 0.2\n",
      "  --clump-kb 2000 (as int)\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --clumpFile  path(f'{cwd}/' + \"_\".join([f'{x:bn}' for x in sumstatsFiles]) + '.clumped')\n",
      "\n",
      "                        File names for clumping\n",
      "  --numThreads 5 (as int)\n",
      "                        Output the bgen file with 8bit formatting parameter:\n",
      "                        bgen_bits=16 Specific number of threads to use\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.8'\n",
      "                        Specify the container to use\n",
      "\n",
      "Sections\n",
      "  filter_samples:       Create a white-space delimited file with a list of\n",
      "                        unrelated samples in data.\n",
      "  filter_bgen_1:        Select a subset of samples from the bgen files\n",
      "  filter_bgen_2:        Make the binary files for bgen input using the selected\n",
      "                        samples and exclude repeated variant ids\n",
      "  filter_plink:         Select a subset of samples from the plink files\n",
      "  reference_1:\n",
      "  reference_2:          Merge all the .bed files into one reference file to use\n",
      "                        in clumping step\n",
      "  default:              Perform LD-clumping in PLINKv1.9\n"
     ]
    }
   ],
   "source": [
    "sos run LD_Clumping.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Working directory: change accordingly\n",
    "parameter: cwd = path\n",
    "# Genotype file in plink binary format\n",
    "parameter: bfile = path()\n",
    "# Path to bgen or plink files\n",
    "parameter: genoFile = paths(\".\")\n",
    "# Path to sample files\n",
    "parameter: sampleFile = path(\".\")\n",
    "# Path to summary stats file\n",
    "parameter: sumstatsFiles = paths\n",
    "# Path to samples of unrelated individuals\n",
    "parameter: unrelated_samples = path(\".\")\n",
    "# Number of samples to use to compute LD\n",
    "parameter: ld_sample_size = 2000\n",
    "# Reference bfile\n",
    "parameter: bfile_ref = path(\".\")\n",
    "# Clumping parameteres\n",
    "parameter: clump_field = str\n",
    "parameter: clump_annotate = \"\"\n",
    "parameter: clump_p1 = 5e-08\n",
    "parameter: clump_p2 = 0.01\n",
    "# r2 = 0.04 => r = 0.2\n",
    "parameter: clump_r2 = 0.04\n",
    "parameter: clump_kb = 2000\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# File names for clumping\n",
    "parameter: clumpFile = path(f'{cwd}/' + \"_\".join([f'{x:bn}' for x in sumstatsFiles]) + '.clumped')\n",
    "# Output the bgen file with 8bit formatting\n",
    "#parameter: bgen_bits=16\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 5\n",
    "# Specify the container to use\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:2.8'\n",
    "clumpregionFile = f'{clumpFile:n}.clumped_region'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Illustration with a minimal working example\n",
    "\n",
    "\n",
    "```\n",
    "JOB_OPT='-j 2'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "On a minimal working example (MWE) dataset generated by the `LMM.ipynb` workflow,\n",
    "\n",
    "Depending on wheter you are using bgen or plink binary files as input the reference_2 step will be skipped for the later. \n",
    "\n",
    "Available workflows are filter_samples, reference, default\n",
    "\n",
    "```\n",
    "sos run LD_Clumping.ipynb default\\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/genotypes.fam \\\n",
    "    --genoFile data/genotypes*.bed \\\n",
    "    --sumstatsFile output/phenotypes_BMI.fastGWA.snp_stats.gz \\\n",
    "    --unrelated-samples data/unrelated_samples.txt \\\n",
    "    --numThreads 5 \\\n",
    "    --clump-p1 0.05 \\\n",
    "    --clump-field P \\\n",
    "    --clump-annotate BP\n",
    "    $JOB_OPT\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "sos run LD_Clumping.ipynb default \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --sumstatsFile output/phenotypes_BMI.fastGWA.snp_stats.gz \\\n",
    "    --unrelated-samples data/unrelated_samples.txt \\\n",
    "    --numThreads 5 \\\n",
    "    --clump-p1 0.05 \\\n",
    "    --clump-field P \\\n",
    "    --clump-annotate BP \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Note\n",
    "\n",
    "In step reference_2 as per PLINK conditions duplicated variants have to be removed and indels renamed to <50 characters in length. PLINK1.9 is not capable of dealing with very long variant names and when merging different bed files it cannot handle multiallelic variants. The merge option is not available in PLINK2.0 as of this moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Select a random subset of unrelated samples\n",
    "\n",
    "The unrelated sample file should be a text file containing white space separated columns. It should have a column named `IID` for sample IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Create a white-space delimited file with a list of unrelated samples in data.\n",
    "[filter_samples: provides = f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt']\n",
    "input: unrelated_samples, sampleFile\n",
    "output: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "R: container = container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    set.seed(1)\n",
    "    all_unrelated = read.table(${_input[0]:r}, header=F${\"\" if _input[0].suffix == \".fam\" else \", skip=2\"})\n",
    "    avail_samples = read.table(${_input[1]:r}, header=F${\"\" if _input[1].suffix == \".fam\" else \", skip=2\"})\n",
    "    unrelated_samples = which(avail_samples[,1] %in% all_unrelated[,1])\n",
    "    dat = avail_samples[unrelated_samples,]\n",
    "    if (${ld_sample_size} < nrow(dat)) {\n",
    "      dat = dat[sample(1:nrow(dat), ${ld_sample_size}), 1, drop=F]\n",
    "    } else {\n",
    "      dat = dat[, 1, drop=F]\n",
    "    }\n",
    "    write.table(dat, ${_output:r}, quote=F, row.names=F, col.names=F)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Select Filter the BGEN files \n",
    "\n",
    "This step is based on the samples selected in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a subset of samples from the bgen files\n",
    "[filter_bgen_1]\n",
    "parameter: genoFile = list\n",
    "depends: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.{ld_sample_size}.bgen'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h',  mem = '60G', tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container_lmm, expand= True, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "   qctool -g {_input} -s {sampleFile} -og {_output} -os {_output:n} -incl-samples {_depends}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Make PLINK files with the selected samples\n",
    "\n",
    "The BGEN files extracted have to be converted to PLINK format because currently LD clumping in PLINK 1.9 does not work with BGEN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make the binary files for bgen input using the selected samples and exclude repeated variant ids\n",
    "[filter_bgen_2]\n",
    "depends: Py_Module('xxhash')\n",
    "output: f'{cwd}/cache/{_input:bn}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    # try create index if not exist\n",
    "    bgenix -g ${_input} -index || true\n",
    "    # get a list of duplicated SNP IDs\n",
    "    bgenix -g ${_input} -list 2>/dev/null | grep -v \"#\" | tail -n+2 | cut -d$'\\t' -f2 | sort | uniq -d > ${_output:n}.exclude\n",
    "    plink2 \\\n",
    "    --bgen ${_input} ref-first \\\n",
    "    --sample ${_input:n}.sample \\\n",
    "    --make-bed \\\n",
    "    --exclude ${_output:n}.exclude \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 12000\n",
    "    \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    # Fix SNP names longer than 50 characters. \n",
    "    # This will result in a false insufficient memory alert and error in the next step, if not dealt with\n",
    "    import pandas as pd\n",
    "    from xxhash import xxh32 as xxh\n",
    "    def shorten_id(x):\n",
    "        return x if len(x) < 30 else f\"{x.split('_')[0]}_{xxh(x).hexdigest()}\"\n",
    "\n",
    "    dat = pd.read_csv('${_output:n}.bim', header=None, sep='\\t')\n",
    "    dat.columns = ['chrom', 'id', 'gd', 'pos', 'a1', 'a2']\n",
    "    dat['id'] = dat['id'].apply(shorten_id)\n",
    "    dat.to_csv('${_output:n}.bim', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Filter PLINK files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a subset of samples from the plink files\n",
    "[filter_plink]\n",
    "depends: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.{ld_sample_size}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h',  mem = '60G', tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container_lmm, expand= True, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink --bfile {_input:n} --keep-fam {_depends} --make-bed --out {_output:n} --threads {numThreads} --memory 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[reference_1]\n",
    "bgen = [x for x in genoFile if x.suffix == '.bgen']\n",
    "plink = [x for x in genoFile if x.suffix == '.bed']\n",
    "input: genoFile\n",
    "output: f'{cwd}/cache/{_input:bn}.{ld_sample_size}.bed'\n",
    "if len(bgen):\n",
    "    sos_run('filter_bgen', genoFile=bgen)\n",
    "if len(plink):\n",
    "    sos_run('filter_plink', genoFile=plink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge all chroms to one file\n",
    "\n",
    "This is necessary for LD clumping in PLINK to work properly. We cannot `--merge` and `--make-bed` starting from bgen files in PLINK 2 at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one reference file to use in clumping step\n",
    "[reference_2]\n",
    "parameter: name_bref = str\n",
    "input: group_by='all'\n",
    "output: bfile_ref = f'{cwd}/{name_bref}.{ld_sample_size}.ref_geno.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Perform LD clumping per chrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Note: The same fields are extracted from all results files (e.g. SNP and P) -- i.e. it is not possible to specify different fields from different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Perform LD-clumping in PLINKv1.9\n",
    "[default]\n",
    "depends: bfile_ref\n",
    "input: bfile_ref  \n",
    "output: clumpFile, clumpregionFile \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G',cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container = container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'   \n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --clump ${sumstatsFiles:,} \\\n",
    "    --clump-field ${clump_field} \\\n",
    "    --clump-p1 ${clump_p1} \\\n",
    "    --clump-p2 ${clump_p2} \\\n",
    "    --clump-r2 ${clump_r2} \\\n",
    "    --clump-kb ${clump_kb} \\\n",
    "    --clump-verbose \\\n",
    "    ${(\"--clump-annotate %s\" % clump_annotate) if clump_annotate else \"\"} \\\n",
    "    --clump-allow-overlap \\\n",
    "    --out ${_output[0]:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    && touch ${_output[0]} # need to touch and create empty file because some chroms may not have anything significant to clump.\n",
    "    grep \"RANGE\" ${_output[0]} | awk -F \":\" '{print $2, $3}' | sort -V | sed 's/\\../ /g; s/^[[:blank:]]*//g ; s/chr//g' > ${_output[1]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
