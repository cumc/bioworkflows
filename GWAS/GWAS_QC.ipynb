{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "running-person",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# GWAS data QC workflow\n",
    "\n",
    "This workflow implements some prelimary data QC steps for PLINK input files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-offering",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook includes workflow for\n",
    "\n",
    "- Computer kinship matrix in sample and estimate related individuals\n",
    "- Genotype and sample QC: by MAF, missing data and HWE\n",
    "- LD pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-delhi",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Run this workflow\n",
    "\n",
    "Depending on the context of your problem, the workflow can be executed in two ways:\n",
    "\n",
    "1. Run `merge_plink` if necessary, to merge all samples first; then run `king` to perform kinship estimate and finally `qc` to do addition QC\n",
    "2. When you have a separate data-set for kinship estimate different from your genotype of interest, you can run `king`, followed by `qc`.\n",
    "\n",
    "In both cases, you should use the `*.related_remove` output from `king` as the `--remove_samples` parameter input for `qc` step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-basin",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "\n",
    "FIXME: first specify which of the 2 scenarios this example is for, then show how to run it.\n",
    "\n",
    "### First scenario: estimate kinship\n",
    "\n",
    "```\n",
    "sos run ~/bioworkflows/GWAS/GWAS_QC.ipynb king\\\n",
    "    --cwd ~/output \\\n",
    "    --genoFile ~/MWE_AD/rename_chr22.bed \\\n",
    "    --name first \\ \n",
    "    --kinship 0.05\n",
    "```\n",
    "\n",
    "### First scenario: do qc\n",
    "\n",
    "```\n",
    "sos run ~/bioworkflows/GWAS/GWAS_QC.ipynb qc\\\n",
    "    --cwd ~/output \\\n",
    "    --genoFile ~/MWE_AD/rename_chr22.bed \\\n",
    "    --remove_samples ~/output/rename_chr22.first.related_remove \\\n",
    "    --maf_filter 0.5 \\\n",
    "    --geno_filter 0.2 \\\n",
    "    --mind_filter 0.1 \\\n",
    "    --hwe_filter 0.0 \\\n",
    "    --name first \\\n",
    "    --window 50 \\\n",
    "    --shift 10 \\\n",
    "    --r2 0.5 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emotional-supplier",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run GWAS_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  king\n",
      "  qc\n",
      "  merge_plink\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --name VAL (as str, required)\n",
      "                        A string to identify your analysis run\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.8'\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  king:                 Inference of relationships in the sample to remove\n",
      "                        closely related individuals\n",
      "    Workflow Options:\n",
      "      --kinship 0.0625 (as float)\n",
      "                        Filter based on kinship coefficient higher than a number\n",
      "                        (e.g first degree 0.25, second degree 0.125, third\n",
      "                        degree 0.0625)\n",
      "      --genoFile VAL (as path, required)\n",
      "                        Plink binary file\n",
      "  qc_1:                 Filter SNPs and select individuals\n",
      "    Workflow Options:\n",
      "      --remove-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to remove (format FID, IID)\n",
      "      --keep-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "      --keep-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to keep\n",
      "      --maf-filter 0.01 (as float)\n",
      "                        MAF filter to use\n",
      "      --geno-filter 0.01 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.02 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 5e-08 (as float)\n",
      "                        HWE filter\n",
      "      --genoFile  paths\n",
      "\n",
      "                        Plink binary files\n",
      "  qc_2:                 LD prunning and remove related individuals (both ind of\n",
      "                        a pair)\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "                        Window size\n",
      "      --shift 10 (as int)\n",
      "                        Shift window every 10 snps\n",
      "      --r2 0.1 (as float)\n",
      "  qc_3:                 Merge all the .bed files into one bed file\n",
      "    Workflow Options:\n",
      "      --merged-prefix ''\n",
      "  merge_plink:\n",
      "    Workflow Options:\n",
      "      --merged-prefix VAL (as str, required)\n",
      "      --genoFile  paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run GWAS_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-victim",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# A string to identify your analysis run\n",
    "parameter: name = str\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Software container option\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.8'\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-texture",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Estimate kinship in the sample\n",
    "\n",
    "The output is a list of related individuals, as well as the kinship matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-neighbor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Inference of relationships in the sample to remove closely related individuals\n",
    "[king]\n",
    "# Filter based on kinship coefficient higher than a number (e.g first degree 0.25, second degree 0.125, third degree 0.0625)\n",
    "parameter: kinship = 0.0625\n",
    "# Plink binary file\n",
    "parameter: genoFile = path\n",
    "# If set to true, the unrelated individuals in a family will be kept without being reported. \n",
    "# Otherwise (use `--no-maximize-unrelated`) the entire family will be removed\n",
    "parameter: maximize_unrelated = True\n",
    "input: genoFile\n",
    "output: f'{cwd}/{_input:bn}.{name}.kin0', related_samples = f'{cwd}/{_input:bn}.{name}.related_remove'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      --make-king-table \\\n",
    "      --out ${_output[0]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)}\n",
    "      \n",
    "R:  container=container_lmm, expand= \"${ }\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout'\n",
    "    library(dplyr)\n",
    "    library(igraph)\n",
    "    # Remove related individuals while keeping maximum number of individuals\n",
    "    # this function is simplified from: \n",
    "    # https://rdrr.io/cran/plinkQC/src/R/utils.R\n",
    "    #' @param relatedness [data.frame] containing pair-wise relatedness estimates\n",
    "    #' (in column [relatednessRelatedness]) for individual 1 (in column\n",
    "    #' [relatednessIID1] and individual 2 (in column [relatednessIID1]). Columns\n",
    "    #' relatednessIID1, relatednessIID2 and relatednessRelatedness have to present,\n",
    "    #' while additional columns such as family IDs can be present. Default column\n",
    "    #' names correspond to column names in output of plink --genome\n",
    "    #' (\\url{https://www.cog-genomics.org/plink/1.9/ibd}). All original\n",
    "    #' columns for pair-wise highIBDTh fails will be returned in fail_IBD.\n",
    "    #' @param relatednessTh [double] Threshold for filtering related individuals.\n",
    "    #' Individuals, whose pair-wise relatedness estimates are greater than this\n",
    "    #' threshold are considered related.\n",
    "    relatednessFilter <- function(relatedness, \n",
    "                                  relatednessTh,\n",
    "                                  relatednessIID1=\"IID1\", \n",
    "                                  relatednessIID2=\"IID2\",\n",
    "                                  relatednessRelatedness=\"KINSHIP\") {\n",
    "        # format data\n",
    "        if (!(relatednessIID1 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessIID2 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessRelatedness %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessRelatedness,\n",
    "                       \"for relatedness not found!\"))\n",
    "        }\n",
    "\n",
    "        iid1_index <- which(colnames(relatedness) == relatednessIID1)\n",
    "        iid2_index <- which(colnames(relatedness) == relatednessIID2)\n",
    "\n",
    "        relatedness[,iid1_index] <- as.character(relatedness[,iid1_index])\n",
    "        relatedness[,iid2_index] <- as.character(relatedness[,iid2_index])\n",
    "\n",
    "        relatedness_names <- names(relatedness)\n",
    "        names(relatedness)[iid1_index] <- \"IID1\"\n",
    "        names(relatedness)[iid2_index] <- \"IID2\"\n",
    "        names(relatedness)[names(relatedness) == relatednessRelatedness] <- \"M\"\n",
    "\n",
    "        # Remove symmetric IID rows\n",
    "        relatedness_original <- relatedness\n",
    "        relatedness <- dplyr::select_(relatedness, ~IID1, ~IID2, ~M)\n",
    "\n",
    "        sortedIDs <- data.frame(t(apply(relatedness, 1, function(pair) {\n",
    "            c(sort(c(pair[1], pair[2])))\n",
    "            })), stringsAsFactors=FALSE)\n",
    "        keepIndex <- which(!duplicated(sortedIDs))\n",
    "\n",
    "        relatedness_original <- relatedness_original[keepIndex,]\n",
    "        relatedness <- relatedness[keepIndex,]\n",
    "\n",
    "        # individuals with at least one pair-wise comparison > relatednessTh\n",
    "        # return NULL to failIDs if no one fails the relatedness check\n",
    "        highRelated <- dplyr::filter_(relatedness, ~M > relatednessTh)\n",
    "        if (nrow(highRelated) == 0) {\n",
    "            return(list(relatednessFails=NULL, failIDs=NULL))\n",
    "        }\n",
    "\n",
    "        # all samples with related individuals\n",
    "        allRelated <- c(highRelated$IID1, highRelated$IID2)\n",
    "        uniqueIIDs <- unique(allRelated)\n",
    "\n",
    "        # Further selection of samples with relatives in cohort\n",
    "        multipleRelative <- unique(allRelated[duplicated(allRelated)])\n",
    "        singleRelative <- uniqueIIDs[!uniqueIIDs %in% multipleRelative]\n",
    "\n",
    "        highRelatedMultiple <- highRelated[highRelated$IID1 %in% multipleRelative |\n",
    "                                            highRelated$IID2 %in% multipleRelative,]\n",
    "        highRelatedSingle <- highRelated[highRelated$IID1 %in% singleRelative &\n",
    "                                           highRelated$IID2 %in% singleRelative,]\n",
    "\n",
    "        # Only one related samples per individual\n",
    "        if(length(singleRelative) != 0) {\n",
    "          # randomly choose one to exclude\n",
    "          failIDs_single <- highRelatedSingle[,1]\n",
    "            \n",
    "        } else {\n",
    "          failIDs_single <- NULL\n",
    "        }\n",
    "  \n",
    "        # An individual has multiple relatives\n",
    "        if(length(multipleRelative) != 0) {\n",
    "            relatedPerID <- lapply(multipleRelative, function(x) {\n",
    "                tmp <- highRelatedMultiple[rowSums(\n",
    "                    cbind(highRelatedMultiple$IID1 %in% x,\n",
    "                          highRelatedMultiple$IID2 %in% x)) != 0,1:2]\n",
    "                rel <- unique(unlist(tmp))\n",
    "                return(rel)\n",
    "            })\n",
    "            names(relatedPerID) <- multipleRelative\n",
    "\n",
    "            keepIDs_multiple <- lapply(relatedPerID, function(x) {\n",
    "                pairwise <- t(combn(x, 2))\n",
    "                index <- (highRelatedMultiple$IID1 %in% pairwise[,1] &\n",
    "                              highRelatedMultiple$IID2 %in% pairwise[,2]) |\n",
    "                    (highRelatedMultiple$IID1 %in% pairwise[,2] &\n",
    "                         highRelatedMultiple$IID2 %in% pairwise[,1])\n",
    "                combination <- highRelatedMultiple[index,]\n",
    "                combination_graph <- igraph::graph_from_data_frame(combination,\n",
    "                                                                   directed=FALSE)\n",
    "                all_iv_set <- igraph::ivs(combination_graph)\n",
    "                length_iv_set <- sapply(all_iv_set, function(x) length(x))\n",
    "\n",
    "                if (all(length_iv_set == 1)) {\n",
    "                    # check how often they occurr elsewhere\n",
    "                    occurrence <- sapply(x, function(id) {\n",
    "                        sum(sapply(relatedPerID, function(idlist) id %in% idlist))\n",
    "                    })\n",
    "                    # if occurrence the same everywhere, pick the first, else keep\n",
    "                    # the one with minimum occurrence elsewhere\n",
    "                    if (length(unique(occurrence)) == 1) {\n",
    "                        nonRelated <- sort(x)[1]\n",
    "                    } else {\n",
    "                        nonRelated <- names(occurrence)[which.min(occurrence)]\n",
    "                    }\n",
    "                } else {\n",
    "                    nonRelated <- all_iv_set[which.max(length_iv_set)]\n",
    "                }\n",
    "                return(nonRelated)\n",
    "            })\n",
    "            keepIDs_multiple <- unique(unlist(keepIDs_multiple))\n",
    "            failIDs_multiple <- c(multipleRelative[!multipleRelative %in%\n",
    "                                                       keepIDs_multiple])\n",
    "        } else {\n",
    "            failIDs_multiple <- NULL\n",
    "        }\n",
    "        allFailIIDs <- c(failIDs_single, failIDs_multiple)\n",
    "        relatednessFails <- lapply(allFailIIDs, function(id) {\n",
    "            fail_inorder <- relatedness_original$IID1 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            fail_inreverse <- relatedness_original$IID2 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            if (any(fail_inreverse)) {\n",
    "                inreverse <- relatedness_original[fail_inreverse, ]\n",
    "                id1 <- iid1_index\n",
    "                id2 <- iid2_index\n",
    "                inreverse[,c(id1, id2)] <- inreverse[,c(id2, id1)]\n",
    "                names(inreverse) <- relatedness_names\n",
    "            } else {\n",
    "                inreverse <- NULL\n",
    "            }\n",
    "            inorder <- relatedness_original[fail_inorder, ]\n",
    "            names(inorder) <- relatedness_names\n",
    "            return(rbind(inorder, inreverse))\n",
    "        })\n",
    "        relatednessFails <- do.call(rbind, relatednessFails)\n",
    "        if (nrow(relatednessFails) == 0) {\n",
    "            relatednessFails <- NULL\n",
    "            failIDs <- NULL\n",
    "        } else {\n",
    "            names(relatednessFails) <- relatedness_names\n",
    "            rownames(relatednessFails) <- 1:nrow(relatednessFails)\n",
    "            uniqueFails <- relatednessFails[!duplicated(relatednessFails[,iid1_index]),]\n",
    "            failIDs <- uniqueFails[,iid1_index]\n",
    "        }\n",
    "        return(list(relatednessFails=relatednessFails, failIDs=failIDs))\n",
    "    }\n",
    "    \n",
    "  \n",
    "    # main code\n",
    "    kin0 <- read.table(${_output[0]:r}, header=F, stringsAsFactor=F)\n",
    "    colnames(kin0) <- c(\"FID1\",\"ID1\",\"FID2\",\"ID2\",\"NSNP\",\"HETHET\",\"IBS0\",\"KINSHIP\")\n",
    "    if (${\"TRUE\" if maximize_unrelated else \"FALSE\"}) {\n",
    "        rel <- relatednessFilter(kin0, ${kinship}, \"ID1\", \"ID2\", \"KINSHIP\")$failIDs\n",
    "        # Get the family ID for these rels so there are two columns FID and IID in the output\n",
    "        lookup <- dplyr::distinct(rbind(kin0[,c(\"FID1\", \"ID1\")], kin0[,c(\"FID2\", \"ID2\")]))\n",
    "        dat <- lookup[which(lookup[,2] %in% rel),]\n",
    "    } else {\n",
    "        rel <- kin0 %>% filter(KINSHIP >= ${kinship})\n",
    "        IID <- sort(unique(unlist(rel[, c(\"ID1\", \"ID2\")])))\n",
    "        dat <- data.frame(IID)\n",
    "        dat <- dat %>%\n",
    "            mutate(FID = IID) %>%\n",
    "            select(FID, IID)\n",
    "    }\n",
    "    cat(\"There are\", nrow(dat),\"related individuals using a kinship threshold of ${kinship}\\n\")\n",
    "    write.table(dat,${_output[1]:r}, quote=FALSE, row.names=FALSE, col.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-yacht",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype and sample QC\n",
    "\n",
    "QC the genetic data based on MAF, sample and variant missigness and Hardy-Weinberg Equilibrium (HWE).\n",
    "\n",
    "In this step you may also provide a list of samples to keep, for example in the case when you would like to subset a sample based on their ancestries to perform independent analyses on each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "presidential-rebecca",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[qc_1 (basic QC filters)]\n",
    "# The path to the file that contains the list of samples to remove (format FID, IID)\n",
    "parameter: remove_samples = path('.')\n",
    "# The path to the file that contains the list of samples to keep (format FID, IID)\n",
    "parameter: keep_samples = path('.')\n",
    "# The path to the file that contains the list of variants to keep\n",
    "parameter: keep_variants = path('.')\n",
    "# minimum MAF filter to use. Notice that PLINK default is 0.01\n",
    "parameter: maf_filter = 0.01\n",
    "# maximum MAF filter to use\n",
    "parameter: maf_max_filter = 0.0\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.01\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.02\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 5e-08\n",
    "# Plink binary files\n",
    "parameter: genoFile = paths\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.{name}.filtered.bed'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, volumes=[f'{cwd}:{cwd}'], expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter >= 0 else ''} \\\n",
    "      ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter >= 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter >= 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter >= 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % keep_variants) if keep_variants.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wrong-socket",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning and remove related individuals (both ind of a pair)\n",
    "[qc_2 (LD pruning)]\n",
    "# Window size\n",
    "parameter: window = 50\n",
    "# Shift window every 10 snps\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "output: bed=f'{_input:n}.prune.bed', prune=f'{_input:n}.prune.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[\"prune\"]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}\n",
    "   \n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output['prune']} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output['bed']:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-carry",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one bed file \n",
    "[qc_3 (merge all files)]\n",
    "parameter: merged_prefix = \"\"\n",
    "merged_prefix = f'{_input[0]:bn}.merged' if merged_prefix == '' else merged_prefix\n",
    "sos_run(\"merge_plink\", merged_prefix=merged_prefix, genoFile=_input['bed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-moisture",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_plink]\n",
    "parameter: merged_prefix = str\n",
    "parameter: genoFile = paths\n",
    "skip_if(len(genoFile) == 1)\n",
    "input: genoFile, group_by = 'all'\n",
    "output: f\"{_input[0]:d}/{merged_prefix}.bed\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink2 \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
