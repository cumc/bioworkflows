{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# LMM/GLMM analyses for UK Biobank data\n",
    "\n",
    "This notebook implements pipelines for analyzing binary and quantitative traits association using BOLT-LMM (version 2.3.4), fastGWA, REGENIE and SAIGE software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This pipeline was initially developed to perfom genetic association analysis using various LMM methods on UK Biobank imputed data of ~500K invidivuals, although it can be used to analyze other studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. Genotype file for constructing the GRM (genetic relationship matrix) formated as a plink binary file `(.bed/.bim/.fam)` \n",
    "    - `--bfile=prefix`\n",
    "2. Imputed genotype dosages in `bgen` format (`.bgen`, `.bgi`, `.sample`)\n",
    "    - `--bgenFile` and ` --sampleFile`\n",
    "3. Phenotype file (white space delimited file with column headers, first two columns should be FID and IID) specify files by options `--phenoFile` and the phenotype to be analized by `--phenoCol`\n",
    "4. Covariates file (same format as phenoFile) specify them by `--covarFile` for qualitative covariates use `--covarCol` and for quantitative `--qCovarCol`. If `--covarFile` is not specified then phenotype file will be used as covariate file. To specify an array of covariates you can use bash tricks, eg `--qCovarCol PC{1:20}`\n",
    "\n",
    "Note: reference genome used **GRCh37/hg19**.\n",
    "\n",
    "## Software specific inputs\n",
    "\n",
    "### BoltLMM additional input\n",
    "\n",
    "- Reference genetic maps, provided on BoltLMM website\n",
    "    - `--geneticMapFile=tables/genetic_map_hg##.txt.gz`\n",
    "- Reference LD scores, provided on BoltLMM website\n",
    "- Use `--covarMaxLevels` to specify the number of categories of a qualitative covariate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Our pipeline generates \n",
    "\n",
    "1. Summary statistics file for each variant analyzed\n",
    "2. QQ and Manhattan plots for these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## References\n",
    "\n",
    "To learn more about each of the specific methods applied in this pipeline please refer to the published papers and software documentation:\n",
    "\n",
    "1. [Bolt-LMM](http://dx.doi.org/10.1038/ng.3190) and [documentation](https://alkesgroup.broadinstitute.org/BOLT-LMM)\n",
    "2. [FastGWA](http://dx.doi.org/10.1038/s41588-019-0530-8) and [documentation](https://cnsgenomics.com/software/gcta/#Overview)\n",
    "3. [REGENIE](https://www.biorxiv.org/content/10.1101/2020.06.19.162354v2) and [documentation](https://rgcgithub.github.io/regenie/)\n",
    "4. [SAIGE](http://dx.doi.org/10.1038/s415) and [documentation](https://github.com/weizhouUMICH/SAIGE)\n",
    "5. [GMMAT](https://github.com/hanchenphd/GMMAT) and [documentation](https://github.com/hanchenphd/GMMAT/blob/master/inst/doc/GMMAT.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LMM.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  boltlmm\n",
      "  gcta\n",
      "  fastGWA\n",
      "  PLINK_QC\n",
      "  regenie\n",
      "  regenie_burden\n",
      "  SAIGE\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --sampleFile . (as path)\n",
      "                        Path to sample file\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype files in plink binary this is used for\n",
      "                        computing the GRM\n",
      "  --genoFile  paths\n",
      "\n",
      "                        Path to bgen or bed files\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        Phenotype file for quantitative trait (BMI)\n",
      "  --phenoCol VAL VAL ... (as type, required)\n",
      "                        Phenotype to be analyzed (specify the column)\n",
      "  --covarFile . (as path)\n",
      "                        Covariate file path. Will use phenoFile if empty\n",
      "  --formatFile . (as path)\n",
      "                        Summary statisticss format file path used for unifying\n",
      "                        output column names. Will not unify names if empty\n",
      "  --covarCol  (as list)\n",
      "                        Qualitative covariates to be used in the analysis\n",
      "  --qCovarCol  (as list)\n",
      "                        Quantitative covariates to be used in the analysis\n",
      "  --numThreads 2 (as int)\n",
      "                        Specific number of threads to use\n",
      "  --bgenMinMAF 0.001 (as float)\n",
      "                        Minimum MAF to be used\n",
      "  --bgenMinINFO 0.8 (as float)\n",
      "                        Mimimum info score to be used\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.8'\n",
      "                        The container with the lmm software. Can be either a\n",
      "                        dockerhub image or a singularity `sif` file. Default is\n",
      "                        set to using dockerhub image\n",
      "  --container-marp 'gaow/marp'\n",
      "\n",
      "Sections\n",
      "  boltlmm_1:            Run BOLT analysis\n",
      "    Workflow Options:\n",
      "      --covarMaxLevels VAL (as int, required)\n",
      "                        Maximum categories of covariates allowed\n",
      "      --LDscoresFile VAL (as path, required)\n",
      "                        Path to LDscore file for reference population\n",
      "      --geneticMapFile VAL (as path, required)\n",
      "                        Path to genetic map file used to interpolate genetic map\n",
      "                        coordinates from SNP physical (base pair) positions\n",
      "      --lmm-option lmm\n",
      "                        LMM option: lmm, lmmInfOnly, and lmmForceNonInf\n",
      "  gcta_1:               Partition the GRM into 100 parts and allocate 8GB memory\n",
      "                        to each job\n",
      "    Workflow Options:\n",
      "      --parts 100 (as int)\n",
      "                        Number of parts the GRM calculation is to be partitioned\n",
      "  gcta_2:               Merge all the parts together (Linux, Mac)\n",
      "  gcta_3:               Make a sparse GRM from the merged full-dense GRM\n",
      "  fastGWA_1:            fastGWA mixed model (based on the sparse GRM generated\n",
      "                        above)\n",
      "    Workflow Options:\n",
      "      --grmFile  path(f'{cwd}/{bfile:bn}.grm.sp')\n",
      "\n",
      "  PLINK_QC:             Select the SNPs and samples to be used based on maf,\n",
      "                        geno, hwe and mind options\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.0 (as float)\n",
      "      --geno-filter 0.0 (as float)\n",
      "      --hwe-filter 0.0 (as float)\n",
      "      --mind-filter 0.0 (as float)\n",
      "  regenie_1:            Run REGENIE step 1: fitting the null\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --lowmem-prefix  cwd\n",
      "\n",
      "                        Path to temporarily store block predictions\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "  regenie_2:            Run REGENIE step 2: association analysis\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --minMAC VAL (as int, required)\n",
      "                        Mimimum allele count to be used\n",
      "      --trait bt\n",
      "  regenie_burden_1:     Run REGENIE_BURDEN step 1: fitting the null Similar to\n",
      "                        the REGENIE step 1, but add 'regenie_burden' instead of\n",
      "                        'regenie' as a sufix\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --lowmem-prefix  cwd\n",
      "\n",
      "                        Path to temporarily store block predictions\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "  regenie_burden_2:     Run regenie for burden tests\n",
      "    Workflow Options:\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --anno-file VAL (as path, required)\n",
      "                        Annotation file format: variantID, gene and functional\n",
      "                        annotation (space/tab delimited)\n",
      "      --set-list VAL (as path, required)\n",
      "                        This file lists variants within each set/gene to use\n",
      "                        when building masks. Format: set/gene name, chromosome,\n",
      "                        physical pos set/gene, then by a comma-separated list of\n",
      "                        variants included in the set/gene.\n",
      "      --keep-gene VAL (as path, required)\n",
      "                        Select specific genes/sets to test\n",
      "      --mask-file VAL (as path, required)\n",
      "                        Allele frequency file. format: variantId, alternative\n",
      "                        allele frequency parameter: aaf_file = path Select the\n",
      "                        annotations to be used in the mask file. format: mask#\n",
      "                        annotatio type\n",
      "      --aaf-bins 0.05 (as float)\n",
      "                        Select the upper MAF to generate masks\n",
      "      --build-mask max\n",
      "                        The way in which the alternative alleles are counted\n",
      "  SAIGE_1:              Fit SAIGE null model\n",
      "    Workflow Options:\n",
      "      --trait-type VAL (as str, required)\n",
      "                        trait type, eg 'binary' or 'quantitative'\n",
      "      --loco TRUE\n",
      "                        Whether to use LOCO or not\n",
      "      --sampleCol IID\n",
      "                        Name of the sample column\n",
      "      --script-path /Users/zhoujiayi/software/bin/step1_fitNULLGLMM.R (as path)\n",
      "                        Path specific to SAIGE script\n",
      "      --invNormalize FALSE\n",
      "                        Inverse normalization only for non-normal quantitative\n",
      "                        traits\n",
      "  SAIGE_2:              Compute SAIGE statistics\n",
      "    Workflow Options:\n",
      "      --bgenMinMAC 4 (as int)\n",
      "                        Mimimum allele count to be used\n",
      "      --af-caco TRUE\n",
      "                        Specify whether to output allele frequencies in cases\n",
      "                        and controls\n",
      "      --script-path /Users/zhoujiayi/software/bin/step2_SPAtests.R (as path)\n",
      "                        Path specific to SAIGE script\n",
      "  regenie_burden_3:     Merge results and log files Skipping the first two rows\n",
      "                        of the input file\n",
      "    Workflow Options:\n",
      "      --[no-]reverse-log-p (default to False)\n",
      "  boltlmm_2, fastGWA_2, SAIGE_3, regenie_3: Merge results and log files\n",
      "    Workflow Options:\n",
      "      --[no-]reverse-log-p (default to False)\n",
      "  boltlmm_3, fastGWA_3, SAIGE_4, regenie_4: Manhattan and QQ plots using `qqman`\n",
      "    Workflow Options:\n",
      "      --bp POS\n",
      "                        Column name for BP\n",
      "      --pval P\n",
      "                        Column name for p-value\n",
      "      --snp SNP\n",
      "                        Column name for SNP\n",
      "      --p-filter '0.05'\n",
      "                        Plot only on p-values smaller than this\n",
      "      --ylim 0 (as int)\n",
      "                        ylim set to 0 to use maximum -log10(p) in data\n",
      "  boltlmm_4, fastGWA_4, SAIGE_5, regenie_5: Generate analysis report: HTML file,\n",
      "                        and optionally PPTX file\n"
     ]
    }
   ],
   "source": [
    "sos run LMM.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path('.')\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = paths\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Covariate file path. Will use phenoFile if empty\n",
    "parameter: covarFile = path('.')\n",
    "# Summary statisticss format file path used for unifying output column names. Will not unify names if empty\n",
    "parameter: formatFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "# Minimum MAF to be used\n",
    "parameter: bgenMinMAF = 0.001\n",
    "# Mimimum info score to be used\n",
    "parameter: bgenMinINFO = 0.8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# The container with the lmm software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "# Default is set to using dockerhub image\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.9'\n",
    "parameter: container_marp = 'gaow/marp'\n",
    "if not covarFile.is_file():\n",
    "    covarFile = phenoFile\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Illustration with minimal working examples\n",
    "\n",
    "```\n",
    "JOB_OPT='-j 2'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### BOLT-LMM example command\n",
    "\n",
    "On a minimal working example (MWE) dataset (about 1min to complete the analysis),\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb boltlmm \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/boltlmm_template.yml \\\n",
    "    --LDscoresFile data/LDSCORE.1000G_EUR.tab.gz \\\n",
    "    --geneticMapFile data/genetic_map_hg19_withX.txt.gz \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --covarMaxLevels 10 \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 5 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --lmm-option none \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```\n",
    "\n",
    "Please note that the command above is only meant to demonstrate the usage of the pipeline. Data will be generated to a folder called `output`. We set `--lmm-option` to `none` to not run LMM on this minimal data-set. The `--pval` column name `P_LINREG` for QQ/Manhattan plot is also p-value from conventional linear regression. In practice we will definitely want to use one of the LMM options in BoltLMM. Default is `lmm` switch in `bolt` if you don't specify `--lmm-option`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### fastGWA example command\n",
    "\n",
    "On a minimal working example (MWE) dataset (analysis completes almost instantly),\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb fastGWA \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/fastGWA_template.yml \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 1 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --parts 2 \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### REGENIE example command\n",
    "On a minimal working example (MWE) dataset,\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb regenie \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes21_22.bed \\\n",
    "    --maf-filter 0.001 \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/regenie_template.yml \\\n",
    "    --phenoCol ASTHMA T2D\\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 4 \\\n",
    "    --bgenMinMAF 0.05 \\\n",
    "    --bgenMinINFO 0.8 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### REGENIE burden example command\n",
    "\n",
    "On a minimal working example (MWE) dataset,\n",
    "```\n",
    "sos run LMM.ipynb regenie_burden \\\n",
    "    --cwd output \\\n",
    "    --bfile genotypes_21_22_plink.exome.bed \\\n",
    "    --genoFile ukb23155_c22_b0_v1.plink.exome.filtered.bed \\\n",
    "    --phenoFile phenotype_burden.txt\\\n",
    "    --phenoCol ASTHMA T2D \\\n",
    "    --formatFile data/regenie_template.yml \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --anno_file annotation_file.txt\\\n",
    "    --set_list set_list_file_chr22.txt \\\n",
    "    --mask_file mask_file.txt \\\n",
    "    --keep_gene keep_gene.txt\\\n",
    "    --aaf_bins 0.05 \\\n",
    "    --trait bt \\\n",
    "    --build_mask max\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### SAIGE example command\n",
    "\n",
    "On a minimal working example (MWE) dataset,\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb SAIGE \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 4 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --trait_type quantitative \\\n",
    "    --pval p.val \\\n",
    "    --bp POS \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Input using `bed` format\n",
    "\n",
    "sos run LMM.ipynb fastGWA \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --genoFile data/genotypes21_22.bed \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/fastGWA_template.yml \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 1 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --parts 2 \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### GMMAT example command\n",
    "sos run LMM.ipynb GMMAT \\\n",
    "    --cwd gemma_output \\\n",
    "    --bfile 100K_chr22.bed \\\n",
    "    --genoFile 100K_chr22.bed \\\n",
    "    --phenoFile MWE_pheno_new1.txt \\\n",
    "    --formatFile gmmat_template.yml \\\n",
    "    --phenoCol AD \\\n",
    "    --covarCol SEX \\\n",
    "    --covarMaxLevels 10 \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 5 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --lmm-option none \\\n",
    "    --p-filter 1 \\\n",
    "    --geno_filter 0.0005 \\\n",
    "    --nperbatch 10 \\\n",
    "    $JOB_OPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Run workflow on a cluster\n",
    "\n",
    "The shell variable `JOB_OPT` was set to `-j 2`. That is, run 2 jobs in parallel on a local computer (each using 5 threads due to `--numThreads 5`).\n",
    "\n",
    "On cluster we use a job template, and configure `JOB_OPT` as follows: \n",
    "\n",
    "```\n",
    "JOB_OPT=\"-c farnam.yml -q farnam -J 40\"\n",
    "```\n",
    "\n",
    "Here we use task queue `farnam` configured in file `farnam.yml`. We allow for at most 40 jobs in the cluster job queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## BoltLMM workflow implementation\n",
    "\n",
    "To install from source code follow instructions here: https://data.broadinstitute.org/alkesgroup/BOLT-LMM/#x1-70002.2\n",
    "    - On Linux machine a binary executable is provided and can be used.\n",
    "    - Supporting files such as LD score file and genetic map file can be found [in the installation bundle](https://data.broadinstitute.org/alkesgroup/BOLT-LMM/downloads/BOLT-LMM_v2.3.4.tar.gz).\n",
    "    - For a complete description on bolt commands go to: http://manpages.ubuntu.com/manpages/eoan/en/man1/bolt.1.html.\n",
    "\n",
    "**A note for developers**: it is important to have input and output for each step. Input files and output files are best derived from one another.\n",
    "\n",
    "BOLT-LMM software computes statistics for testing association between phenotypes and genotypes using a linear mixed model\n",
    "\n",
    "\n",
    "```\n",
    "--bfile = accepts genotype files in PLINK binary format (.fam, .bed, .bim)\n",
    "--geneticMapFile = Oxford-format file for interpolating genetic distances: tables/genetic_map_hg##.txt.gz\n",
    "--phenoFile = phenotype file (header required; FII and IID must be first two columns)\n",
    "--phenoCol = phenotype columns header\n",
    "--covarFile = covariate file (header required; FII and IID must be first two columns)\n",
    "--covarCol = categorical covariate column(s); for >1, use multiple --covarCol and/or {i:j} expansion\n",
    "--qcovarCol = quantitative covariate column(s); for  >1, use multiple --qCovarCol and/or {i:j} expansion\n",
    "--lmm = compute assoc stats under the inf model and with Bayesian non-inf prior (VB approx), if power gain expected\n",
    "--modelSnps = file(s) listing SNPs to use in model (i.e., GRM) (default: use all non-excluded SNPs)\n",
    "--LDscoresFile = LD Scores for calibration of Bayesian assoc stats: tables/LDSCORE.1000G_EUR.tab.g\n",
    "--numThreads = number of computational threads\n",
    "--statsFile = output file for assoc stats at PLINK genotypes\n",
    "--bgenFile = file(s) containing Oxford BGEN-format genotypes to test for association\n",
    "--sampleFile = file containing Oxford sample file corresponding to BGEN file(s)\n",
    "--bgenMinMAF = MAF threshold on Oxford BGEN-format genotypes; lower-MAF SNPs will be ignored\n",
    "--bgenMinINFO = INFO threshold on Oxford BGEN-format genotypes; lower-INFO SNPs will be ignored\n",
    "--statsFileBgenSNPs = output file for assoc stats at BGEN-format genotypes\n",
    "```\n",
    "\n",
    "It is important to know that BOLT-LMMv2.3.4 accepts bgen files only in 8bit formatting as stated below:\n",
    "\n",
    "*WARNING: The BGEN format comprises a few sub-formats; we have only implemented support for the versions (and specific data layouts) used in the UK Biobank N=150K and N=500K releases. In particular, for BGEN v1.2, BOLT-LMM currently only supports the 8-bit encoding used for the UK Biobank N=500K data. (Starting with BOLT-LMM v2.3.3, missing values in BGEN v1.2 data are now allowed.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run BOLT analysis\n",
    "[boltlmm_1]\n",
    "# Maximum categories of covariates allowed \n",
    "parameter: covarMaxLevels = int\n",
    "# Path to LDscore file for reference population\n",
    "parameter: LDscoresFile = path\n",
    "# Path to genetic map file used to interpolate genetic map coordinates from SNP physical (base pair) positions\n",
    "parameter: geneticMapFile = path\n",
    "# LMM option: lmm, lmmInfOnly, and lmmForceNonInf\n",
    "parameter: lmm_option = 'lmm'\n",
    "depends: LDscoresFile, geneticMapFile\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/cache/{_input:bn}.{phenoFile:bn}_{phenoCol[0]}.boltlmm.snp_stats.gz'\n",
    "file_options=f\"--bfile {bfile:n} --bgenFile={_input} --bgenMinMAF={bgenMinMAF} --bgenMinINFO={bgenMinINFO} --sampleFile={sampleFile} --statsFileBgenSnps={_output} --statsFile={_output:nn}.ref_stats.gz \" if _input.suffix == \".bgen\" else f\"--bfile={_input:n} --statsFile={_output} \"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    bolt \\\n",
    "    --phenoFile=${phenoFile} \\\n",
    "    --phenoCol=${phenoCol[0]} \\\n",
    "    --covarFile=${covarFile} \\\n",
    "    ${' '.join(['--covarCol=%s ' % x for x in covarCol if x is not None])} \\\n",
    "    --covarMaxLevels=${covarMaxLevels} \\\n",
    "    ${' '.join(['--qCovarCol=%s ' % x for x in qCovarCol if x is not None])} \\\n",
    "    --LDscoresFile=${LDscoresFile} \\\n",
    "    --geneticMapFile=${geneticMapFile} \\\n",
    "    ${('--' + lmm_option) if lmm_option in ['lmm', 'lmmInfOnly', 'lmmForceNonInf'] else ''} \\\n",
    "    ${file_options} \\\n",
    "    --numThreads=${numThreads} \\\n",
    "    --verboseStats \n",
    "\n",
    "bash: expand = \"${ }\", active = (_index != 0)\n",
    "    # remove redundant reference summary stats file\n",
    "    rm -f ${_output:nn}.ref_stats.gz\n",
    "\n",
    "bash: expand = \"${ }\", active = (_index == 0)\n",
    "    # rename reference summary stats file\n",
    "    if [ -f ${_output:nn}.ref_stats.gz ]; then\n",
    "      mv ${_output:nn}.ref_stats.gz ${cwd}/${phenoFile:bn}_${phenoCol[0]}.boltlmm.ref_stats.gz\n",
    "    else\n",
    "       echo \"File does not exist.\"\n",
    "    fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## fastGWA workflow implementation\n",
    "\n",
    "Installation instructions can be found in https://cnsgenomics.com/software/gcta/#Download. On Linux machine a binary executable is provided and can be used.\n",
    "\n",
    "Documentation: https://cnsgenomics.com/software/gcta/#fastGWA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: Creation of the GRM\n",
    "The GRM only needs to be created once for all the phenotypes to analyze with the same genotypic data. In this step the GRM calculation is divided into multiple parts for a faster computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Partition the GRM into 100 parts and allocate 8GB memory to each job\n",
    "[gcta_1]\n",
    "# Number of parts the GRM calculation is to be partitioned\n",
    "parameter: parts = 100\n",
    "part_number = [f'{parts}_{format(x+1, \"0\" + str(len(str(parts))))}' for x in range(parts)]\n",
    "input: bfile, for_each = 'part_number'\n",
    "output: f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.bin', \n",
    "        f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.N.bin', \n",
    "        f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.id'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    gcta64 \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --make-grm-part ${parts} ${_index+1} \\\n",
    "    --thread-num ${numThreads} \\\n",
    "    --out ${_output[0]:nnn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Combine all the GRM parts into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the parts together (Linux, Mac)\n",
    "[gcta_2]\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/{bfile:bn}.grm.bin', \n",
    "        f'{cwd}/{bfile:bn}.grm.N.bin', \n",
    "        f'{cwd}/{bfile:bn}.grm.id' \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '2h', mem = '6G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # here input is results all parts each having 3 items. We need to get the corresponding every other 3 items\n",
    "    cat ${paths(_input[::3])} > ${_output[0]}\n",
    "    cat ${paths(_input[1::3])} > ${_output[1]}\n",
    "    cat ${paths(_input[2::3])} > ${_output[2]}\n",
    "    #rm ${paths(_input)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Make a sparse GRM to be used in the association analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make a sparse GRM from the merged full-dense GRM\n",
    "[gcta_3]\n",
    "output: f'{cwd}/{bfile:bn}.grm.sp' \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    gcta64 --grm ${_output:nn} --make-bK-sparse 0.05 --out ${_output:nn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 4: Run the single variant association analysis using FastGWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# fastGWA mixed model (based on the sparse GRM generated above)\n",
    "[fastGWA_1]\n",
    "parameter: grmFile = path(f'{cwd}/{bfile:bn}.grm.sp')\n",
    "depends: grmFile\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True)\n",
    "if len(phenoCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_phenotype\", sep=' ', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True)\n",
    "if len(covarCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_covar\", sep=' ', index=False, columns = ['FID', 'IID'] + covarCol)\n",
    "if len(qCovarCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_qcovar\", sep=' ', index=False, columns = ['FID', 'IID'] + qCovarCol)\n",
    "\n",
    "input: genoFile, group_by = 1\n",
    "input_options = f\"--bgen {_input} --info {bgenMinINFO} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bfile {_input:n}\"\n",
    "output: f'{cwd}/cache/{_input:bnn}.{phenoFile:bn}.fastGWA.gz'\n",
    "fail_if(not path(f'{_input}.bgi').is_file() and _input.suffix == '.bgen', msg = f'Cannot find file ``{_input}.bgi``. Please generate it using command ``bgenix -g {_input} -index``.') if _input.suffix == \".bgen\" else f\"continue\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '5G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    gcta64 \\\n",
    "    ${input_options} \\\n",
    "    --grm-sparse ${grmFile:nn} \\\n",
    "    --maf ${bgenMinMAF} \\\n",
    "    --fastGWA-mlm \\\n",
    "    --pheno ${cwd}/${phenoFile:bn}.fastGWA_phenotype \\\n",
    "    --qcovar ${cwd}/${covarFile:bn}.fastGWA_qcovar \\\n",
    "    --covar ${cwd}/${covarFile:bn}.fastGWA_covar \\\n",
    "    --threads ${numThreads} \\\n",
    "    --out ${_output:nn}\\\n",
    "    && gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Output from each step:\n",
    "\n",
    "1. **gcta_1 for x number of parts (in the example above x=100, so this step will create 400 files):**\n",
    "* test.part_{_part_number}.grm.bin\n",
    "* test.part_{_part_number}.grm.N.bin \n",
    "* test.part_{_part_number}.grm.id\n",
    "* test.part_{_part_number}.log (the program creates the log file so there is no need for .stderr and .stdout)\n",
    "\n",
    "2. **gcta_2 this step creates 5 output files:**\n",
    "* test.grm.bin (it is a binary file which contains the lower triangle elements of the GRM)\n",
    "* test.grm.N.bin (it is a binary file which contains the number of SNPs used to calculate the GRM)\n",
    "* test.grm.id (no header line; columns are family ID and individual ID, see above)\n",
    "* test.grm.stderr\n",
    "* test.grm.stdout\n",
    "\n",
    "3. **gcta_3 this step creates 3 output files:**\n",
    "* test.grm.sp (sparse GRM made from the dense GRM)\n",
    "* test.grm.sp.stderr\n",
    "* test.grm.sp.stdout\n",
    "\n",
    "4. **fastGWA this step creates 2 output files per chromosome**\n",
    "* test{chr1:22}.fastGWA\n",
    "* test{chr1:22}.fastGWA.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# REGENIE workflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Documentation can be found [here](https://rgcgithub.github.io/regenie/). Binary and quantitative traits should be analyzed separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select the SNPs and samples to be used based on maf, geno, hwe and mind options\n",
    "[PLINK_QC]\n",
    "parameter: maf_filter = 0.0\n",
    "parameter: geno_filter = 0.0\n",
    "parameter: hwe_filter = 0.0\n",
    "parameter: mind_filter = 0.0\n",
    "input: bfile\n",
    "output: f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout' \n",
    "    plink2 \\\n",
    "      --bfile ${bfile:n} --mac 1 \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --write-samples --no-id-header \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output[0]:n} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 1: fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 1: fitting the null\n",
    "[regenie_1,regenie_burden_1]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Path to temporarily store block predictions\n",
    "parameter: lowmem_dir = cwd\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True, dtype=str)\n",
    "dat = dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "if len(phenoCol) > 0:    \n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", sep=' ', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True)\n",
    "if len(covarCol) > 0 or len(qCovarCol) > 0:\n",
    "    dat = dat.dropna(subset=covarCol)\n",
    "    dat = dat.dropna(subset=qCovarCol)\n",
    "    dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "    dat1 = pd.DataFrame(dat, columns = ['FID','IID'] + covarCol)\n",
    "    dat1 = dat1.astype(int)\n",
    "    dat2 = pd.DataFrame(dat, columns = ['IID'] + qCovarCol)\n",
    "    merged_left = pd.merge(left=dat1, right=dat2, how='left', left_on='IID', right_on='IID')\n",
    "    merged_left.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_covar\", sep=' ', index=False)\n",
    "depends: f'{cwd}/cache/{bfile:bn}.qc_pass.snplist', f'{cwd}/cache/{bfile:bn}.qc_pass.id'\n",
    "input: geno = bfile, pheno = f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", covar = f\"{cwd}/{phenoFile:bn}.regenie_covar\", qc = output_from(\"PLINK_QC\")\n",
    "output: f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f\"{lowmem_dir:a}:{lowmem_dir:a}\"]\n",
    "    regenie \\\n",
    "      --step 1 \\\n",
    "      --bed ${_input[\"geno\"]:n} \\\n",
    "      --phenoFile ${_input[\"pheno\"]} \\\n",
    "      --covarFile ${_input[\"covar\"]} \\\n",
    "      --keep ${_input[\"qc\"][0]} \\\n",
    "      --extract ${_input[\"qc\"][1]} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --lowmem --lowmem-prefix ${lowmem_dir:a}/${_output:bn} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:nn}.regenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2: association analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 2: association analysis\n",
    "[regenie_2]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "parameter: trait = 'bt'\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/cache/{_input:bn}_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    set -e\n",
    "    regenie \\\n",
    "     --step 2 \\\n",
    "     ${input_options} \\\n",
    "     --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "     --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "     --phenoColList ${','.join(phenoCol)} \\\n",
    "     ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "     --firth 0.01 --approx \\\n",
    "     --pred ${_input.info} \\\n",
    "     --bsize ${bsize} \\\n",
    "     --minMAC ${minMAC} \\\n",
    "     --minINFO ${bgenMinINFO}\\\n",
    "     --split \\\n",
    "     --threads ${numThreads} \\\n",
    "     --out ${cwd}/cache/${_input:bn} && \\\n",
    "     gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Regenie burden test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run regenie for burden tests\n",
    "[regenie_burden_2]\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Annotation file format: variantID, gene and functional annotation (space/tab delimited)\n",
    "parameter: anno_file = path\n",
    "# This file lists variants within each set/gene to use when building masks. Format: set/gene name, chromosome, physical pos set/gene, then by a comma-separated list of variants included in the set/gene.\n",
    "parameter: set_list = path\n",
    "# Select specific genes/sets to test\n",
    "parameter: keep_gene = path\n",
    "# Allele frequency file. format: variantId, alternative allele frequency\n",
    "#parameter: aaf_file = path\n",
    "# Select the annotations to be used in the mask file. format: mask# annotatio type\n",
    "parameter: mask_file = path\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins = 0.05\n",
    "# The way in which the alternative alleles are counted\n",
    "parameter: build_mask = 'max'\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/cache/{_input:bn}_burden_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    set -e\n",
    "    regenie \\\n",
    "      --step 2 \\\n",
    "      ${input_options} \\\n",
    "      --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "      --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "      --phenoColList ${','.join(phenoCol)} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --firth --approx \\\n",
    "      --pred ${_input.info} \\\n",
    "      --set-list ${set_list} \\\n",
    "      --extract-sets ${keep_gene}\\\n",
    "      --aaf-bins ${aaf_bins} \\\n",
    "      --write-mask \\\n",
    "      ${('--build-mask ' + build_mask) if build_mask in ['max','sum','comphet'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --check-burden-files \\\n",
    "      --out  ${cwd}/cache/${_input:bn}_burden && \\\n",
    "      gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SAIGE workflow implementation\n",
    "\n",
    "We need to create a conda enviroment for the installation of SAIGE in Yale's HRC cluster. Instructions in https://github.com/weizhouUMICH/SAIGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Fit SAIGE null model\n",
    "[SAIGE_1]\n",
    "# trait type, eg 'binary' or 'quantitative'\n",
    "parameter: trait_type = str\n",
    "# Whether to use LOCO or not\n",
    "parameter: loco = 'TRUE'\n",
    "# Name of the sample column\n",
    "parameter: sampleCol='IID'\n",
    "#Path specific to SAIGE script\n",
    "parameter: script_path = path('~/software/bin/step1_fitNULLGLMM.R')\n",
    "# Inverse normalization only for non-normal quantitative traits\n",
    "parameter: invNormalize = 'FALSE'\n",
    "input: bfile, phenoFile\n",
    "output: f'{cwd}/{bfile:bn}.{phenoFile:bn}.SAIGE.rda', f'{cwd}/{bfile:bn}.{phenoFile:bn}.SAIGE.varianceRatio.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template_name='conda', env_name='RSAIGE'\n",
    "    Rscript ${script_path} \\\n",
    "        --plinkFile=${_input[0]:n} \\\n",
    "        --phenoFile=${_input[1]} \\\n",
    "        --phenoCol=${phenoCol[0]} \\\n",
    "        ${('--covarColList=' + ','.join(covarCol + qCovarCol)) if len(covarCol + qCovarCol) else ''} \\\n",
    "        --sampleIDColinphenoFile=${sampleCol} \\\n",
    "        --traitType=${trait_type} \\\n",
    "        --outputPrefix=${_output[0]:n} \\\n",
    "        --nThreads=${numThreads} \\\n",
    "        --LOCO=${loco} \\\n",
    "        --invNormalize=${invNormalize} \\\n",
    "        --IsOverwriteVarianceRatioFile=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: perform single variant association test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Compute SAIGE statistics\n",
    "[SAIGE_2]\n",
    "# Mimimum allele count to be used\n",
    "parameter: bgenMinMAC = 4\n",
    "#Specify whether to output allele frequencies in cases and controls\n",
    "parameter: af_caco = 'TRUE'\n",
    "#Path specific to SAIGE script\n",
    "parameter: script_path = path('~/software/bin/step2_SPAtests.R')\n",
    "# Fix SAIGE non-standard sample file input\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(sampleFile, header=0, skiprows=lambda x: x == 1, delim_whitespace=True)\n",
    "dat.to_csv(f\"{cwd}/{sampleFile:bn}.SAIGE_sample\", sep=' ', index=False, header=False, columns = [dat.columns[0]])\n",
    "\n",
    "input: for_each='genoFile'\n",
    "input_options = f\"--bgenFile={_genoFile} --bgenFileIndex=${_genoFile}.bgi --sampleFile=${cwd}/{sampleFile:bn}.SAIGE_sample --minInfo=${bgenMinINFO}\" if _input.suffix == \".bgen\" else f\"--plinkFile={_input:n}\"\n",
    "output: f'{cwd}/cache/{_genoFile:bn}.{phenoFile:bn}.SAIGE.gz'\n",
    "fail_if(not path(f'{_genoFile}.bgi').is_file() and _input.suffix == '.bgen', msg = f'Cannot find file ``{_genoFile}.bgi``. Please generate it using command ``bgenix -g {_genoFile} -index``.')\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template_name='conda', env_name='RSAIGE'\n",
    "    Rscript ${script_path} \\\n",
    "        ${input_options}\\\n",
    "        --minMAF=${bgenMinMAF} \\\n",
    "        --minMAC=${bgenMinMAC} \\\n",
    "        --GMMATmodelFile=${_input[0]} \\\n",
    "        --varianceRatioFile=${_input[1]} \\\n",
    "        --SAIGEOutputFile=${_output:n} \\\n",
    "        --numLinesOutput=2 \\\n",
    "        --IsOutputAFinCaseCtrl=${af_caco} \\\n",
    "        && sed '1 s/rsid //' -i ${_output:n} \\\n",
    "        && gzip -f --best ${_output:n} \\\n",
    "        && mv ${_output:n}.bgen.txt.gz ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Output from each step:\n",
    "\n",
    "**From step 1**\n",
    "\n",
    "1. Model file: `${_output}.rda`\n",
    "\n",
    "2. Association result file for the subset of randomly selected markers: `${_output}.results.txt`\n",
    "\n",
    "3. Variance ratio file: `${_output}.varianceRatio.txt`\n",
    "\n",
    "**From step 2**\n",
    "\n",
    "1. A file with association results for each chromosome (Note: this are given in regard to Allele 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## GMMAT workflow implementation\n",
    "Documentation can be found [here](https://github.com/hanchenphd/GMMAT/blob/master/inst/doc/GMMAT.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: Creation of the GRM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate standardized GRM using GEMMA\n",
    "[gemma_grm]\n",
    "parameter: grmFile = path(f'{cwd}/{bfile:bn}.sXX.txt')\n",
    "input: bfile\n",
    "output: grmFile\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '2h', mem = '6G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container='/mnt/mfs/statgen/containers/lmm.sif', expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    gemma \\\n",
    "    -bfile ${_input:n} \\\n",
    "    -gk 2 \\\n",
    "    -o ${_output:bnn} \\\n",
    "    -outdir ${grmFile:d}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run GMMAT step1: fit a GLMM with covariate adjustment and random effects to account for population structure and family or cryptic relatedness\n",
    "[GMMAT_null]\n",
    "#use the standardized GRM file generated in gemma steps\n",
    "parameter: grmFile = path(f'{cwd:d}/{bfile:bn}.sXX.txt')\n",
    "#a colum in the  data frame data, indicaing e id of samples\n",
    "parameter: phenoCol = 'AD'\n",
    "parameter: idCol = 'IID'\n",
    "input: phenoFile, f'{bfile:n}.fam', grmFile\n",
    "output: f'{cwd}/{bfile:bn}.{phenoFile:bn}.GMMAT.rds'\n",
    "R: container='/mnt/mfs/statgen/containers/lmm.sif',expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('GMMAT')\n",
    "    library('data.table')\n",
    "    library('dplyr')\n",
    "   \n",
    "    #Prepare phenotype and covariates in an R data frame\n",
    "    pheno = fread(${_input[0]:r}, header = TRUE)\n",
    "    #Pheno are currently coded as 1, 2, and -9, need to recoded as 0,1,and NA\n",
    "    pheno$${phenoCol}=  recode(pheno$${phenoCol}, `2` = 1, `1` = 0, `-9` = NULL)\n",
    "    #Prepare GRM file in a R data frame\n",
    "    GRM = as.matrix(fread(${_input[2]:r}, header = FALSE))\n",
    "    #Extract IIDs from .fam file\n",
    "    id_vector = fread(${_input[1]:r}, header = FALSE)[,2]\n",
    "    #make the GRM colnames and rownames using the actual IID\n",
    "    colnames(GRM) = t(id_vector)\n",
    "    rownames(GRM) = t(id_vector)\n",
    "\n",
    "    fit_null = glmmkin(${phenoCol} ~ ${\"+\".join(covarCol + qCovarCol)} , \n",
    "                           data = pheno, \n",
    "                           kins = GRM, \n",
    "                           id = '${idCol}',\n",
    "                           family = binomial(link = \"logit\"))\n",
    "    saveRDS(fit_null, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Perform single variant score test for common variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Run GMMAT step2: single variant score test(based on the null model built above)\n",
    "[GMMAT]\n",
    "#the maximum rate alllowed for a variant to be included\n",
    "parameter: geno_filter = 0.01\n",
    "#how many SNPs should be tested in a batch\n",
    "parameter: nperbatch = 100\n",
    "depends:  f'{cwd}/{bfile:bn}.{phenoFile:bn}.GMMAT.rds'\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.{phenoFile:bn}.gmmat.score.txt.gz'\n",
    "R:  container='/mnt/mfs/statgen/containers/lmm.sif', expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('GMMAT')\n",
    "    null_model = readRDS(${_depends:r})\n",
    "    glmm.score(null_model, \n",
    "               infile = ${_input:nr}, \n",
    "               outfile = ${_output:nr}, \n",
    "               MAF.range = c(${bgenMinMAF},1), \n",
    "               miss.cutoff = ${geno_filter},\n",
    "               nperbatch = ${nperbatch})\n",
    "bash: container=container_lmm,expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    gzip ${cwd}/${_input:bn}.${phenoFile:bn}.gmmat.score.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SMMAT workflow implementation\n",
    "Documentation can be found [here](https://github.com/hanchenphd/GMMAT/blob/master/inst/doc/GMMAT.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: Creation of the GRM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run SMMAT step1: fit a GLMM with covariate adjustment and random effects to account for population structure and family or cryptic relatedness\n",
    "[SMMAT_null]\n",
    "#use the standardized GRM file generated in gemma steps\n",
    "parameter: grmFile = path(f'{cwd:d}/{bfile:bn}.sXX.txt')\n",
    "#a colum in the  data frame data, indicaing e id of samples\n",
    "parameter: phenoCol = 'AD'\n",
    "parameter: idCol = 'IID'\n",
    "input: phenoFile, f'{bfile:n}.fam', grmFile\n",
    "output: f'{cwd}/{bfile:bn}.{phenoFile:bn}.GMMAT.rds'\n",
    "R: container='/mnt/mfs/statgen/containers/lmm.sif',expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('GMMAT')\n",
    "    library('data.table')\n",
    "    library('dplyr')\n",
    "   \n",
    "    #Prepare phenotype and covariates in an R data frame\n",
    "    pheno = fread(${_input[0]:r}, header = TRUE)\n",
    "    #Pheno are currently coded as 1, 2, and -9, need to recoded as 0,1,and NA\n",
    "    pheno$${phenoCol}=  recode(pheno$${phenoCol}, `2` = 1, `1` = 0, `-9` = NULL)\n",
    "    #Prepare GRM file in a R data frame\n",
    "    GRM = as.matrix(fread(${_input[2]:r}, header = FALSE))\n",
    "    #Extract IIDs from .fam file\n",
    "    id_vector = fread(${_input[1]:r}, header = FALSE)[,2]\n",
    "    #make the GRM colnames and rownames using the actual IID\n",
    "    colnames(GRM) = t(id_vector)\n",
    "    rownames(GRM) = t(id_vector)\n",
    "\n",
    "    fit_null = glmmkin(${phenoCol} ~ ${\"+\".join(covarCol + qCovarCol)} , \n",
    "                           data = pheno, \n",
    "                           kins = GRM, \n",
    "                           id = '${idCol}',\n",
    "                           family = binomial(link = \"logit\"))\n",
    "    saveRDS(fit_null, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Perform variant set burden test for rare variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# run SMMAT step 2:  variant set burden tests (based on the null model built above)\n",
    "[SMMAT]\n",
    "input: f'{bfile:n}.bed', f'{bfile:n}.fam',f'{bfile:n}.bim' group_by = 1, groupFile\n",
    "depends: f'{cwd}/{bfile:bn}.{phenoFile:bn}.GMMAT.rds'\n",
    "output: f'{cwd}/{_input[0]:bn}.{phenoFile:bn}.smmat.burden.txt.gz'\n",
    "R:  container='/mnt/mfs/statgen/containers/lmm.sif', expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('GMMAT')\n",
    "    library('SNPRelate')\n",
    "    snpgdsBED2GDS(${_input[0]}, ${_input[1]}, ${_input[2]}, f'{cwd}/{_input[0]:bn}.gds')\n",
    "    null_model = readRDS(${_depends:r})\n",
    "    burden.test = SMMAT(null_model,\n",
    "                        group.file = ${_input[4]},\n",
    "                        MAF.range = c(1e-7, ${maf_max_filter}),\n",
    "                        miss.cutoff = ${geno_filter},\n",
    "                        method = 'davies',\n",
    "                        tests = 'B')\n",
    "    write.table(burden.test,f'{cwd}/{_input[0]:bn}.{phenoFile:bn}.smmat.burden.txt', sep = '\\t', quote = F, col.names = T, row.names = F)\n",
    "  bash: container=container_lmm,expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    gzip ${cwd}/${_input[0]:bn}.${phenoFile:bn}.smmat.score.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Output from each step:\n",
    "\n",
    "**From step 1**\n",
    "\n",
    "Model file:` ${_output}.rda`\n",
    "\n",
    "\n",
    "**From step 2**\n",
    "\n",
    "A file with association results(score satistics, variance of score, score test P value) for each chromosome (Note: this are given in regard to Allele 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge results and log files\n",
    "[boltlmm_2, fastGWA_2, SAIGE_3, regenie_3, regenie_burden_3, GMMAT_1]\n",
    "parameter:reverse_log_p = False\n",
    "depends: formatFile\n",
    "input: group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz',\n",
    "        f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '1h', mem = '20G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: container=container_lmm, expand ='${ }'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "    if ${formatFile.is_file()}:\n",
    "        output = '${_output[0]:n}' + '_original_columns' + '${_output[0]:x}'\n",
    "    else:\n",
    "        output = '${_output[0]}'\n",
    "   \n",
    "    data = pd.concat([pd.read_csv(f, compression='gzip', header=0, delim_whitespace=True, quotechar='\"', comment='#') for f in [${_input:r,}]], ignore_index=True)\n",
    "    data.to_csv(output, compression='gzip', sep='\\t', header = True, index = False)\n",
    "    # unify output format\n",
    "    if ${formatFile.is_file()} or ${reverse_log_p}:\n",
    "        sumstats = pd.read_csv(output, compression='gzip', header=0, delim_whitespace=True, quotechar='\"')  \n",
    "        if ${formatFile.is_file()}:\n",
    "            import yaml\n",
    "            config = yaml.safe_load(open(${formatFile:r}, 'r'))\n",
    "        try:\n",
    "            sumstats = sumstats.loc[:,list(config.values())]\n",
    "        except:\n",
    "            raise ValueError(f'According to ${formatFile}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "        sumstats.columns = list(config.keys())\n",
    "        if ${reverse_log_p}:\n",
    "            sumstats['P'] = sumstats['P'].apply(lambda row: 10**-row)\n",
    "        sumstats.to_csv(${_output[0]:r}, compression='gzip', sep='\\t', header = True, index = False)        \n",
    "\n",
    "bash: container=container_lmm, expand=\"$( )\"\n",
    "    # count result SNPs\n",
    "    for f in $(_input); do echo \"$f: `zcat $f | wc -l`\"; done > $(_output[1])\n",
    "    # merge stderr and stdout files\n",
    "    for f in $(_input); do \n",
    "        for ext in stderr stdout log; do\n",
    "            echo \"$f $ext:\"\n",
    "            cat ${f%.gz}.$ext 2>/dev/null || true\n",
    "            rm -f ${f%.gz}.$ext \n",
    "        done\n",
    "    done > $(_output[0]:n).log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Manhattan and QQ plots\n",
    "\n",
    "Before running the pipeline make sure you have installed the necessary packages. We use the `qqman` package from R: https://www.r-graph-gallery.com/101_Manhattan_plot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[boltlmm_3, fastGWA_3, SAIGE_4, regenie_4, regenie_burden_4, GMMAT_2]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for SNP\n",
    "parameter: snp = 'SNP'\n",
    "# Plot only on p-values smaller than this\n",
    "parameter: p_filter = '0.05'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "sep = '\\n\\n---\\n'\n",
    "if any(['fastGWA' in step_name]):\n",
    "    heritability = get_output(f'grep Heritability {_input[0]:n}.log | head -1').strip()\n",
    "else:\n",
    "    heritability = None\n",
    "depends: phenoFile\n",
    "input: group_by = 2, group_with = 'phenoCol'\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        annotated_manhattan = f'{_input[0]:nn}.manhattan_annotated.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md',\n",
    "        plot_data = f'{_input[0]:nn}.plot_data.rds'       \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '48G', tags = f'{step_name}_{_output[0]:bn}'    \n",
    "bash: container=container_lmm, expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[3]}\n",
    "    \n",
    "R: container=container_lmm, expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = '\\t')$${_phenoCol}\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write('# ${_phenoCol} result summary\\n## Phenotype summary:\\n```', ${_output[3]:r}, append = T)\n",
    "    write.table(out, ${_output[3]:r}, append = T)\n",
    "    write('${(\" Heritability is %s\" % heritability) if heritability is not None else ''}', ${_output[3]:r}, append = T)\n",
    "    write(\"```\", ${_output[3]:r}, append = T)\n",
    "\n",
    "R: container=container_lmm, expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1))/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = 'Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"), chrlabs = as.character(c(1:22)))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = 'QQ Plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[3]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"variants analyzed.${sep}\"), ${_output[3]:r}, append=T)\n",
    "    \n",
    "  \n",
    "R: container=container_lmm, expand='${ }', stderr = f'{_output[2]:n}.stderr', stdout = f'{_output[2]:n}.stdout'\n",
    "    library('dplyr')\n",
    "    library('ggrepel')\n",
    "    #Load your data\n",
    "    data <- read.table(gzfile('${_input[0]}'),sep='\\t', header=T)\n",
    "    # Create a subset of the data with variants with P< 0.05 and arrange by chromosome number\n",
    "    # https://danielroelfs.com/blog/how-i-create-manhattan-plots-using-ggplot/\n",
    "    sig.dat <- data %>% \n",
    "      subset(${pval} < ${p_filter}) %>%\n",
    "      arrange (CHR, .by_group=TRUE)\n",
    "    # Add highlight and annotation information\n",
    "    #mutate( is_highlight=ifelse(SNP %in% index_snps, \"yes\", \"no\")) %>%\n",
    "    #mutate( is_annotate=ifelse(-log10(P_BOLT_LMM)>6, \"yes\", \"no\")) \n",
    "    # Check the list of chromosomes (make sure the sex chr are at the end of the list)\n",
    "    # Get the cumulative base pair position for each variant\n",
    "    nCHR <- length(unique(sig.dat$CHR))\n",
    "    sig.dat$BPcum <- NA\n",
    "    s <- 0\n",
    "    nbp <- c()\n",
    "    for (i in unique(sig.dat$CHR)){\n",
    "      nbp[i] <- max(sig.dat[sig.dat$CHR == i,]$${bp})\n",
    "      sig.dat[sig.dat$CHR == i,\"BPcum\"] <- sig.dat[sig.dat$CHR == i,\"${bp}\"] + s\n",
    "      s <- s + nbp[i]\n",
    "    }\n",
    "\n",
    "    # Calculate the mid point for each chromosome for plotting the x-axis\n",
    "    # Calculate the y-lim \n",
    "\n",
    "    axis.set <- sig.dat %>% \n",
    "      group_by(CHR) %>% \n",
    "      summarize(center = (max(BPcum) + min(BPcum)) / 2)\n",
    "    if (${ylim} == 0) ylim <- abs(floor(log10(min(sig.dat$${pval})))) + 2 \n",
    "    sig <- 5e-8\n",
    "\n",
    "    # Now time to draw the manhattan plot without filtering the most significant signals\n",
    "    manhplot <- ggplot(sig.dat, aes(x = BPcum, y = -log10(${pval}), \n",
    "                                 color = as.factor(CHR), size = -log10(${pval}))) +\n",
    "      geom_point(alpha = 0.75) +\n",
    "      geom_hline(yintercept = -log10(sig), color = \"red1\", linetype = \"dashed\") + \n",
    "      scale_x_continuous(label = axis.set$CHR, breaks = axis.set$center) +\n",
    "      scale_y_continuous(expand = c(0,0), limits = c(0, ylim)) +\n",
    "      scale_color_manual(values = rep(c(\"#276FBF\", \"#183059\"), nCHR)) +\n",
    "      scale_size_continuous(range = c(0.5,3)) +\n",
    "      # Add highlighted points\n",
    "      # geom_point(data=subset(sig.dat, is_highlight==\"yes\"), color=\"orange\", alpha=0.75) +\n",
    "      labs(x = \"Chromosome\", \n",
    "           y = \"-log10(p)\",\n",
    "           title ='Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})') + \n",
    "      theme_classic() +\n",
    "      theme( \n",
    "        legend.position = \"none\",\n",
    "        panel.border = element_blank(),\n",
    "        panel.grid.major.x = element_blank(),\n",
    "        panel.grid.minor.x = element_blank(),\n",
    "        axis.text.x = element_text(angle = 90, size = 8, vjust = 0.5)\n",
    "      )\n",
    "\n",
    "    # To save a plot created with ggplot2 you have to use to print() function\n",
    "\n",
    "    png('${_output[2]}', width = 6, height = 4, unit='in', res=300)\n",
    "    print(manhplot)\n",
    "    dev.off()\n",
    "  \n",
    "    # save significant data to a file for further evaluations\n",
    "    tmp = sig.dat[,c('CHR', '${bp}', 'BPcum', '${snp}', '${pval}')]\n",
    "    colnames(tmp) = c('CHR', 'POS', 'POScum', 'SNP', 'pvalue')\n",
    "    saveRDS(list(data = tmp, \n",
    "                 ylim = abs(floor(log10(min(sig.dat$${pval})))) + 2,\n",
    "                 axis.set = axis.set), ${_output[4]:r})\n",
    "\n",
    "bash: container=container_lmm, expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[2]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[3]}\n",
    "  ls {_input[0]:nn}.* | grep -vP 'stderr|stdout'>> {_output[3]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Create analysis report\n",
    "\n",
    "To install `marp`: \n",
    "```bash \n",
    "npm install -g @marp-team/marp-cli\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate analysis report: HTML file, and optionally PPTX file\n",
    "[boltlmm_4, fastGWA_4, SAIGE_5, regenie_5, regenie_burden_5, GMMAT_3]\n",
    "input: group_by = 5, group_with='phenoCol'\n",
    "output: f\"{_input['analysis_summary']:n}.html\"\n",
    "sh: container=container_marp, expand = True, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    node /opt/marp/.cli/marp-cli.js {_input['analysis_summary']} -o {_output:a} \\\n",
    "        --title '{_phenoCol} {step_name.rsplit(\"_\",1)[0]} analysis' \\\n",
    "        --allow-local-files\n",
    "    node /opt/marp/.cli/marp-cli.js {_input['analysis_summary']} -o {_output:an}.pptx \\\n",
    "        --title '{_phenoCol} {step_name.rsplit(\"_\",1)[0]} analysis' \\\n",
    "        --allow-local-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Take BoltLMM for example, there are some analysis files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.snp_stats.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.ref_stats.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.snp_counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The result of analysis will be summarized to a `PPTX` file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "ls output/*.boltlmm.analysis_summary.pptx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
