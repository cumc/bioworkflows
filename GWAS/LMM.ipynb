{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# LMM/GLMM analyses for UK Biobank data\n",
    "\n",
    "This notebook implements pipelines for analyzing binary and quantitative traits association using BOLT-LMM (version 2.3.4), fastGWA and SAIGE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This pipeline was initially developed to perfom genetic association analysis using various LMM methods on UK Biobank imputed data of ~500K invidivuals, although it can be used to analyze other studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. Genotype file for constructing the GRM (genetic relationship matrix) formated as a plink binary file `(.bed/.bim/.fam)` \n",
    "    - `--bfile=prefix`\n",
    "2. Imputed genotype dosages in `bgen` format (`.bgen`, `.bgi`, `.sample`)\n",
    "    - `--bgenFile` and ` --sampleFile`\n",
    "3. Phenotype file (white space delimited file with column headers, first two columns should be FID and IID) specify files by options `--phenoFile` and the phenotype to be analized by `--phenoCol`\n",
    "4. Covariates file (same format as phenoFile) specify them by `--covarFile` for qualitative covariates use `--covarCol` and for quantitative `--qCovarCol`. If `--covarFile` is not specified then phenotype file will be used as covariate file. To specify an array of covariates you can use bash tricks, eg `--qCovarCol PC{1:20}`\n",
    "\n",
    "Note: reference genome used **GRCh37/hg19**.\n",
    "\n",
    "## Software specific inputs\n",
    "\n",
    "### BoltLMM additional input\n",
    "\n",
    "- Reference genetic maps, provided on BoltLMM website\n",
    "    - `--geneticMapFile=tables/genetic_map_hg##.txt.gz`\n",
    "- Reference LD scores, provided on BoltLMM website\n",
    "- Use `--covarMaxLevels` to specify the number of categories of a qualitative covariate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Our pipeline generates \n",
    "\n",
    "1. Summary statistics file for each variant analyzed\n",
    "2. QQ and Manhattan plots for these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LMM.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  boltlmm\n",
      "  gcta\n",
      "  fastGWA\n",
      "  regenie\n",
      "  SAIGE\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --sampleFile VAL (as path, required)\n",
      "                        Path to sample file\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype files in plink binary this is used for\n",
      "                        computing the GRM\n",
      "  --bgenFile  paths\n",
      "\n",
      "                        Path to bgen files\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        Phenotype file for quantitative trait (BMI)\n",
      "  --phenoCol VAL (as str, required)\n",
      "                        Phenotype to be analyzed (specify the column)\n",
      "  --covarFile . (as path)\n",
      "                        Covariate file path. Will use phenoFile if empty\n",
      "  --formatFile . (as path)\n",
      "                        Summary statisticss format file path used for unifying\n",
      "                        output column names. Will not unify names if empty\n",
      "  --covarCol  (as list)\n",
      "                        Qualitative covariates to be used in the analysis\n",
      "  --qCovarCol  (as list)\n",
      "                        Quantitative covariates to be used in the analysis\n",
      "  --numThreads VAL (as int, required)\n",
      "                        Specific number of threads to use\n",
      "  --bgenMinMAF VAL (as float, required)\n",
      "                        Minimum MAF to be used\n",
      "  --bgenMinINFO VAL (as float, required)\n",
      "                        Mimimum info score to be used\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "\n",
      "Sections\n",
      "  boltlmm_1:            Run BOLT analysis\n",
      "    Workflow Options:\n",
      "      --covarMaxLevels VAL (as int, required)\n",
      "                        Maximum categories of covariates allowed\n",
      "      --LDscoresFile VAL (as path, required)\n",
      "                        Path to LDscore file for reference population\n",
      "      --geneticMapFile VAL (as path, required)\n",
      "                        Path to genetic map file used to interpolate genetic map\n",
      "                        coordinates from SNP physical (base pair) positions\n",
      "      --lmm-option lmm\n",
      "                        LMM option: lmm, lmmInfOnly, and lmmForceNonInf\n",
      "  gcta_1:               Partition the GRM into 100 parts and allocate 8GB memory\n",
      "                        to each job\n",
      "    Workflow Options:\n",
      "      --parts 100 (as int)\n",
      "                        Number of parts the GRM calculation is to be partitioned\n",
      "  gcta_2:               Merge all the parts together (Linux, Mac)\n",
      "  gcta_3:               Make a sparse GRM from the merged full-dense GRM\n",
      "  fastGWA_1:            fastGWA mixed model (based on the sparse GRM generated\n",
      "                        above)\n",
      "    Workflow Options:\n",
      "      --grmFile  path(f'{cwd}/{bfile:bn}.grm.sp')\n",
      "\n",
      "  regenie_0:\n",
      "    Workflow Options:\n",
      "      --plink2-module '\\nmodule load PLINK/2_x86_64_20180428\\necho \"Module plink2 loaded\"\\n{cmd}\\n'\n",
      "  regenie_1:            Run REGENIE step 1: fitting the null\n",
      "    Workflow Options:\n",
      "      --bsize VAL (as int, required)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --lowmem VAL (as path, required)\n",
      "                        Path to temporarily store block predictions\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "  regenie_2:            Run REGENIE step 2: association analysis\n",
      "    Workflow Options:\n",
      "      --minMAC 4 (as int)\n",
      "                        Mimimum allele count to be used\n",
      "      --phenoColList  (as list)\n",
      "  SAIGE_1:              Fit SAIGE null model\n",
      "    Workflow Options:\n",
      "      --trait-type VAL (as str, required)\n",
      "                        trait type, eg 'binary' or 'quantitative'\n",
      "      --loco TRUE\n",
      "                        Whether to use LOCO or not\n",
      "      --sampleCol IID\n",
      "                        Name of the sample column\n",
      "      --script-path /home/dc2325/software/bin/step1_fitNULLGLMM.R (as path)\n",
      "                        Path specific to SAIGE script\n",
      "      --invNormalize FALSE\n",
      "                        Inverse normalization only for non-normal quantitative\n",
      "                        traits\n",
      "  SAIGE_2:              Compute SAIGE statistics\n",
      "    Workflow Options:\n",
      "      --bgenMinMAC 4 (as int)\n",
      "                        Mimimum allele count to be used\n",
      "      --af-caco TRUE\n",
      "                        Specify whether to output allele frequencies in cases\n",
      "                        and controls\n",
      "      --script-path /home/dc2325/software/bin/step2_SPAtests.R (as path)\n",
      "                        Path specific to SAIGE script\n",
      "  boltlmm_2, fastGWA_2, SAIGE_3: Merge results and log files\n",
      "  boltlmm_3, fastGWA_3, SAIGE_4: Manhattan and QQ plots using `qqman`\n",
      "    Workflow Options:\n",
      "      --bp POS\n",
      "                        Column name for BP\n",
      "      --pval P\n",
      "                        Column name for p-value\n",
      "      --snp SNP\n",
      "                        Column name for SNP\n",
      "      --p-filter '0.05'\n",
      "                        Plot only on p-values smaller than this\n",
      "      --ylim 0 (as int)\n",
      "                        ylim set to 0 to use maximum -log10(p) in data\n",
      "  boltlmm_4, fastGWA_4, SAIGE_5: Generate analysis report: HTML file, and\n",
      "                        optionally PPTX file\n"
     ]
    }
   ],
   "source": [
    "sos run LMM.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "# Path to bgen files \n",
    "parameter: bgenFile = paths\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Covariate file path. Will use phenoFile if empty\n",
    "parameter: covarFile = path('.')\n",
    "# Summary statisticss format file path used for unifying output column names. Will not unify names if empty\n",
    "parameter: formatFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = int\n",
    "# Minimum MAF to be used\n",
    "parameter: bgenMinMAF = float\n",
    "# Mimimum info score to be used\n",
    "parameter: bgenMinINFO = float\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# The container with the lmm software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "parameter: container_option = 'statisticalgenetics/lmm'\n",
    "\n",
    "if not covarFile.is_file():\n",
    "    covarFile = phenoFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Illustration with minimal working examples\n",
    "\n",
    "```\n",
    "JOB_OPT='-j 2'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### BOLT-LMM example command\n",
    "\n",
    "On a minimal working example (MWE) dataset (about 1min to complete the analysis),\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb boltlmm \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --bgenFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/boltlmm_template.yml \\\n",
    "    --LDscoresFile BOLT-LMM_v2.3.4/tables/LDSCORE.1000G_EUR.tab.gz \\\n",
    "    --geneticMapFile BOLT-LMM_v2.3.4/tables/genetic_map_hg19_withX.txt.gz \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --covarMaxLevels 10 \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 5 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --lmm-option none \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```\n",
    "\n",
    "Please note that the command above is only meant to demonstrate the usage of the pipeline. Data will be generated to a folder called `output`. We set `--lmm-option` to `none` to not run LMM on this minimal data-set. The `--pval` column name `P_LINREG` for QQ/Manhattan plot is also p-value from conventional linear regression. In practice we will definitely want to use one of the LMM options in BoltLMM. Default is `lmm` switch in `bolt` if you don't specify `--lmm-option`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### fastGWA example command\n",
    "\n",
    "On a minimal working example (MWE) dataset (analysis completes almost instantly),\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb fastGWA \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --bgenFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/fastGWA_template.yml \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 1 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --parts 2 \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### REGENIE example command\n",
    "\n",
    "On a minimal working example (MWE) dataset,\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb regenie\\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes21_22.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --bgenFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/regenie_template.yml \\\n",
    "    --phenoCol ASTHMA T2D\\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --lowmem_prefix output \\\n",
    "    --trait bt \\\n",
    "    --minMAC 4 \\\n",
    "    --bgenMinMAF 0.05 \\\n",
    "    --bgenMinINFO 0.8 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### SAIGE example command\n",
    "\n",
    "On a minimal working example (MWE) dataset,\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb SAIGE \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --bgenFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --phenoCol BMI \\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 4 \\\n",
    "    --bgenMinMAF 0.001 \\\n",
    "    --bgenMinINFO 0.1 \\\n",
    "    --trait_type quantitative \\\n",
    "    --pval p.val \\\n",
    "    --bp POS \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Run workflow on a cluster\n",
    "\n",
    "The shell variable `JOB_OPT` was set to `-j 2`. That is, run 2 jobs in parallel on a local computer (each using 5 threads due to `--numThreads 5`).\n",
    "\n",
    "On cluster we use a job template, and configure `JOB_OPT` as follows: \n",
    "\n",
    "```\n",
    "JOB_OPT=\"-c farnam.yml -q farnam -J 40\"\n",
    "```\n",
    "\n",
    "Here we use task queue `farnam` configured in file `farnam.yml`. We allow for at most 40 jobs in the cluster job queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## BoltLMM workflow implementation\n",
    "\n",
    "To install from source code follow instructions here: https://data.broadinstitute.org/alkesgroup/BOLT-LMM/#x1-70002.2\n",
    "    - On Linux machine a binary executable is provided and can be used.\n",
    "    - Supporting files such as LD score file and genetic map file can be found [in the installation bundle](https://data.broadinstitute.org/alkesgroup/BOLT-LMM/downloads/BOLT-LMM_v2.3.4.tar.gz).\n",
    "    - For a complete description on bolt commands go to: http://manpages.ubuntu.com/manpages/eoan/en/man1/bolt.1.html.\n",
    "\n",
    "**A note for developers**: it is important to have input and output for each step. Input files and output files are best derived from one another.\n",
    "\n",
    "BOLT-LMM software computes statistics for testing association between phenotypes and genotypes using a linear mixed model\n",
    "\n",
    "\n",
    "```\n",
    "--bfile = accepts genotype files in PLINK binary format (.fam, .bed, .bim)\n",
    "--geneticMapFile = Oxford-format file for interpolating genetic distances: tables/genetic_map_hg##.txt.gz\n",
    "--phenoFile = phenotype file (header required; FII and IID must be first two columns)\n",
    "--phenoCol = phenotype columns header\n",
    "--covarFile = covariate file (header required; FII and IID must be first two columns)\n",
    "--covarCol = categorical covariate column(s); for >1, use multiple --covarCol and/or {i:j} expansion\n",
    "--qcovarCol = quantitative covariate column(s); for  >1, use multiple --qCovarCol and/or {i:j} expansion\n",
    "--lmm = compute assoc stats under the inf model and with Bayesian non-inf prior (VB approx), if power gain expected\n",
    "--modelSnps = file(s) listing SNPs to use in model (i.e., GRM) (default: use all non-excluded SNPs)\n",
    "--LDscoresFile = LD Scores for calibration of Bayesian assoc stats: tables/LDSCORE.1000G_EUR.tab.g\n",
    "--numThreads = number of computational threads\n",
    "--statsFile = output file for assoc stats at PLINK genotypes\n",
    "--bgenFile = file(s) containing Oxford BGEN-format genotypes to test for association\n",
    "--sampleFile = file containing Oxford sample file corresponding to BGEN file(s)\n",
    "--bgenMinMAF = MAF threshold on Oxford BGEN-format genotypes; lower-MAF SNPs will be ignored\n",
    "--bgenMinINFO = INFO threshold on Oxford BGEN-format genotypes; lower-INFO SNPs will be ignored\n",
    "--statsFileBgenSNPs = output file for assoc stats at BGEN-format genotypes\n",
    "```\n",
    "\n",
    "It is important to know that BOLT-LMMv2.3.4 accepts bgen files only in 8bit formatting as stated below:\n",
    "\n",
    "*WARNING: The BGEN format comprises a few sub-formats; we have only implemented support for the versions (and specific data layouts) used in the UK Biobank N=150K and N=500K releases. In particular, for BGEN v1.2, BOLT-LMM currently only supports the 8-bit encoding used for the UK Biobank N=500K data. (Starting with BOLT-LMM v2.3.3, missing values in BGEN v1.2 data are now allowed.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run BOLT analysis\n",
    "[boltlmm_1]\n",
    "# Maximum categories of covariates allowed \n",
    "parameter: covarMaxLevels = int\n",
    "# Path to LDscore file for reference population\n",
    "parameter: LDscoresFile = path\n",
    "# Path to genetic map file used to interpolate genetic map coordinates from SNP physical (base pair) positions\n",
    "parameter: geneticMapFile = path\n",
    "# LMM option: lmm, lmmInfOnly, and lmmForceNonInf\n",
    "parameter: lmm_option = 'lmm'\n",
    "depends: LDscoresFile, geneticMapFile\n",
    "input: bgenFile, group_by = 1\n",
    "output: f'{cwd}/cache/{_input:bn}.{phenoFile:bn}_{phenoCol[0]}.boltlmm.snp_stats.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bolt \\\n",
    "    --bfile=${bfile:n} \\\n",
    "    --phenoFile=${phenoFile} \\\n",
    "    --phenoCol=${phenoCol[0]} \\\n",
    "    --covarFile=${covarFile} \\\n",
    "    ${' '.join(['--covarCol=%s ' % x for x in covarCol if x is not None])} \\\n",
    "    --covarMaxLevels=${covarMaxLevels} \\\n",
    "    ${' '.join(['--qCovarCol=%s ' % x for x in qCovarCol if x is not None])} \\\n",
    "    --LDscoresFile=${LDscoresFile} \\\n",
    "    --geneticMapFile=${geneticMapFile} \\\n",
    "    ${('--' + lmm_option) if lmm_option in ['lmm', 'lmmInfOnly', 'lmmForceNonInf'] else ''} \\\n",
    "    --statsFile=${_output:nn}.ref_stats.gz \\\n",
    "    --numThreads=${numThreads} \\\n",
    "    --bgenFile=${_input} \\\n",
    "    --bgenMinMAF=${bgenMinMAF} \\\n",
    "    --bgenMinINFO=${bgenMinINFO} \\\n",
    "    --sampleFile=${sampleFile} \\\n",
    "    --statsFileBgenSnps=${_output} \\\n",
    "    --verboseStats\n",
    "\n",
    "bash: expand = \"${ }\", active = (_index != 0)\n",
    "    # remove redundant reference summary stats file\n",
    "    rm -f ${_output:nn}.ref_stats.gz\n",
    "\n",
    "bash: expand = \"${ }\", active = (_index == 0)\n",
    "    # rename reference summary stats file\n",
    "    mv ${_output:nn}.ref_stats.gz ${cwd}/${phenoFile:bn}_${phenoCol}.boltlmm.ref_stats.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## fastGWA workflow implementation\n",
    "\n",
    "Installation instructions can be found in https://cnsgenomics.com/software/gcta/#Download. On Linux machine a binary executable is provided and can be used.\n",
    "\n",
    "Documentation: https://cnsgenomics.com/software/gcta/#fastGWA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: Creation of the GRM\n",
    "The GRM only needs to be created once for all the phenotypes to analyze with the same genotypic data. In this step the GRM calculation is divided into multiple parts for a faster computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Partition the GRM into 100 parts and allocate 8GB memory to each job\n",
    "[gcta_1]\n",
    "# Number of parts the GRM calculation is to be partitioned\n",
    "parameter: parts = 100\n",
    "part_number = [f'{parts}_{format(x+1, \"0\" + str(len(str(parts))))}' for x in range(parts)]\n",
    "input: bfile, for_each = 'part_number'\n",
    "output: f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.bin', \n",
    "        f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.N.bin', \n",
    "        f'{cwd}/cache/{_input:bn}.part_{_part_number}.grm.id'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    gcta64 \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --make-grm-part ${parts} ${_index+1} \\\n",
    "    --thread-num ${numThreads} \\\n",
    "    --out ${_output[0]:nnn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Combine all the GRM parts into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the parts together (Linux, Mac)\n",
    "[gcta_2]\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/{bfile:bn}.grm.bin', \n",
    "        f'{cwd}/{bfile:bn}.grm.N.bin', \n",
    "        f'{cwd}/{bfile:bn}.grm.id' \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '2h', mem = '6G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # here input is results all parts each having 3 items. We need to get the corresponding every other 3 items\n",
    "    cat ${paths(_input[::3])} > ${_output[0]}\n",
    "    cat ${paths(_input[1::3])} > ${_output[1]}\n",
    "    cat ${paths(_input[2::3])} > ${_output[2]}\n",
    "    #rm ${paths(_input)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Make a sparse GRM to be used in the association analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make a sparse GRM from the merged full-dense GRM\n",
    "[gcta_3]\n",
    "output: f'{cwd}/{bfile:bn}.grm.sp' \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    gcta64 --grm ${_output:nn} --make-bK-sparse 0.05 --out ${_output:nn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 4: Run the single variant association analysis using FastGWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# fastGWA mixed model (based on the sparse GRM generated above)\n",
    "[fastGWA_1]\n",
    "parameter: grmFile = path(f'{cwd}/{bfile:bn}.grm.sp')\n",
    "depends: grmFile\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True)\n",
    "if len(phenoCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_phenotype\", sep=' ', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True)\n",
    "if len(covarCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_covar\", sep=' ', index=False, columns = ['FID', 'IID'] + covarCol)\n",
    "if len(qCovarCol) > 0:\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.fastGWA_qcovar\", sep=' ', index=False, columns = ['FID', 'IID'] + qCovarCol)\n",
    "\n",
    "input: bgenFile, group_by = 1, group_with = dict(info=[(path(f\"{cwd}/{phenoFile:bn}.fastGWA_phenotype\"), sampleFile, grmFile,\n",
    "                                                        path(f\"{cwd}/{covarFile:bn}.fastGWA_qcovar\"), path(f\"{cwd}/{covarFile:bn}.fastGWA_covar\"))] * len(bgenFile))\n",
    "output: f'{cwd}/cache/{_input:bnn}.{phenoFile:bn}.fastGWA.gz'\n",
    "fail_if(not path(f'{_input}.bgi').is_file(), msg = f'Cannot find file ``{_input}.bgi``. Please generate it using command ``bgenix -g {_input} -index``.')\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '5G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    gcta64 \\\n",
    "    --bgen ${_input} \\\n",
    "    --sample  ${_input.info[1]} \\\n",
    "    --grm-sparse ${_input.info[2]:nn} \\\n",
    "    --maf ${bgenMinMAF} \\\n",
    "    --info ${bgenMinINFO} \\\n",
    "    --fastGWA-mlm \\\n",
    "    --pheno ${_input.info[0]} \\\n",
    "    --qcovar ${_input.info[3]} \\\n",
    "    --covar ${_input.info[4]} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --out ${_output:nn} \\\n",
    "    && gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Output from each step:\n",
    "\n",
    "1. **gcta_1 for x number of parts (in the example above x=100, so this step will create 400 files):**\n",
    "* test.part_{_part_number}.grm.bin\n",
    "* test.part_{_part_number}.grm.N.bin \n",
    "* test.part_{_part_number}.grm.id\n",
    "* test.part_{_part_number}.log (the program creates the log file so there is no need for .stderr and .stdout)\n",
    "\n",
    "2. **gcta_2 this step creates 5 output files:**\n",
    "* test.grm.bin (it is a binary file which contains the lower triangle elements of the GRM)\n",
    "* test.grm.N.bin (it is a binary file which contains the number of SNPs used to calculate the GRM)\n",
    "* test.grm.id (no header line; columns are family ID and individual ID, see above)\n",
    "* test.grm.stderr\n",
    "* test.grm.stdout\n",
    "\n",
    "3. **gcta_3 this step creates 3 output files:**\n",
    "* test.grm.sp (sparse GRM made from the dense GRM)\n",
    "* test.grm.sp.stderr\n",
    "* test.grm.sp.stdout\n",
    "\n",
    "4. **fastGWA this step creates 2 output files per chromosome**\n",
    "* test{chr1:22}.fastGWA\n",
    "* test{chr1:22}.fastGWA.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# REGENIE workflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Documentation can be found [here](https://rgcgithub.github.io/regenie/). Binary and quantitative traits should be analyzed separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select the SNPs and samples to be used based on maf, geno, hwe and mind options\n",
    "[regenie_qc: provides = [f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist']]\n",
    "parameter: mwe_filter = 0\n",
    "parameter: geno_filter = 0\n",
    "parameter: hwe_filter = 0\n",
    "parameter: mind_filter = 0\n",
    "parameter: plink2_module = '''\n",
    "module load PLINK/2_x86_64_20180428\n",
    "echo \"Module plink2 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "input: bfile\n",
    "output: f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template = '{cmd}' if executable('plink2').target_exists() else plink2_module    \n",
    "    plink2 \\\n",
    "      --bfile ${bfile:n} ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --write-samples --no-id-header \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output[0]:n} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 1: fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 1: fitting the null\n",
    "[regenie_1]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = int\n",
    "# Path to temporarily store block predictions\n",
    "parameter: lowmem_prefix = path('.')\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True, dtype=str)\n",
    "dat = dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "if len(phenoCol) > 0:    \n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", sep=' ', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True)\n",
    "if len(covarCol) > 0 or len(qCovarCol) > 0:\n",
    "    dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_covar\", sep=' ', index=False, columns = ['FID', 'IID'] + covarCol + qCovarCol)\n",
    "depends: f'{cwd}/cache/{bfile:bn}.qc_pass.snplist', f'{cwd}/cache/{bfile:bn}.qc_pass.id'\n",
    "input: bfile, f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", f\"{cwd}/{phenoFile:bn}.regenie_covar\"\n",
    "output: f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_option, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    regenie \\\n",
    "      --step 1 \\\n",
    "      --bed ${_input[0]:n} \\\n",
    "      --phenoFile ${_input[1]} \\\n",
    "      --covarFile ${_input[2]} \\\n",
    "      --extract ${_depends[0]} \\\n",
    "      --keep ${_depends[1]} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --lowmem --lowmem-prefix ${lowmem_prefix} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:nn}.regenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2: association analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 2: association analysis\n",
    "[regenie_2]\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "parameter: trait = 'bt'\n",
    "input: bgenFile, group_by = 1, group_with = dict(info=[(path(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\"),\n",
    "                                                        path(f\"{cwd}/{covarFile:bn}.regenie_covar\"),\n",
    "                                                        path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(bgenFile))\n",
    "output: [f'{cwd}/{_input:bn}_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash:container=container_option, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    set -e\n",
    "    regenie \\\n",
    "     --step 2 \\\n",
    "     --bgen ${_input} \\\n",
    "     --phenoFile ${_input.info[0]} \\\n",
    "     --covarFile ${_input.info[1]} \\\n",
    "     --phenoColList ${','.join(phenoCol)} \\\n",
    "     ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "     --firth 0.01 --approx \\\n",
    "     --pred ${_input.info[2]} \\\n",
    "     --bsize 400 \\\n",
    "     --minMAC ${minMAC} \\\n",
    "     --split \\\n",
    "     --threads ${numThreads} \\\n",
    "     --out ${str(_output[0]).rsplit('_',1)[0]}\n",
    "     gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SAIGE workflow implementation\n",
    "\n",
    "We need to create a conda enviroment for the installation of SAIGE in Yale's HRC cluster. Instructions in https://github.com/weizhouUMICH/SAIGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Fit SAIGE null model\n",
    "[SAIGE_1]\n",
    "# trait type, eg 'binary' or 'quantitative'\n",
    "parameter: trait_type = str\n",
    "# Whether to use LOCO or not\n",
    "parameter: loco = 'TRUE'\n",
    "# Name of the sample column\n",
    "parameter: sampleCol='IID'\n",
    "#Path specific to SAIGE script\n",
    "parameter: script_path = path('~/software/bin/step1_fitNULLGLMM.R')\n",
    "# Inverse normalization only for non-normal quantitative traits\n",
    "parameter: invNormalize = 'FALSE'\n",
    "input: bfile, phenoFile\n",
    "output: f'{cwd}/{bfile:bn}.{phenoFile:bn}.SAIGE.rda', f'{cwd}/{bfile:bn}.{phenoFile:bn}.SAIGE.varianceRatio.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template_name='conda', env_name='RSAIGE'\n",
    "    Rscript ${script_path} \\\n",
    "        --plinkFile=${_input[0]:n} \\\n",
    "        --phenoFile=${_input[1]} \\\n",
    "        --phenoCol=${phenoCol[0]} \\\n",
    "        ${('--covarColList=' + ','.join(covarCol + qCovarCol)) if len(covarCol + qCovarCol) else ''} \\\n",
    "        --sampleIDColinphenoFile=${sampleCol} \\\n",
    "        --traitType=${trait_type} \\\n",
    "        --outputPrefix=${_output[0]:n} \\\n",
    "        --nThreads=${numThreads} \\\n",
    "        --LOCO=${loco} \\\n",
    "        --invNormalize=${invNormalize} \\\n",
    "        --IsOverwriteVarianceRatioFile=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: perform single variant association test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Compute SAIGE statistics\n",
    "[SAIGE_2]\n",
    "# Mimimum allele count to be used\n",
    "parameter: bgenMinMAC = 4\n",
    "#Specify whether to output allele frequencies in cases and controls\n",
    "parameter: af_caco = 'TRUE'\n",
    "#Path specific to SAIGE script\n",
    "parameter: script_path = path('~/software/bin/step2_SPAtests.R')\n",
    "# Fix SAIGE non-standard sample file input\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(sampleFile, header=0, skiprows=lambda x: x == 1, delim_whitespace=True)\n",
    "dat.to_csv(f\"{cwd}/{sampleFile:bn}.SAIGE_sample\", sep=' ', index=False, header=False, columns = [dat.columns[0]])\n",
    "\n",
    "input: for_each='bgenFile'\n",
    "output: f'{cwd}/cache/{_bgenFile:bn}.{phenoFile:bn}.SAIGE.gz'\n",
    "fail_if(not path(f'{_bgenFile}.bgi').is_file(), msg = f'Cannot find file ``{_bgenFile}.bgi``. Please generate it using command ``bgenix -g {_bgenFile} -index``.')\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template_name='conda', env_name='RSAIGE'\n",
    "    Rscript ${script_path} \\\n",
    "        --bgenFile=${_bgenFile} \\\n",
    "        --bgenFileIndex=${_bgenFile}.bgi \\\n",
    "        --minMAF=${bgenMinMAF} \\\n",
    "        --minMAC=${bgenMinMAC} \\\n",
    "        --minInfo=${bgenMinINFO} \\\n",
    "        --sampleFile=${cwd}/${sampleFile:bn}.SAIGE_sample \\\n",
    "        --GMMATmodelFile=${_input[0]} \\\n",
    "        --varianceRatioFile=${_input[1]} \\\n",
    "        --SAIGEOutputFile=${_output:n} \\\n",
    "        --numLinesOutput=2 \\\n",
    "        --IsOutputAFinCaseCtrl=${af_caco} \\\n",
    "        && sed '1 s/rsid //' -i ${_output:n} \\\n",
    "        && gzip -f --best ${_output:n} \\\n",
    "        && mv ${_output:n}.bgen.txt.gz ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Output from each step:\n",
    "\n",
    "**From step 1**\n",
    "\n",
    "1. Model file: `${_output}.rda`\n",
    "\n",
    "2. Association result file for the subset of randomly selected markers: `${_output}.results.txt`\n",
    "\n",
    "3. Variance ratio file: `${_output}.varianceRatio.txt`\n",
    "\n",
    "**From step 2**\n",
    "\n",
    "1. A file with association results for each chromosome (Note: this are given in regard to Allele 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge results and log files\n",
    "[boltlmm_2, fastGWA_2, SAIGE_3, regenie_3]\n",
    "parameter:reverse_log_p = False\n",
    "input: group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz',\n",
    "        f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '30m', mem = '6G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand ='${ }'\n",
    "    import gzip\n",
    "    n_lines = -1\n",
    "    if ${formatFile.is_file()}:\n",
    "        output = '${_output[0]:n}' + '_original_columns' + '${_output[0]:x}'\n",
    "    else:\n",
    "        output = '${_output[0]}'\n",
    "    with gzip.open(output, 'wt') as outfile:\n",
    "        with gzip.open(${_input[0]:r}) as f:\n",
    "            for line in f:\n",
    "                outfile.write(line.decode('utf-8'))\n",
    "            for files in [${_input:r,}][1:]:\n",
    "                with gzip.open(files) as f:\n",
    "                    i = 0\n",
    "                    for line in f:\n",
    "                        if i > 0:\n",
    "                            outfile.write(line.decode('utf-8'))\n",
    "                        i += 1\n",
    "    # unify output format\n",
    "    if ${formatFile.is_file()} or ${reverse_log_p}:\n",
    "        import pandas as pd\n",
    "        sumstats = pd.read_csv(output, compression='gzip', header=0, delim_whitespace=True, quotechar='\"')  \n",
    "        if ${formatFile.is_file()}:\n",
    "            import yaml\n",
    "            config = yaml.safe_load(open(${formatFile:r}, 'r'))\n",
    "        try:\n",
    "            sumstats = sumstats.loc[:,list(config.values())]\n",
    "        except:\n",
    "            raise ValueError(f'According to ${formatFile}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "        sumstats.columns = list(config.keys())\n",
    "        if ${reverse_log_p}:\n",
    "            sumstats['P'] = sumstats['P'].apply(lambda row: 10**-row)\n",
    "        sumstats.to_csv(${_output[0]:r}, compression='gzip', sep='\\t', header = True, index = False)        \n",
    "\n",
    "bash: expand=\"$( )\"\n",
    "    # count result SNPs\n",
    "    for f in $(_input); do echo \"$f: `zcat $f | wc -l`\"; done > $(_output[1])\n",
    "    # merge stderr and stdout files\n",
    "    for f in $(_input); do \n",
    "        for ext in stderr stdout log; do\n",
    "            echo \"$f $ext:\"\n",
    "            cat ${f%.gz}.$ext 2>/dev/null || true\n",
    "            rm -f ${f%.gz}.$ext \n",
    "        done\n",
    "    done > $(_output[0]:n).log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Manhattan and QQ plots\n",
    "\n",
    "Before running the pipeline make sure you have installed the necessary packages. We use the `qqman` package from R: https://www.r-graph-gallery.com/101_Manhattan_plot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[boltlmm_3, fastGWA_3, SAIGE_4, regenie_4]\n",
    "depends: R_library('qqman'), R_library('dplyr'), R_library('ggrepel'), R_library('ggplot2')\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for SNP\n",
    "parameter: snp = 'SNP'\n",
    "# Plot only on p-values smaller than this\n",
    "parameter: p_filter = '0.05'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "sep = '\\n\\n---\\n'\n",
    "input: group_by = 2, group_with = 'phenoCol'\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        annotated_manhattan = f'{_input[0]:nn}.manhattan_annotated.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md',\n",
    "        plot_data = f'{_input[0]:nn}.plot_data.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '48G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "    \n",
    "bash: expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[3]}\n",
    "    \n",
    "R: expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    pheno = read.table(${phenoFile:r}, header=T)$${_phenoCol}\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write('# ${_phenoCol} result summary\\n## Phenotype summary:\\n```', ${_output[3]:r}, append = T)\n",
    "    write.table(out, ${_output[3]:r}, append = T)\n",
    "    write(\"```\", ${_output[3]:r}, append = T)\n",
    "\n",
    "R: expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1))/qchisq(0.5,1)\n",
    "    if (${ylim} == 0) ylim <- abs(ceiling(log10(min(data$${pval}))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = 'Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"), suggestiveline = T, genomewideline = T, chrlabs = as.character(c(1:22)))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = 'QQ Plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[3]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"variants analyzed.${sep}\"), ${_output[3]:r}, append=T)\n",
    "    \n",
    "  \n",
    "R: expand='${ }', stderr = f'{_output[2]:n}.stderr', stdout = f'{_output[2]:n}.stdout'\n",
    "    library('dplyr')\n",
    "    library('ggrepel')\n",
    "    #Load your data\n",
    "    data <- read.table(gzfile('${_input[0]}'), header=T)\n",
    "    # Create a subset of the data with variants with P< 0.05 and arrange by chromosome number\n",
    "    # https://danielroelfs.com/blog/how-i-create-manhattan-plots-using-ggplot/\n",
    "    sig.dat <- data %>% \n",
    "      subset(${pval} < ${p_filter}) %>%\n",
    "      arrange (CHR, .by_group=TRUE)\n",
    "    # Add highlight and annotation information\n",
    "    #mutate( is_highlight=ifelse(SNP %in% index_snps, \"yes\", \"no\")) %>%\n",
    "    #mutate( is_annotate=ifelse(-log10(P_BOLT_LMM)>6, \"yes\", \"no\")) \n",
    "    # Check the list of chromosomes (make sure the sex chr are at the end of the list)\n",
    "    # Get the cumulative base pair position for each variant\n",
    "    nCHR <- length(unique(sig.dat$CHR))\n",
    "    sig.dat$BPcum <- NA\n",
    "    s <- 0\n",
    "    nbp <- c()\n",
    "    for (i in unique(sig.dat$CHR)){\n",
    "      nbp[i] <- max(sig.dat[sig.dat$CHR == i,]$${bp})\n",
    "      sig.dat[sig.dat$CHR == i,\"BPcum\"] <- sig.dat[sig.dat$CHR == i,\"${bp}\"] + s\n",
    "      s <- s + nbp[i]\n",
    "    }\n",
    "\n",
    "    # Calculate the mid point for each chromosome for plotting the x-axis\n",
    "    # Calculate the y-lim \n",
    "\n",
    "    axis.set <- sig.dat %>% \n",
    "      group_by(CHR) %>% \n",
    "      summarize(center = (max(BPcum) + min(BPcum)) / 2)\n",
    "    if (${ylim} == 0) ylim <- abs(floor(log10(min(sig.dat$${pval})))) + 2 \n",
    "    sig <- 5e-8\n",
    "\n",
    "    # Now time to draw the manhattan plot without filtering the most significant signals\n",
    "    manhplot <- ggplot(sig.dat, aes(x = BPcum, y = -log10(${pval}), \n",
    "                                 color = as.factor(CHR), size = -log10(${pval}))) +\n",
    "      geom_point(alpha = 0.75) +\n",
    "      geom_hline(yintercept = -log10(sig), color = \"red1\", linetype = \"dashed\") + \n",
    "      scale_x_continuous(label = axis.set$CHR, breaks = axis.set$center) +\n",
    "      scale_y_continuous(expand = c(0,0), limits = c(0, ylim)) +\n",
    "      scale_color_manual(values = rep(c(\"#276FBF\", \"#183059\"), nCHR)) +\n",
    "      scale_size_continuous(range = c(0.5,3)) +\n",
    "      # Add highlighted points\n",
    "      # geom_point(data=subset(sig.dat, is_highlight==\"yes\"), color=\"orange\", alpha=0.75) +\n",
    "      labs(x = \"Chromosome\", \n",
    "           y = \"-log10(p)\",\n",
    "           title ='Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})') + \n",
    "      theme_classic() +\n",
    "      theme( \n",
    "        legend.position = \"none\",\n",
    "        panel.border = element_blank(),\n",
    "        panel.grid.major.x = element_blank(),\n",
    "        panel.grid.minor.x = element_blank(),\n",
    "        axis.text.x = element_text(angle = 90, size = 8, vjust = 0.5)\n",
    "      )\n",
    "\n",
    "    # To save a plot created with ggplot2 you have to use to print() function\n",
    "\n",
    "    png('${_output[2]}', width = 6, height = 4, unit='in', res=300)\n",
    "    print(manhplot)\n",
    "    dev.off()\n",
    "  \n",
    "    # save significant data to a file for further evaluations\n",
    "    tmp = sig.dat[,c('CHR', '${bp}', 'BPcum', '${snp}', '${pval}')]\n",
    "    colnames(tmp) = c('CHR', 'POS', 'POScum', 'SNP', 'pvalue')\n",
    "    saveRDS(list(data = tmp, \n",
    "                 ylim = abs(floor(log10(min(sig.dat$${pval})))) + 2,\n",
    "                 axis.set = axis.set), ${_output[4]:r})\n",
    "\n",
    "bash: expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[3]}\n",
    "  echo -e \"![]({_output[2]:bn}.png){sep}\" >> {_output[3]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[3]}\n",
    "  ls {_input[0]:nn}.* | grep -vP 'stderr|stdout'>> {_output[3]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Create analysis report\n",
    "\n",
    "To install `marp`: \n",
    "```bash \n",
    "npm install -g @marp-team/marp-cli\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate analysis report: HTML file, and optionally PPTX file\n",
    "[boltlmm_4, fastGWA_4, SAIGE_5, regenie_5]\n",
    "depends: executable('marp')\n",
    "input: group_by = 5, group_with='phenoCol'\n",
    "output: f\"{_input['analysis_summary']:n}.html\"\n",
    "bash: workdir = cwd, expand = True\n",
    "    set -e\n",
    "    marp {_input['analysis_summary']:b} -o {_output:a} \\\n",
    "        --title '{_phenoCol} {step_name.rsplit(\"_\",1)[0]} analysis' \\\n",
    "        --allow-local-files || true\n",
    "    marp {_input['analysis_summary']:b} -o {_output:an}.pptx \\\n",
    "        --title '{_phenoCol} {step_name.rsplit(\"_\",1)[0]} analysis' \\\n",
    "        --allow-local-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Take BoltLMM for example, there are some analysis files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.snp_stats.gz (1.3 KiB):</div>"
      ],
      "text/plain": [
       "\n",
       "> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.snp_stats.gz (1.3 KiB):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP\tCHR\tBP\tGENPOS\tALLELE1\tALLELE0\tA1FREQ\tINFO\tCHISQ_LINREG\tP_LINREG\n",
      "rs79945276\t21\t48096251\t0.646473\tT\tG\t0.0640784\t0.96222\t4.23679\t4.0E-02\n",
      "rs12481825\t21\t48096617\t0.646484\tA\tC\t0.0153529\t0.977965\t0.712511\t4.0E-01\n",
      "rs61504104\t21\t48096920\t0.646493\tC\tT\t0.0887647\t0.975897\t0.0796273\t7.8E-01\n",
      "rs55777714\t21\t48097101\t0.646499\tT\tC\t0.169882\t0.959507\t0.128473\t7.2E-01\n"
     ]
    }
   ],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.snp_stats.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.ref_stats.gz (10.3 MiB):</div>"
      ],
      "text/plain": [
       "\n",
       "> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.ref_stats.gz (10.3 MiB):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP\tCHR\tBP\tGENPOS\tALLELE1\tALLELE0\tA1FREQ\tF_MISS\tCHISQ_LINREG\tP_LINREG\n",
      "rs3131962\t1\t756604\t0.00490722\tA\tG\t0.165\t0\t0.0284453\t8.7E-01\n",
      "rs12562034\t1\t768448\t0.00495714\tA\tG\t0.07\t0\t1.03484\t3.1E-01\n",
      "rs4040617\t1\t779322\t0.00500708\tG\tA\t0.155\t0\t0.133342\t7.1E-01\n",
      "rs79373928\t1\t801536\t0.0058722\tG\tT\t0.02\t0\t0.0409388\t8.4E-01\n"
     ]
    }
   ],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.ref_stats.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.snp_counts.txt (142 B):</div>"
      ],
      "text/plain": [
       "\n",
       "> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.snp_counts.txt (142 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">2 lines</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/imputed_genotypes_chr21.phenotypes_BMI.boltlmm.snp_stats.gz: 25\n",
      "output/imputed_genotypes_chr22.phenotypes_BMI.boltlmm.snp_stats.gz: 22"
     ]
    }
   ],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.snp_counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.log (34.8 KiB):</div>"
      ],
      "text/plain": [
       "\n",
       "> /home/gw/tmp/10-Jun-2020/MWE_test/output/phenotypes_BMI.boltlmm.log (34.8 KiB):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">1036 lines (5 displayed, see --limit)</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/imputed_genotypes_chr21.phenotypes_BMI.boltlmm.snp_stats.gz stderr:\n",
      "NOTE: Using all-1s vector (constant term) in addition to specified covariates\n",
      "NOTE: Using all-1s vector (constant term) in addition to specified covariates\n",
      "NOTE: Using all-1s vector (constant term) in addition to specified covariates\n",
      "NOTE: Using all-1s vector (constant term) in addition to specified covariates"
     ]
    }
   ],
   "source": [
    "%preview output/phenotypes_BMI.boltlmm.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The result of analysis will be summarized to a `PPTX` file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/phenotypes_BMI.boltlmm.analysis_summary.pptx\n"
     ]
    }
   ],
   "source": [
    "ls output/*.boltlmm.analysis_summary.pptx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.13"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
