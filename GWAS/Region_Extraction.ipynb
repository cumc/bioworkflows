{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Extracting data for genomic regions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To extract the summary statistics and genotype on specific genomic regions and calculate their LD matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "Make sure you install the pre-requisited before running this notebook:\n",
    "\n",
    "```\n",
    "pip install pybgen\n",
    "pip install pandas_plink\n",
    "pip install scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Input\n",
    "\n",
    "- `--region-file`, including a list of regions\n",
    "    - Each locus will be represented by one line in the region file with 3 columns chr, start, and end. e.g. `7 27723990 28723990`\n",
    "- `--geno-path`, the path of a genotype inventory, which lists the path of all genotype file in `bgen` format or in `plink` format.\n",
    "    - The list is a file with 2 columns: `chr genotype_file_chr.ext`. \n",
    "    - The first column is chromosome ID, the 2nd file is genotype for that chromosome.\n",
    "    - When chromosome ID is 0, it implies that the genotype file contains all the genotypes.\n",
    "- `--pheno-path`, the path of a phenotype.\n",
    "    - The phenotype file should have a column with the name `IID`, which is used to represent the sample ID.\n",
    "- `--bgen-sample-path`, the path of a file including the sample in the `bgen` files.\n",
    "    - If the genotype file is in `bgen` format, you should provide this path.\n",
    "- `--sumstats-path`, the path of the GWAS file, including all summary statistics (eg, $\\hat{\\beta}$, $SE(\\hat{\\beta})$ and p-values)\n",
    "    - These summary statistics should contain at least these columns: `chrom, pos, ref, alt, snp_id, bhat, sbhat, p`\n",
    "- `--unrelated-samples`, the file path of unrelated samples with a column named `IID`.   \n",
    "- `--cwd`, the path of output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Output\n",
    "- `rg_stat`, the reginonal summary stats\n",
    "    - The rowname is the variant ID.\n",
    "    - It should contain at least the following columns: `CHR, BP, SNP, ALT, REF, BETA, SE, Z, P`.\n",
    "- `rg_geno`,the regional genotypes\n",
    "    - The rowname is the variant ID, which should match with the rowname of `rg_stat`.\n",
    "    - The column name is the sample's IID, which is sorted by the sample in phenotype.\n",
    "- `pld`, the regional approximate population LD calculated by unrelated individuals\n",
    "- `sld`, the regional approximate sample LD calcualted by unrelated individuals in a phenotype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Using our minimal working example data-set where we have already generated results for fastGWA,\n",
    "\n",
    "```\n",
    "sos run Region_Extraction.ipynb \\\n",
    "    --cwd candidate_loci \\\n",
    "    --region-file data/regions.txt \\\n",
    "    --pheno-path data/phenotypes.txt \\\n",
    "    --geno-path data/genotype_inventory.txt \\\n",
    "    --bgen-sample-path data/imputed_genotypes.sample \\\n",
    "    --sumstats-path output/phenotypes_BMI.fastGWA.snp_stats.gz \\\n",
    "    --unrelated-samples data/unrelated_samples.txt \\\n",
    "    --job-size 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory where output will be saved to\n",
    "parameter: cwd = path\n",
    "# Region specifications\n",
    "parameter: region_file = path\n",
    "# Genotype file inventory\n",
    "parameter: geno_path = path\n",
    "# Phenotype path\n",
    "parameter: pheno_path = path\n",
    "# Sample file path, for bgen format\n",
    "parameter: bgen_sample_path = path('.')\n",
    "# Path to summary stats file\n",
    "parameter: sumstats_path = path\n",
    "# Path to summary stats format configuration\n",
    "parameter: format_config_path = path('.')\n",
    "# Path to samples of unrelated individuals\n",
    "parameter: unrelated_samples = path\n",
    "# Number of tasks to run in each job on cluster\n",
    "parameter: job_size = int\n",
    "\n",
    "fail_if(not region_file.is_file(), msg = 'Cannot find regions to extract. Please specify them using ``--region-file`` option.')\n",
    "# Load all regions of interest. Each item in the list will be a region: (chr, start, end)\n",
    "regions = list(set([tuple(x.strip().split()) for x in open(region_file).readlines() if x.strip()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Some utility functions\n",
    "\n",
    "- `plink_slice`: The function of extracting regional genotype\n",
    "   - p: list of bim, fam, bed\n",
    "   - pb: index of bim\n",
    "   - pf: index of fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_1 (export utils script)]\n",
    "report: expand = '${ }', output=f'{cwd:a}/utils.py'\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from xxhash import xxh32 as xxh\n",
    "\n",
    "    def shorten_id(x):\n",
    "        return x if len(x) < 30 else f\"{x.split('_')[0]}_{xxh(x).hexdigest()}\"\n",
    "\n",
    "    def read_sumstat(file, config_file):\n",
    "        sumstats = pd.read_csv(file, compression='gzip', header=0, sep='\\t', quotechar='\"')\n",
    "        if config_file is not None:\n",
    "            import yaml\n",
    "            config = yaml.safe_load(open(config_file, 'r'))\n",
    "            try:\n",
    "                sumstats = sumstats.loc[:,list(config.values())]\n",
    "            except:\n",
    "                raise ValueError(f'According to {config_file}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "            sumstats.columns = list(config.keys())\n",
    "        sumstats.SNP = sumstats.SNP.apply(shorten_id)\n",
    "        sumstats.CHR = sumstats.CHR.astype(int)\n",
    "        sumstats.POS = sumstats.POS.astype(int)\n",
    "        return sumstats\n",
    "\n",
    "    def regional_stats(sumstats, region):\n",
    "        ss = sumstats[(sumstats.CHR == region[0]) & (sumstats.POS >= region[1]) & (sumstats.POS <= region[2])]\n",
    "        ss.loc[:,'Z'] = p2z(ss.P,ss.BETA)\n",
    "        return ss\n",
    "\n",
    "    from scipy.stats import norm\n",
    "    def p2z(pval,beta,twoside=True):\n",
    "        if twoside:\n",
    "            pval = pval/2\n",
    "        z=np.abs(norm.ppf(pval))\n",
    "        ind=beta<0\n",
    "        z[ind]=-z[ind]\n",
    "        return z\n",
    "\n",
    "    def plink_slice(p,pb=None,pf=None):\n",
    "        (bim,fam,bed)=p\n",
    "        if pb is not None:\n",
    "            bim = bim.iloc[pb]\n",
    "            bed = bed[pb,:]\n",
    "        if pf is not None:\n",
    "            fam = fam.iloc[pf]\n",
    "            bed = bed[:,pf]\n",
    "        bed = bed.compute(num_workers=1)\n",
    "        return(bim,fam,bed)\n",
    "\n",
    "    def LD_matrix(bed):\n",
    "        snps = pd.DataFrame(bed.transpose())\n",
    "        # use mean imputation to fill missing first, before computing correlations\n",
    "        ld = snps.fillna( snps.mean() ).corr()\n",
    "        return ld\n",
    "\n",
    "    def bgen_region(region,geno,dtype='float16'):\n",
    "        snps,genos=[],[]\n",
    "        i=0\n",
    "        for t,g in geno[0].iter_variants_in_region('0'+str(region[0]) if region[0]<10 else str(region[0]),region[1],region[2]):\n",
    "            snps.append([int(t.chrom),t.name,0.0,t.pos,t.a1,t.a2,i])\n",
    "            genos.append(g.astype(dtype))\n",
    "            i+=1\n",
    "        return(pd.DataFrame(snps,columns=['chrom','snp','cm','pos','a0','a1','i']),np.array(genos))\n",
    "    \n",
    "    def check_unique(idx, variable):\n",
    "        if idx.duplicated().any():\n",
    "            raise ValueError(f\"{variable} index has duplicated elements!\")\n",
    "\n",
    "    def extract_region(region,gwas,geno,pheno,unr,plink=True):\n",
    "        import time\n",
    "        t = time.localtime()\n",
    "        # Extract the summary stat\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", t)}: Extracting summary statistics ...')\n",
    "        rg_stat = regional_stats(gwas, region)\n",
    "        # see https://github.com/statgenetics/UKBB_GWAS_dev/issues/13\n",
    "        rg_stat.index = rg_stat.CHR.astype(str) + \"_\" + rg_stat.POS.astype(str) + '_' + rg_stat.apply(lambda x: '_'.join(sorted([x.REF, x.ALT])), axis=1)\n",
    "        check_unique(rg_stat.index, \"Summary statistics\")\n",
    "        #\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", t)}: Extracting genotypes in {\"plink\" if plink else \"bgen\"} format ...')\n",
    "        if plink:\n",
    "            rg_bim,rg_fam,rg_bed = plink_slice(geno,pb=list(region_index(geno[0],region,chrom_col=0,pos_col=3)))\n",
    "        else:\n",
    "            rg_bim,rg_bed=bgen_region(region,geno,dtype='float16')\n",
    "            rg_fam = geno[1]\n",
    "        rg_bim.index = rg_bim.chrom.astype(str) + \"_\" + rg_bim.pos.astype(str) + '_' + rg_bim.apply(lambda x: '_'.join(sorted([x.a0, x.a1])), axis=1)\n",
    "        check_unique(rg_fam.index, 'SNPs in reference genotype')\n",
    "        rg_fam.index = rg_fam.iid.astype(str)\n",
    "        check_unique(rg_fam.index, 'FAM info')\n",
    "        rg_bed = pd.DataFrame(rg_bed,index=rg_bim.index,columns=rg_fam.index)\n",
    "\n",
    "        if not list(rg_stat.index)==list(rg_bed.index):\n",
    "            # overlapping variants\n",
    "            com_row_idx = rg_bed.index.intersection(rg_stat.index)\n",
    "            if len(com_row_idx) == 0:\n",
    "                raise ValueError(\"Variants ID between summary statistics and reference genotype are completely different\")\n",
    "            print(f'The regional genotype file ({len(rg_bed.index)} variants) and the regional summary statistics ({len(rg_stat.index)} variants) do not match with each other. The overlapping variants ({len(com_row_idx)} variants) will be selected.')\n",
    "            rg_stat = rg_stat.loc[com_row_idx,:]\n",
    "            rg_bed = rg_bed.loc[com_row_idx,:]\n",
    "       \n",
    "        # Calculate the LD matrix based on unrelated individuals\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", t)}: Calculating LD matrix ...')\n",
    "        iid_unr = rg_fam.index.intersection(pd.Index(unr.IID.astype(str))) #order based on rg_fam\n",
    "        pop_ld_approx = LD_matrix(rg_bed.loc[:,iid_unr])\n",
    "        pop_ld_approx.index = rg_stat.SNP\n",
    "        pheno.index = pheno.IID.astype(str)\n",
    "        check_unique(pheno.index, \"Phenotype\")\n",
    "        iid_ph = pheno.index.intersection(rg_fam.index) #order based on pheno\n",
    "        sample_ld_approx = LD_matrix(rg_bed.loc[:,iid_unr.intersection(iid_ph)])\n",
    "        sample_ld_approx.index = rg_stat.SNP\n",
    "        \n",
    "        # genotypes in the sample of a specific phenotype with ordering match\n",
    "        if not list(iid_ph)==list(pheno.IID.astype(str)):\n",
    "            print('Warning: Some samples with phenotype do not have genotypes')\n",
    "        rg_bed = rg_bed.loc[:,iid_ph]\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", t)}: Data extraction complete!')\n",
    "        return dict(stats=rg_stat,geno=rg_bed,pld=pop_ld_approx,sld=sample_ld_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extract data\n",
    "\n",
    "This step runs in parallel for all loci listed in the region file (via `for_each`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_2 (extract genotypes)]\n",
    "depends: Py_Module('pandas_plink'), Py_Module('pybgen')\n",
    "input: geno_path, pheno_path, sumstats_path, unrelated_samples, for_each = 'regions'\n",
    "output: sumstats = f'{cwd:a}/{_regions[0]}_{_regions[1]}_{_regions[2]}/{sumstats_path:bn}_{_regions[0]}_{_regions[1]}_{_regions[2]}.sumstats.gz',\n",
    "        genotype = f'{cwd:a}/{_regions[0]}_{_regions[1]}_{_regions[2]}/{sumstats_path:bn}_{_regions[0]}_{_regions[1]}_{_regions[2]}.genotype.gz',\n",
    "        pld = f'{cwd:a}/{_regions[0]}_{_regions[1]}_{_regions[2]}/{sumstats_path:bn}_{_regions[0]}_{_regions[1]}_{_regions[2]}.population_ld.gz',\n",
    "        sld = f'{cwd:a}/{_regions[0]}_{_regions[1]}_{_regions[2]}/{sumstats_path:bn}_{_regions[0]}_{_regions[1]}_{_regions[2]}.sample_ld.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h', mem = '60G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand = '${ }', input = f'{cwd:a}/utils.py', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    \n",
    "    # Load the file of summary statistics and standardize it.\n",
    "    sumstats = read_sumstat(${_input[2]:r}, ${format_config_path:r} if ${format_config_path.is_file()} else None)\n",
    "\n",
    "    # Load phenotype file\n",
    "    pheno = pd.read_csv(${_input[1]:r}, header=0, delim_whitespace=True, quotechar='\"')\n",
    "    # Load unrelated sample file\n",
    "    unr = pd.read_csv(${_input[3]:r}, header=0, delim_whitespace=True, quotechar='\"')\n",
    "    \n",
    "    # Load genotype file for the region of interest\n",
    "    geno_inventory = dict([x.strip().split() for x in open(${_input[0]:r}).readlines() if x.strip()])\n",
    "    chrom = \"${_regions[0]}\"\n",
    "    if chrom.startswith('chr'):\n",
    "        chrom = chrom[3:]\n",
    "    if chrom not in geno_inventory:\n",
    "        geno_file = geno_inventory['0']\n",
    "    else:\n",
    "        geno_file = geno_inventory[chrom]\n",
    "    import os\n",
    "    if not os.path.isfile(geno_file):\n",
    "        # relative path\n",
    "        if not os.path.isfile('${_input[0]:ad}/' + geno_file):\n",
    "            raise ValueError(f\"Cannot find genotype file {geno_file}\")\n",
    "        else:\n",
    "            geno_file = '${_input[0]:ad}/' + geno_file\n",
    "    if geno_file.endswith('.bed'):\n",
    "        plink = True\n",
    "        from pandas_plink import read_plink\n",
    "        geno = read_plink(geno_file)\n",
    "    elif geno_file.endswith('.bgen'):\n",
    "        plink = False\n",
    "        from pybgen import PyBGEN\n",
    "        bgen = PyBGEN(geno_file)\n",
    "        sample_file = geno_file.replace('.bgen', '.sample')\n",
    "        if not os.path.isfile(sample_file):\n",
    "            if not os.path.isfile(${bgen_sample_path:r}):\n",
    "                raise ValueError(f\"Cannot find the matching sample file ``{sample_file}`` for ``{geno_file}``.\\nYou can specify path to sample file for all BGEN files using ``--bgen-sample-path``.\")\n",
    "            else:\n",
    "                sample_file = ${bgen_sample_path:r}\n",
    "        bgen_fam = pd.read_csv(sample_file, header=0, delim_whitespace=True, quotechar='\"',skiprows=1)\n",
    "        bgen_fam.columns = ['fid','iid','missing','sex']\n",
    "        geno = [bgen,bgen_fam]\n",
    "    else:\n",
    "        raise ValueError('Plesae provide the genotype files with PLINK binary format or BGEN format')\n",
    "    \n",
    "    rg_info = extract_region((int(chrom), ${_regions[1]}, ${_regions[2]}), sumstats, geno, pheno, unr, plink)\n",
    "    rg_info['stats'].to_csv(${_output['sumstats']:r}, sep = \"\\t\", header = True, index = True)\n",
    "    rg_info['geno'].to_csv(${_output['genotype']:r}, sep = \"\\t\", header = True, index = True)\n",
    "    rg_info['pld'].to_csv(${_output['pld']:r}, sep = \"\\t\", header = True, index = True)\n",
    "    rg_info['sld'].to_csv(${_output['sld']:r}, sep = \"\\t\", header = True, index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.21.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
